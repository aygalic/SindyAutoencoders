{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JksVf1YHpA-V","executionInfo":{"status":"ok","timestamp":1679425142656,"user_tz":-60,"elapsed":24005,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"62186337-ae18-4ae2-c852-cd92f8ff1e85"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLXiW0_hpC6c","executionInfo":{"status":"ok","timestamp":1679425145301,"user_tz":-60,"elapsed":373,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"bafa4749-77a9-4878-a7fd-4955ba2550b1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"8c9fvc6touxm","executionInfo":{"status":"ok","timestamp":1679425183974,"user_tz":-60,"elapsed":35485,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["import os\n","import datetime\n","import pandas as pd\n","import numpy as np\n","from robi.example_spring import get_spring_data\n","from src.sindy_utils import library_size\n","from src.training import train_network\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"HasmB1RQouxw"},"source":["# Generate data"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"2snSfLoFouxz","executionInfo":{"status":"ok","timestamp":1679425200354,"user_tz":-60,"elapsed":16412,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["training_data = get_spring_data(100)\n","validation_data = get_spring_data(10)"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"lwYma8nEoux2"},"source":["# Set up model and training parameters"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"KjZBQslhoux4","executionInfo":{"status":"ok","timestamp":1679425211708,"user_tz":-60,"elapsed":376,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["params = {}\n","\n","params['input_dim'] = training_data['x'].shape[-1]\n","params['latent_dim'] = 1\n","params['model_order'] = 2\n","params['poly_order'] = 2\n","params['include_sine'] = False\n","params['library_dim'] = library_size(2*params['latent_dim'], params['poly_order'], params['include_sine'], True)\n","\n","# sequential thresholding parameters\n","params['sequential_thresholding'] = True\n","params['coefficient_threshold'] = 0.1\n","params['threshold_frequency'] = 500\n","params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","params['coefficient_initialization'] = 'constant'\n","\n","# loss function weighting\n","params['loss_weight_decoder'] = 1.0\n","params['loss_weight_sindy_x'] = 5e-4\n","params['loss_weight_sindy_z'] = 5e-5\n","params['loss_weight_sindy_regularization'] = 1e-5\n","\n","params['activation'] = 'sigmoid'\n","params['widths'] = [128,64,32]\n","\n","# training parameters\n","params['epoch_size'] = training_data['x'].shape[0]\n","params['batch_size'] = 1000\n","params['learning_rate'] = 1e-4\n","\n","params['data_path'] = os.getcwd() + '/'\n","params['print_progress'] = True\n","params['print_frequency'] = 100\n","\n","# training time cutoffs\n","params['max_epochs'] = 5001\n","params['refinement_epochs'] = 1001"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"LixxYZ9Boux6"},"source":["# Run training experiments"]},{"cell_type":"code","execution_count":6,"metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"LuIdjMaXoux8","outputId":"85fe4a9c-53ef-4806-cf5e-d814fe7ef413","executionInfo":{"status":"ok","timestamp":1679435094417,"user_tz":-60,"elapsed":9880568,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["EXPERIMENT 0\n","TRAINING\n","Epoch 0\n","   training loss 0.002731034066528082, (0.0026911483, 0.52640957, 0.00725854, 0.99359125)\n","   validation loss 0.003602056298404932, (0.0032659862, 0.49151534, 0.6031169, 0.99359125)\n","decoder loss ratio: 0.400510, decoder SINDy loss  ratio: 1.000018\n","Epoch 100\n","   training loss 0.0005675706779584289, (0.0005608091, 0.00016071499, 0.0072559644, 0.3125574)\n","   validation loss 0.0018754403572529554, (0.0015707246, 0.0007403617, 0.6031063, 0.3125574)\n","decoder loss ratio: 0.192619, decoder SINDy loss  ratio: 1.000001\n","Epoch 200\n","   training loss 0.000559683539904654, (0.0005552089, 0.0028133136, 0.00725658, 0.070564434)\n","   validation loss 0.0018707149429246783, (0.0015681405, 0.0062444317, 0.6031134, 0.070564434)\n","decoder loss ratio: 0.192302, decoder SINDy loss  ratio: 1.000013\n","Epoch 300\n","   training loss 0.00014649836521130055, (0.00012844437, 0.2618605, 0.006403617, 0.17591466)\n","   validation loss 0.0008989585330709815, (0.0005821892, 0.58728987, 0.5712913, 0.17591466)\n","decoder loss ratio: 0.071394, decoder SINDy loss  ratio: 0.947249\n","Epoch 400\n","   training loss 1.406062347086845e-05, (8.185698e-06, 0.010861515, 0.00561703, 0.2523335)\n","   validation loss 0.0003077238507103175, (3.497046e-05, 0.03132249, 0.5373278, 0.2523335)\n","decoder loss ratio: 0.004288, decoder SINDy loss  ratio: 0.890934\n","Epoch 500\n","   training loss 1.2771634828823153e-05, (6.773157e-06, 0.0019462683, 0.0054708524, 0.31657383)\n","   validation loss 0.0002942458086181432, (2.1897149e-05, 0.0052697603, 0.5378388, 0.31657383)\n","decoder loss ratio: 0.002685, decoder SINDy loss  ratio: 0.891782\n","THRESHOLDING: 2 active coefficients\n","Epoch 600\n","   training loss 1.2515052731032483e-05, (6.5079344e-06, 0.0019376845, 0.005508653, 0.31559077)\n","   validation loss 0.00029232539236545563, (1.9940291e-05, 0.004755159, 0.5379828, 0.31559077)\n","decoder loss ratio: 0.002445, decoder SINDy loss  ratio: 0.892021\n","Epoch 700\n","   training loss 1.2413240256137215e-05, (6.435144e-06, 0.00222061, 0.005537852, 0.3098139)\n","   validation loss 0.00029183586593717337, (1.956429e-05, 0.005306195, 0.5378162, 0.3098139)\n","decoder loss ratio: 0.002399, decoder SINDy loss  ratio: 0.891744\n","Epoch 800\n","   training loss 1.2367230738163926e-05, (6.4131254e-06, 0.0023496011, 0.0055556144, 0.30588177)\n","   validation loss 0.000291572418063879, (1.9472707e-05, 0.0056353356, 0.5375182, 0.30588177)\n","decoder loss ratio: 0.002388, decoder SINDy loss  ratio: 0.891250\n","Epoch 900\n","   training loss 1.2340654393483419e-05, (6.4089472e-06, 0.0024002537, 0.005568484, 0.30274525)\n","   validation loss 0.0002913412463385612, (1.9468216e-05, 0.005817618, 0.53710943, 0.30274525)\n","decoder loss ratio: 0.002387, decoder SINDy loss  ratio: 0.890572\n","Epoch 1000\n","   training loss 1.2339375643932726e-05, (6.430699e-06, 0.0024173302, 0.005578124, 0.29987475)\n","   validation loss 0.0002910624607466161, (1.9563002e-05, 0.0059964773, 0.53640175, 0.29987475)\n","decoder loss ratio: 0.002399, decoder SINDy loss  ratio: 0.889399\n","THRESHOLDING: 2 active coefficients\n","Epoch 1100\n","   training loss 1.234980118169915e-05, (6.464174e-06, 0.0024357778, 0.0055869045, 0.29703858)\n","   validation loss 0.0002906332374550402, (1.9763991e-05, 0.006394582, 0.5351582, 0.29703858)\n","decoder loss ratio: 0.002424, decoder SINDy loss  ratio: 0.887337\n","Epoch 1200\n","   training loss 1.2408896509441547e-05, (6.542743e-06, 0.0025691728, 0.0056078993, 0.29337442)\n","   validation loss 0.00029018690111115575, (2.004268e-05, 0.0071391393, 0.533707, 0.29337442)\n","decoder loss ratio: 0.002458, decoder SINDy loss  ratio: 0.884931\n","Epoch 1300\n","   training loss 1.2374581274343655e-05, (6.5159506e-06, 0.002792328, 0.0056393626, 0.28993323)\n","   validation loss 0.0002896265941672027, (2.0329919e-05, 0.008079979, 0.53198665, 0.28993323)\n","decoder loss ratio: 0.002493, decoder SINDy loss  ratio: 0.882078\n","Epoch 1400\n","   training loss 1.2397964383126236e-05, (6.542168e-06, 0.0029581957, 0.005670258, 0.2872757)\n","   validation loss 0.00028896014555357397, (2.0727077e-05, 0.009200685, 0.52980053, 0.2872757)\n","decoder loss ratio: 0.002542, decoder SINDy loss  ratio: 0.878454\n","Epoch 1500\n","   training loss 1.2597323802765459e-05, (6.747562e-06, 0.0029973816, 0.005694516, 0.2852634)\n","   validation loss 0.00028819634462706745, (2.1373846e-05, 0.010537331, 0.5268859, 0.2852634)\n","decoder loss ratio: 0.002621, decoder SINDy loss  ratio: 0.873621\n","THRESHOLDING: 2 active coefficients\n","Epoch 1600\n","   training loss 1.275617159990361e-05, (6.910317e-06, 0.0030007018, 0.0057133147, 0.28391618)\n","   validation loss 0.0002872507902793586, (2.1990767e-05, 0.011948874, 0.52364683, 0.28391618)\n","decoder loss ratio: 0.002697, decoder SINDy loss  ratio: 0.868250\n","Epoch 1700\n","   training loss 1.2964350389665924e-05, (7.101794e-06, 0.0032026686, 0.005727667, 0.2838589)\n","   validation loss 0.00028676181682385504, (2.2477936e-05, 0.013748233, 0.5215158, 0.2838589)\n","decoder loss ratio: 0.002756, decoder SINDy loss  ratio: 0.864717\n","Epoch 1800\n","   training loss 1.3542863598559052e-05, (7.672588e-06, 0.0032658419, 0.0057340907, 0.2839937)\n","   validation loss 0.00028629854205064476, (2.3246666e-05, 0.014904182, 0.5189334, 0.2839937)\n","decoder loss ratio: 0.002851, decoder SINDy loss  ratio: 0.860435\n","Epoch 1900\n","   training loss 1.3259842489787843e-05, (7.3937526e-06, 0.0031739087, 0.0057339794, 0.2840405)\n","   validation loss 0.00028508665855042636, (2.3178027e-05, 0.015365521, 0.51659983, 0.2840405)\n","decoder loss ratio: 0.002842, decoder SINDy loss  ratio: 0.856566\n","Epoch 2000\n","   training loss 1.2637416148209013e-05, (6.7795095e-06, 0.0030662033, 0.005732431, 0.28383806)\n","   validation loss 0.0002837142674252391, (2.2835386e-05, 0.015568112, 0.51452416, 0.28383806)\n","decoder loss ratio: 0.002800, decoder SINDy loss  ratio: 0.853124\n","THRESHOLDING: 2 active coefficients\n","Epoch 2100\n","   training loss 1.2311938917264342e-05, (6.4600604e-06, 0.0029622607, 0.0057297624, 0.28388837)\n","   validation loss 0.0002825840492732823, (2.2808263e-05, 0.015803434, 0.51229346, 0.28388837)\n","decoder loss ratio: 0.002797, decoder SINDy loss  ratio: 0.849425\n","Epoch 2200\n","   training loss 1.25070073409006e-05, (6.6542075e-06, 0.0029019478, 0.0057291677, 0.28431192)\n","   validation loss 0.00028198809013701975, (2.3236917e-05, 0.016083298, 0.5102078, 0.28431192)\n","decoder loss ratio: 0.002850, decoder SINDy loss  ratio: 0.845967\n","Epoch 2300\n","   training loss 1.2317941582296044e-05, (6.4604046e-06, 0.0030422397, 0.0057354434, 0.28377035)\n","   validation loss 0.0002809327270369977, (2.3169281e-05, 0.016668756, 0.50818455, 0.28377035)\n","decoder loss ratio: 0.002841, decoder SINDy loss  ratio: 0.842613\n","Epoch 2400\n","   training loss 1.2339629392954521e-05, (6.4808382e-06, 0.0031463944, 0.0057407613, 0.2831091)\n","   validation loss 0.0002803933166433126, (2.3286293e-05, 0.01714968, 0.50683683, 0.2831091)\n","decoder loss ratio: 0.002856, decoder SINDy loss  ratio: 0.840378\n","Epoch 2500\n","   training loss 1.2339472050371114e-05, (6.4794185e-06, 0.0032291329, 0.0057445993, 0.2826298)\n","   validation loss 0.00027986292843706906, (2.3377805e-05, 0.017630184, 0.50555456, 0.2826298)\n","decoder loss ratio: 0.002867, decoder SINDy loss  ratio: 0.838252\n","THRESHOLDING: 2 active coefficients\n","Epoch 2600\n","   training loss 1.2332722690189257e-05, (6.4704677e-06, 0.0033027134, 0.005747741, 0.28232485)\n","   validation loss 0.00027936851256527007, (2.3466688e-05, 0.018148195, 0.5043423, 0.28232485)\n","decoder loss ratio: 0.002878, decoder SINDy loss  ratio: 0.836242\n","Epoch 2700\n","   training loss 1.2349457392701879e-05, (6.484642e-06, 0.003360264, 0.005750812, 0.2821397)\n","   validation loss 0.00027901510475203395, (2.3594634e-05, 0.018657554, 0.5033324, 0.2821397)\n","decoder loss ratio: 0.002893, decoder SINDy loss  ratio: 0.834567\n","Epoch 2800\n","   training loss 1.2318778317421675e-05, (6.4542173e-06, 0.0033495517, 0.0057521723, 0.28209966)\n","   validation loss 0.00027904249145649374, (2.370136e-05, 0.019155234, 0.5031247, 0.28209966)\n","decoder loss ratio: 0.002907, decoder SINDy loss  ratio: 0.834223\n","Epoch 2900\n","   training loss 1.2334695384197403e-05, (6.4665574e-06, 0.0033728206, 0.0057538385, 0.2822578)\n","   validation loss 0.00027885474264621735, (2.385573e-05, 0.01964306, 0.50238854, 0.2822578)\n","decoder loss ratio: 0.002925, decoder SINDy loss  ratio: 0.833002\n","Epoch 3000\n","   training loss 1.2324477211222984e-05, (6.455165e-06, 0.0033522642, 0.0057514636, 0.2825967)\n","   validation loss 0.0002785596589092165, (2.386475e-05, 0.020192496, 0.50171864, 0.2825967)\n","decoder loss ratio: 0.002927, decoder SINDy loss  ratio: 0.831891\n","THRESHOLDING: 2 active coefficients\n","Epoch 3100\n","   training loss 1.2252432497916743e-05, (6.374635e-06, 0.0034520568, 0.0057488093, 0.28307897)\n","   validation loss 0.00027906030300073326, (2.3615046e-05, 0.020825537, 0.50314635, 0.28307897)\n","decoder loss ratio: 0.002896, decoder SINDy loss  ratio: 0.834259\n","Epoch 3200\n","   training loss 1.2324486306170002e-05, (6.4493843e-06, 0.0034190756, 0.005737834, 0.28352317)\n","   validation loss 0.00027908800984732807, (2.3760469e-05, 0.021514228, 0.5028331, 0.28352317)\n","decoder loss ratio: 0.002914, decoder SINDy loss  ratio: 0.833739\n","Epoch 3300\n","   training loss 1.2374427569739055e-05, (6.4884116e-06, 0.0035485888, 0.0057377387, 0.28397173)\n","   validation loss 0.00028074198053218424, (2.3799534e-05, 0.021482762, 0.50605714, 0.28397173)\n","decoder loss ratio: 0.002919, decoder SINDy loss  ratio: 0.839085\n","Epoch 3400\n","   training loss 1.2185295418021269e-05, (6.312171e-06, 0.0033461994, 0.005727715, 0.28419563)\n","   validation loss 0.00027693252195604146, (2.367465e-05, 0.02135682, 0.49869612, 0.28419563)\n","decoder loss ratio: 0.002903, decoder SINDy loss  ratio: 0.826880\n","Epoch 3500\n","   training loss 1.968380092876032e-05, (1.3704272e-05, 0.0050678565, 0.0057576364, 0.28473195)\n","   validation loss 0.00030943064484745264, (3.2320415e-05, 0.03189478, 0.5453363, 0.28473195)\n","decoder loss ratio: 0.003963, decoder SINDy loss  ratio: 0.904213\n","THRESHOLDING: 2 active coefficients\n","Epoch 3600\n","   training loss 1.5843856090214103e-05, (9.896567e-06, 0.004356037, 0.0057398635, 0.28595552)\n","   validation loss 0.00028971116989851, (2.7312859e-05, 0.02502846, 0.5165746, 0.28595552)\n","decoder loss ratio: 0.003349, decoder SINDy loss  ratio: 0.856524\n","Epoch 3700\n","   training loss 1.550440356368199e-05, (9.558888e-06, 0.0042441217, 0.005731641, 0.2867488)\n","   validation loss 0.00028846284840255976, (2.6963444e-05, 0.025128826, 0.5147509, 0.2867488)\n","decoder loss ratio: 0.003307, decoder SINDy loss  ratio: 0.853500\n","Epoch 3800\n","   training loss 1.5190149497357197e-05, (9.248172e-06, 0.0041196197, 0.0057237474, 0.28741232)\n","   validation loss 0.00028740669949911535, (2.6649775e-05, 0.025239022, 0.51324165, 0.28741232)\n","decoder loss ratio: 0.003268, decoder SINDy loss  ratio: 0.850998\n","Epoch 3900\n","   training loss 1.4887307770550251e-05, (8.949569e-06, 0.003997553, 0.005716456, 0.2879633)\n","   validation loss 0.0002864655980374664, (2.6356045e-05, 0.025353897, 0.5119245, 0.2879633)\n","decoder loss ratio: 0.003232, decoder SINDy loss  ratio: 0.848814\n","Epoch 4000\n","   training loss 1.2775051800417714e-05, (6.891433e-06, 0.003088308, 0.0056945137, 0.28819466)\n","   validation loss 0.0002767316473182291, (2.44479e-05, 0.023494488, 0.49645412, 0.28819466)\n","decoder loss ratio: 0.002998, decoder SINDy loss  ratio: 0.823162\n","THRESHOLDING: 2 active coefficients\n","Epoch 4100\n","   training loss 1.752893513184972e-05, (1.1655196e-05, 0.0029191168, 0.0056922953, 0.28816366)\n","   validation loss 0.00028591224690899253, (2.9118659e-05, 0.024340961, 0.5053898, 0.28816366)\n","decoder loss ratio: 0.003571, decoder SINDy loss  ratio: 0.837979\n","Epoch 4200\n","   training loss 1.73321404872695e-05, (1.146188e-05, 0.0028727287, 0.0056879004, 0.2882674)\n","   validation loss 0.0002854575286619365, (2.8901628e-05, 0.024571365, 0.50488925, 0.2882674)\n","decoder loss ratio: 0.003544, decoder SINDy loss  ratio: 0.837149\n","Epoch 4300\n","   training loss 1.7179299902636558e-05, (1.1311906e-05, 0.0028280288, 0.005683451, 0.28842673)\n","   validation loss 0.0002851081662811339, (2.8734938e-05, 0.024777938, 0.5045001, 0.28842673)\n","decoder loss ratio: 0.003524, decoder SINDy loss  ratio: 0.836503\n","Epoch 4400\n","   training loss 1.706182592897676e-05, (1.1197188e-05, 0.0027892108, 0.0056793042, 0.28855252)\n","   validation loss 0.00028481479967013, (2.8607521e-05, 0.024984613, 0.504145, 0.28855252)\n","decoder loss ratio: 0.003508, decoder SINDy loss  ratio: 0.835915\n","Epoch 4500\n","   training loss 1.6970716387731954e-05, (1.1108686e-05, 0.0027546922, 0.005675437, 0.28865775)\n","   validation loss 0.0002845604030881077, (2.8507799e-05, 0.025194924, 0.50381255, 0.28865775)\n","decoder loss ratio: 0.003496, decoder SINDy loss  ratio: 0.835363\n","THRESHOLDING: 2 active coefficients\n","Epoch 4600\n","   training loss 1.6896665329113603e-05, (1.1037307e-05, 0.0027220643, 0.005671711, 0.28873992)\n","   validation loss 0.0002843281836248934, (2.8425447e-05, 0.025407938, 0.5034899, 0.28873992)\n","decoder loss ratio: 0.003486, decoder SINDy loss  ratio: 0.834828\n","Epoch 4700\n","   training loss 1.683406844676938e-05, (1.0977436e-05, 0.002690123, 0.0056680064, 0.28881228)\n","   validation loss 0.0002841076347976923, (2.835384e-05, 0.025623182, 0.503169, 0.28881228)\n","decoder loss ratio: 0.003477, decoder SINDy loss  ratio: 0.834296\n","Epoch 4800\n","   training loss 1.6779766156105325e-05, (1.0925878e-05, 0.0026564954, 0.00566412, 0.28890043)\n","   validation loss 0.00028388164355419576, (2.8288378e-05, 0.025835, 0.502825, 0.28890043)\n","decoder loss ratio: 0.003469, decoder SINDy loss  ratio: 0.833726\n","Epoch 4900\n","   training loss 1.673145015956834e-05, (1.0880552e-05, 0.0026219373, 0.0056599793, 0.2889811)\n","   validation loss 0.0002836419444065541, (2.8225972e-05, 0.02604411, 0.5024479, 0.2889811)\n","decoder loss ratio: 0.003461, decoder SINDy loss  ratio: 0.833101\n","Epoch 5000\n","   training loss 1.669015910010785e-05, (1.0842481e-05, 0.0025860623, 0.0056554624, 0.28906444)\n","   validation loss 0.0002833945327438414, (2.816865e-05, 0.026249008, 0.5020455, 0.28906444)\n","decoder loss ratio: 0.003454, decoder SINDy loss  ratio: 0.832433\n","THRESHOLDING: 2 active coefficients\n","REFINEMENT\n","Epoch 0\n","   training loss 1.083193001250038e-05, (7.844234e-06, 0.003067006, 0.0056686923, 0.2902996)\n","   validation loss 0.0002742347423918545, (2.482674e-05, 0.026303418, 0.49618566, 0.2902996)\n","decoder loss ratio: 0.003045, decoder SINDy loss  ratio: 0.822717\n","Epoch 100\n","   training loss 1.374368275719462e-05, (1.0891698e-05, 0.0011433347, 0.005589636, 0.3293801)\n","   validation loss 0.0002802112139761448, (2.8035072e-05, 0.024181828, 0.50193405, 0.3293801)\n","decoder loss ratio: 0.003438, decoder SINDy loss  ratio: 0.832249\n","Epoch 200\n","   training loss 1.3688734725292306e-05, (1.0856379e-05, 0.00090720935, 0.0055739903, 0.3353294)\n","   validation loss 0.0002800517831929028, (2.7923468e-05, 0.024397751, 0.5018168, 0.3353294)\n","decoder loss ratio: 0.003424, decoder SINDy loss  ratio: 0.832054\n","Epoch 300\n","   training loss 1.3608179870061576e-05, (1.0784261e-05, 0.0008303132, 0.0055648065, 0.33722422)\n","   validation loss 0.00027982296887785196, (2.781505e-05, 0.024691053, 0.5015467, 0.33722422)\n","decoder loss ratio: 0.003411, decoder SINDy loss  ratio: 0.831606\n","Epoch 400\n","   training loss 1.3505055903806351e-05, (1.068678e-05, 0.0007950744, 0.0055570425, 0.33808586)\n","   validation loss 0.00027956359554082155, (2.7697717e-05, 0.024983408, 0.5012334, 0.33808586)\n","decoder loss ratio: 0.003397, decoder SINDy loss  ratio: 0.831087\n","Epoch 500\n","   training loss 1.3386793398240115e-05, (1.0573128e-05, 0.00077805005, 0.005549525, 0.33858588)\n","   validation loss 0.0002792837913148105, (2.757267e-05, 0.025266953, 0.5008955, 0.33858588)\n","decoder loss ratio: 0.003381, decoder SINDy loss  ratio: 0.830527\n","Epoch 600\n","   training loss 1.3261875210446306e-05, (1.0452301e-05, 0.00077343703, 0.005541805, 0.33891413)\n","   validation loss 0.0002789884456433356, (2.7445325e-05, 0.025542676, 0.500532, 0.33891413)\n","decoder loss ratio: 0.003366, decoder SINDy loss  ratio: 0.829924\n","Epoch 700\n","   training loss 1.314028304477688e-05, (1.0334477e-05, 0.00078002614, 0.0055336086, 0.33913854)\n","   validation loss 0.00027867601602338254, (2.7324058e-05, 0.025813477, 0.50012255, 0.33913854)\n","decoder loss ratio: 0.003351, decoder SINDy loss  ratio: 0.829245\n","Epoch 800\n","   training loss 1.3028717148699798e-05, (1.022644e-05, 0.0007981899, 0.005524734, 0.3392979)\n","   validation loss 0.00027834370848722756, (2.7214555e-05, 0.026084024, 0.49964988, 0.3392979)\n","decoder loss ratio: 0.003337, decoder SINDy loss  ratio: 0.828461\n","Epoch 900\n","   training loss 1.2930585398862604e-05, (1.0131565e-05, 0.0008297323, 0.005515067, 0.3394033)\n","   validation loss 0.0002779981878120452, (2.7120148e-05, 0.026362186, 0.49911985, 0.3394033)\n","decoder loss ratio: 0.003326, decoder SINDy loss  ratio: 0.827582\n","Epoch 1000\n","   training loss 1.2846148820244707e-05, (1.0050039e-05, 0.00087714393, 0.005504506, 0.33946338)\n","   validation loss 0.0002776454493869096, (2.7041078e-05, 0.026655063, 0.49854323, 0.33946338)\n","decoder loss ratio: 0.003316, decoder SINDy loss  ratio: 0.826626\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-69edefec05a3>:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append({**results_dict, **params}, ignore_index=True)\n"]}],"source":["num_experiments = 1\n","df = pd.DataFrame()\n","for i in range(num_experiments):\n","    print('EXPERIMENT %d' % i)\n","\n","    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","\n","    params['save_name'] = 'spring_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n","\n","    tf.compat.v1.reset_default_graph()\n","\n","    results_dict = train_network(training_data, validation_data, params)\n","    df = df.append({**results_dict, **params}, ignore_index=True)\n","\n","df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}