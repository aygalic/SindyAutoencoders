{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRiWtT66EpgK","executionInfo":{"status":"ok","timestamp":1679777779089,"user_tz":-60,"elapsed":24263,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"4dd62852-ed2b-4757-fb1e-f99637b66020"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UtJhc1fEoHM","executionInfo":{"status":"ok","timestamp":1679777789271,"user_tz":-60,"elapsed":442,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"c3108f23-740e-47c5-ac3c-172adc57654c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"pycharm":{"name":"#%%\n"},"id":"tBTeSgnZDfni","executionInfo":{"status":"ok","timestamp":1679777797464,"user_tz":-60,"elapsed":4548,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["import os\n","import datetime\n","import pandas as pd\n","import numpy as np\n","from robi.example_LV2 import get_lofka_volterra_data\n","from src.sindy_utils import library_size\n","from src.training import train_network\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"eieoW7yzDfnr"},"source":["# Generate data"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"nN2gnjRMDfnt","executionInfo":{"status":"ok","timestamp":1679777810973,"user_tz":-60,"elapsed":13517,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["# generate training, validation, testing data\n","noise_strength = 1e-6\n","training_data = get_lofka_volterra_data(128, noise_strength=noise_strength)\n","validation_data = get_lofka_volterra_data(20, noise_strength=noise_strength)"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["training_data"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"mdVSNA1iDfnw"}},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"LtUvTVjpDfnx"},"source":["# Set up model and training parameters"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"3yuYFK6RDfny","executionInfo":{"status":"ok","timestamp":1679777813961,"user_tz":-60,"elapsed":195,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["params = {}\n","\n","params['input_dim'] = 128\n","params['latent_dim'] = 2\n","params['model_order'] = 1\n","params['poly_order'] = 2\n","params['include_sine'] = False\n","params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n","\n","# sequential thresholding parameters\n","params['sequential_thresholding'] = True\n","params['coefficient_threshold'] = 0.1\n","params['threshold_frequency'] = 500\n","params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","params['coefficient_initialization'] = 'constant'\n","\n","# loss function weighting\n","params['loss_weight_decoder'] = 1.0\n","params['loss_weight_sindy_z'] = 1e-4\n","params['loss_weight_sindy_x'] = 1e-4\n","params['loss_weight_sindy_regularization'] = 1e-5\n","\n","params['activation'] = 'sigmoid'\n","params['widths'] = [64,32]\n","\n","# training parameters\n","params['epoch_size'] = training_data['x'].shape[0]\n","params['batch_size'] = 1024\n","params['learning_rate'] = 1e-3\n","\n","params['data_path'] = os.getcwd() + '/'\n","params['print_progress'] = True\n","params['print_frequency'] = 100\n","\n","# training time cutoffs\n","params['max_epochs'] = 5001\n","params['refinement_epochs'] = 1001"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"VSf6uw-aDfnz"},"source":["# Run training experiments"]},{"cell_type":"code","execution_count":7,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"H9PEhyUeDfn0","executionInfo":{"status":"ok","timestamp":1679788312005,"user_tz":-60,"elapsed":10472610,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"738c9a94-f5ab-469b-982c-adfd767dcef2"},"outputs":[{"output_type":"stream","name":"stdout","text":["EXPERIMENT 0\n","TRAINING\n","Epoch 0\n","   training loss 0.04867162927985191, (0.041144263, 73.814285, 1.3691305, 0.90251803)\n","   validation loss 0.09921310096979141, (0.0895632, 93.44309, 2.9657373, 0.90251803)\n","decoder loss ratio: 0.326918, decoder SINDy loss  ratio: 1.255512\n","Epoch 100\n","   training loss 2.8853635740233585e-05, (1.2610619e-05, 0.018196467, 0.0042847674, 1.3994894)\n","   validation loss 3.357855530339293e-05, (1.4479771e-05, 0.0365249, 0.01451401, 1.3994894)\n","decoder loss ratio: 0.000053, decoder SINDy loss  ratio: 0.006144\n","Epoch 200\n","   training loss 2.9100610845489427e-05, (1.7294087e-05, 0.009174155, 0.0020424456, 1.0684861)\n","   validation loss 3.59214172931388e-05, (2.2885373e-05, 0.016070202, 0.007441638, 1.0684861)\n","decoder loss ratio: 0.000084, decoder SINDy loss  ratio: 0.003150\n","Epoch 300\n","   training loss 1.8412702047498897e-05, (8.575811e-06, 0.0076433006, 0.0014312848, 0.8929434)\n","   validation loss 2.6326953957322985e-05, (1.5568641e-05, 0.013579152, 0.004709635, 0.8929434)\n","decoder loss ratio: 0.000057, decoder SINDy loss  ratio: 0.001994\n","Epoch 400\n","   training loss 9.359948307974264e-06, (6.733644e-07, 0.008631018, 0.0013493355, 0.7688548)\n","   validation loss 1.091994454327505e-05, (1.604813e-06, 0.01286095, 0.0034048848, 0.7688548)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001441\n","Epoch 500\n","   training loss 2.0946163203916512e-05, (1.2883251e-05, 0.0073559876, 0.0013369857, 0.7193616)\n","   validation loss 2.9174530936870724e-05, (2.0436704e-05, 0.012766504, 0.0026756115, 0.7193616)\n","decoder loss ratio: 0.000075, decoder SINDy loss  ratio: 0.001133\n","THRESHOLDING: 8 active coefficients\n","Epoch 600\n","   training loss 2.0571629647747613e-05, (1.2739676e-05, 0.008752932, 0.0013952191, 0.6817138)\n","   validation loss 2.8424812626326457e-05, (2.010496e-05, 0.011815627, 0.0032115246, 0.6817138)\n","decoder loss ratio: 0.000073, decoder SINDy loss  ratio: 0.001360\n","Epoch 700\n","   training loss 1.1659585652523674e-05, (4.1608328e-06, 0.007941052, 0.0011901379, 0.6585634)\n","   validation loss 1.3924698578193784e-05, (5.735813e-06, 0.012498221, 0.003534301, 0.6585634)\n","decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.001496\n","Epoch 800\n","   training loss 3.871123772114515e-05, (3.107132e-05, 0.010789758, 0.0021882327, 0.63421166)\n","   validation loss 6.939218292245641e-05, (6.11232e-05, 0.01396683, 0.0053017777, 0.63421166)\n","decoder loss ratio: 0.000223, decoder SINDy loss  ratio: 0.002244\n","Epoch 900\n","   training loss 1.1231505595787894e-05, (3.9723564e-06, 0.009269169, 0.0013526696, 0.61969656)\n","   validation loss 1.2779612916347105e-05, (5.2025707e-06, 0.011093918, 0.0027068527, 0.61969656)\n","decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.001146\n","Epoch 1000\n","   training loss 1.2189557310193777e-05, (5.025166e-06, 0.00974603, 0.0009363561, 0.60961527)\n","   validation loss 1.3396362191997468e-05, (5.775448e-06, 0.012293678, 0.0029539445, 0.60961527)\n","decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.001251\n","THRESHOLDING: 6 active coefficients\n","Epoch 1100\n","   training loss 9.500968189968262e-06, (2.5909078e-06, 0.008503206, 0.00067312387, 0.59924275)\n","   validation loss 1.0832673069671728e-05, (3.3993908e-06, 0.011441, 0.002967553, 0.59924275)\n","decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.001256\n","Epoch 1200\n","   training loss 2.8444745112210512e-05, (2.1425016e-05, 0.009200005, 0.0012832901, 0.5971399)\n","   validation loss 3.814426963799633e-05, (3.0766845e-05, 0.011160863, 0.0028993902, 0.5971399)\n","decoder loss ratio: 0.000112, decoder SINDy loss  ratio: 0.001227\n","Epoch 1300\n","   training loss 1.382760274282191e-05, (6.8238264e-06, 0.010404252, 0.001347587, 0.5828592)\n","   validation loss 1.5604218788212165e-05, (8.150598e-06, 0.013391719, 0.0028585736, 0.5828592)\n","decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.001210\n","Epoch 1400\n","   training loss 1.3454796317091677e-05, (6.610948e-06, 0.009601598, 0.0014020258, 0.5743486)\n","   validation loss 1.8385195289738476e-05, (1.0936833e-05, 0.01381116, 0.0032376102, 0.5743486)\n","decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.001371\n","Epoch 1500\n","   training loss 8.945605259214062e-06, (2.1450373e-06, 0.009835911, 0.001693381, 0.56476384)\n","   validation loss 1.0848580132005736e-05, (3.7031296e-06, 0.012476086, 0.0025020393, 0.56476384)\n","decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.001059\n","THRESHOLDING: 6 active coefficients\n","Epoch 1600\n","   training loss 5.084780423203483e-05, (4.39543e-05, 0.011258494, 0.001410207, 0.5626636)\n","   validation loss 7.526143599534407e-05, (6.792264e-05, 0.013772443, 0.0033490963, 0.5626636)\n","decoder loss ratio: 0.000248, decoder SINDy loss  ratio: 0.001418\n","Epoch 1700\n","   training loss 3.955159627366811e-05, (3.2765354e-05, 0.009640185, 0.0016380635, 0.56584173)\n","   validation loss 5.85802918067202e-05, (5.1372885e-05, 0.012122274, 0.0033676217, 0.56584173)\n","decoder loss ratio: 0.000188, decoder SINDy loss  ratio: 0.001426\n","Epoch 1800\n","   training loss 8.597407941124402e-06, (1.8189573e-06, 0.010048324, 0.0018094466, 0.55926734)\n","   validation loss 9.841935025178827e-06, (2.812653e-06, 0.012035348, 0.0023307381, 0.55926734)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000987\n","Epoch 1900\n","   training loss 1.3174631021684036e-05, (6.4671876e-06, 0.009570977, 0.0021996505, 0.5530381)\n","   validation loss 2.002366636588704e-05, (1.2943792e-05, 0.0122778695, 0.0032170578, 0.5530381)\n","decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.001362\n","Epoch 2000\n","   training loss 1.1378909221093636e-05, (4.677314e-06, 0.010391744, 0.0015825463, 0.55041665)\n","   validation loss 1.916132532642223e-05, (1.22624e-05, 0.011136, 0.002811596, 0.55041665)\n","decoder loss ratio: 0.000045, decoder SINDy loss  ratio: 0.001190\n","THRESHOLDING: 6 active coefficients\n","Epoch 2100\n","   training loss 1.212338793266099e-05, (5.4976854e-06, 0.00973488, 0.0011483886, 0.55373764)\n","   validation loss 1.62034612003481e-05, (9.360294e-06, 0.010921385, 0.0021365273, 0.55373764)\n","decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000904\n","Epoch 2200\n","   training loss 7.911994543974288e-06, (1.3446288e-06, 0.010439037, 0.0013101147, 0.5392451)\n","   validation loss 9.49539116845699e-06, (2.7188498e-06, 0.0116282, 0.0022127037, 0.5392451)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000937\n","Epoch 2300\n","   training loss 1.581921605975367e-05, (9.232682e-06, 0.011086722, 0.0012721989, 0.5350642)\n","   validation loss 1.923795571201481e-05, (1.2418682e-05, 0.012520564, 0.0021657585, 0.5350642)\n","decoder loss ratio: 0.000045, decoder SINDy loss  ratio: 0.000917\n","Epoch 2400\n","   training loss 1.5905796317383647e-05, (9.395835e-06, 0.010842817, 0.0011878905, 0.53068906)\n","   validation loss 2.4491784643032588e-05, (1.773399e-05, 0.01198852, 0.0025205205, 0.53068906)\n","decoder loss ratio: 0.000065, decoder SINDy loss  ratio: 0.001067\n","Epoch 2500\n","   training loss 7.830582035239786e-06, (1.2320093e-06, 0.011910068, 0.0017234804, 0.5235218)\n","   validation loss 9.339812095277011e-06, (2.5922554e-06, 0.012785278, 0.0023381177, 0.5235218)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000990\n","THRESHOLDING: 6 active coefficients\n","Epoch 2600\n","   training loss 1.476619036111515e-05, (8.205567e-06, 0.012332721, 0.0013073093, 0.5196621)\n","   validation loss 1.8196802557213232e-05, (1.141685e-05, 0.013092536, 0.0027407783, 0.5196621)\n","decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.001160\n","Epoch 2700\n","   training loss 5.380904985941015e-05, (4.706608e-05, 0.013086043, 0.0026267315, 0.51716936)\n","   validation loss 8.544213778804988e-05, (7.83136e-05, 0.015283527, 0.0042849253, 0.51716936)\n","decoder loss ratio: 0.000286, decoder SINDy loss  ratio: 0.001814\n","Epoch 2800\n","   training loss 2.0843821403104812e-05, (1.4148047e-05, 0.01347344, 0.00205089, 0.51433414)\n","   validation loss 3.189034396200441e-05, (2.493465e-05, 0.01494281, 0.0031807022, 0.51433414)\n","decoder loss ratio: 0.000091, decoder SINDy loss  ratio: 0.001347\n","Epoch 2900\n","   training loss 7.729466233286075e-06, (1.0716446e-06, 0.013239946, 0.0023027328, 0.51035535)\n","   validation loss 9.196043720294256e-06, (2.3660873e-06, 0.0146189025, 0.0026451228, 0.51035535)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.001120\n","Epoch 3000\n","   training loss 1.7732054402586073e-05, (1.1275003e-05, 0.0117964195, 0.0015856259, 0.51188475)\n","   validation loss 2.237237640656531e-05, (1.5612888e-05, 0.013248529, 0.0031578694, 0.51188475)\n","decoder loss ratio: 0.000057, decoder SINDy loss  ratio: 0.001337\n","THRESHOLDING: 5 active coefficients\n","Epoch 3100\n","   training loss 2.7389090973883867e-05, (2.0392657e-05, 0.01829331, 0.0021869869, 0.49484053)\n","   validation loss 3.2891719456529245e-05, (2.5615132e-05, 0.01931358, 0.0039682486, 0.49484053)\n","decoder loss ratio: 0.000093, decoder SINDy loss  ratio: 0.001680\n","Epoch 3200\n","   training loss 2.165780824725516e-05, (1.52056855e-05, 0.013001759, 0.0023996122, 0.49119875)\n","   validation loss 3.3012682251865044e-05, (2.6293492e-05, 0.014702058, 0.0033699928, 0.49119875)\n","decoder loss ratio: 0.000096, decoder SINDy loss  ratio: 0.001427\n","Epoch 3300\n","   training loss 7.955926776048727e-06, (1.8045014e-06, 0.011196211, 0.001508499, 0.48809543)\n","   validation loss 1.1568346963031217e-05, (5.245533e-06, 0.011899945, 0.0025186578, 0.48809543)\n","decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.001066\n","Epoch 3400\n","   training loss 7.006884516158607e-06, (7.572381e-07, 0.011362688, 0.0021080747, 0.49025705)\n","   validation loss 8.273877938336227e-06, (1.7245993e-06, 0.013961209, 0.0025058736, 0.49025705)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001061\n","Epoch 3500\n","   training loss 2.3777964088367298e-05, (1.7582788e-05, 0.011935782, 0.0010425708, 0.48973408)\n","   validation loss 4.776801506523043e-05, (4.112181e-05, 0.014071777, 0.003416858, 0.48973408)\n","decoder loss ratio: 0.000150, decoder SINDy loss  ratio: 0.001446\n","THRESHOLDING: 5 active coefficients\n","Epoch 3600\n","   training loss 1.0146143722522538e-05, (3.9275087e-06, 0.0111408895, 0.0017569414, 0.4928852)\n","   validation loss 1.2327949661994353e-05, (5.78949e-06, 0.013408076, 0.002687999, 0.4928852)\n","decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.001138\n","Epoch 3700\n","   training loss 8.527418685844168e-06, (2.2984127e-06, 0.0114559345, 0.0014945798, 0.49339548)\n","   validation loss 1.1707797966664657e-05, (5.1387806e-06, 0.013604312, 0.002746313, 0.49339548)\n","decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.001163\n","Epoch 3800\n","   training loss 8.949697075877339e-06, (2.6599519e-06, 0.01166269, 0.0018728424, 0.49361932)\n","   validation loss 1.3669254258275032e-05, (6.9194393e-06, 0.014924982, 0.0032112438, 0.49361932)\n","decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.001359\n","Epoch 3900\n","   training loss 1.735303521854803e-05, (1.0733376e-05, 0.014354875, 0.0023369524, 0.49504772)\n","   validation loss 2.7275120373815298e-05, (2.0231206e-05, 0.01777899, 0.003155407, 0.49504772)\n","decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.001336\n","Epoch 4000\n","   training loss 9.451696314499713e-06, (3.2649623e-06, 0.01077989, 0.0017519034, 0.49335542)\n","   validation loss 1.1098965842393227e-05, (4.695068e-06, 0.012270347, 0.002433088, 0.49335542)\n","decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.001030\n","THRESHOLDING: 5 active coefficients\n","Epoch 4100\n","   training loss 3.3610238460823894e-05, (2.7211861e-05, 0.012752328, 0.0018796342, 0.4935182)\n","   validation loss 5.314801092026755e-05, (4.641356e-05, 0.014987097, 0.0030056026, 0.4935182)\n","decoder loss ratio: 0.000169, decoder SINDy loss  ratio: 0.001272\n","Epoch 4200\n","   training loss 7.0240166678559035e-06, (7.698668e-07, 0.0114513915, 0.001724346, 0.49365762)\n","   validation loss 8.010338206076995e-06, (1.548938e-06, 0.013139307, 0.0021089301, 0.49365762)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000893\n","Epoch 4300\n","   training loss 7.277281838469207e-06, (1.0851911e-06, 0.010641291, 0.0016665237, 0.4961309)\n","   validation loss 9.189690899802372e-06, (2.7084673e-06, 0.01323383, 0.0019653144, 0.4961309)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000832\n","Epoch 4400\n","   training loss 2.1817380911670625e-05, (1.5116966e-05, 0.01519569, 0.0017367353, 0.5007172)\n","   validation loss 2.6758983949548565e-05, (1.9651752e-05, 0.018164545, 0.0028360533, 0.5007172)\n","decoder loss ratio: 0.000072, decoder SINDy loss  ratio: 0.001201\n","Epoch 4500\n","   training loss 1.5644856830476783e-05, (9.474765e-06, 0.010844361, 0.0010429607, 0.498136)\n","   validation loss 3.625182944233529e-05, (2.9641653e-05, 0.013530957, 0.0027571956, 0.498136)\n","decoder loss ratio: 0.000108, decoder SINDy loss  ratio: 0.001167\n","THRESHOLDING: 5 active coefficients\n","Epoch 4600\n","   training loss 8.348889423359651e-06, (2.241321e-06, 0.010129394, 0.001038619, 0.49907675)\n","   validation loss 1.1929345419048332e-05, (5.2161754e-06, 0.014927136, 0.0022968838, 0.49907675)\n","decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000972\n","Epoch 4700\n","   training loss 1.2643779882637318e-05, (6.4931337e-06, 0.010509718, 0.0012037522, 0.4979299)\n","   validation loss 1.835154034779407e-05, (1.1900042e-05, 0.012728381, 0.0019936163, 0.4979299)\n","decoder loss ratio: 0.000043, decoder SINDy loss  ratio: 0.000844\n","Epoch 4800\n","   training loss 7.306132465600967e-05, (6.70048e-05, 0.010333823, 0.00049044064, 0.4974092)\n","   validation loss 0.00010057049075840041, (9.362259e-05, 0.015107358, 0.004630746, 0.4974092)\n","decoder loss ratio: 0.000342, decoder SINDy loss  ratio: 0.001960\n","Epoch 4900\n","   training loss 1.8460203136783093e-05, (1.2288741e-05, 0.0102786, 0.0017876187, 0.4964839)\n","   validation loss 2.034624048974365e-05, (1.3820078e-05, 0.0129414825, 0.0026717603, 0.4964839)\n","decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.001131\n","Epoch 5000\n","   training loss 1.686846007942222e-05, (1.0743779e-05, 0.010300704, 0.0009963119, 0.4994979)\n","   validation loss 2.529230187064968e-05, (1.8814575e-05, 0.012539929, 0.0022875408, 0.4994979)\n","decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000968\n","THRESHOLDING: 5 active coefficients\n","REFINEMENT\n","Epoch 0\n","   training loss 3.0099381547188386e-06, (1.9077684e-06, 0.009606687, 0.0014150103, 0.50095755)\n","   validation loss 3.969139925175114e-06, (2.579625e-06, 0.0118275015, 0.0020676476, 0.50095755)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000875\n","Epoch 100\n","   training loss 1.429335679858923e-05, (1.3354636e-05, 0.008330712, 0.001056494, 0.5172234)\n","   validation loss 3.4590317227412015e-05, (3.307971e-05, 0.012369572, 0.002736532, 0.5172234)\n","decoder loss ratio: 0.000121, decoder SINDy loss  ratio: 0.001158\n","Epoch 200\n","   training loss 2.1176872451178497e-06, (1.3004538e-06, 0.0071665985, 0.0010057348, 0.5272052)\n","   validation loss 4.492445441428572e-06, (3.2056034e-06, 0.010669319, 0.002199105, 0.5272052)\n","decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000931\n","Epoch 300\n","   training loss 1.3021373206356657e-06, (5.8973467e-07, 0.006116093, 0.0010079322, 0.53555286)\n","   validation loss 2.093792772939196e-06, (1.0527702e-06, 0.008790968, 0.0016192568, 0.53555286)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000685\n","Epoch 400\n","   training loss 6.421067610062892e-06, (5.625031e-06, 0.0070798392, 0.0008805294, 0.5385659)\n","   validation loss 8.361834261449985e-06, (7.043311e-06, 0.011327723, 0.0018575079, 0.5385659)\n","decoder loss ratio: 0.000026, decoder SINDy loss  ratio: 0.000786\n","Epoch 500\n","   training loss 4.388482921058312e-06, (3.7551467e-06, 0.005185419, 0.0011479396, 0.5491404)\n","   validation loss 5.149261141923489e-06, (4.013405e-06, 0.00979358, 0.0015649815, 0.5491404)\n","decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000663\n","Epoch 600\n","   training loss 4.746962986246217e-06, (4.1558696e-06, 0.00508768, 0.00082325167, 0.5593238)\n","   validation loss 1.2206168321426958e-05, (1.0940902e-05, 0.011059816, 0.0015928467, 0.5593238)\n","decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000674\n","Epoch 700\n","   training loss 2.4368403046537424e-06, (1.886607e-06, 0.004842476, 0.00065985625, 0.56645244)\n","   validation loss 3.682625447254395e-06, (2.68281e-06, 0.00825687, 0.0017412857, 0.56645244)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000737\n","Epoch 800\n","   training loss 7.236979854496894e-06, (6.628596e-06, 0.0052908286, 0.00079301244, 0.5695466)\n","   validation loss 1.0497998118808027e-05, (9.448956e-06, 0.008558266, 0.0019321609, 0.5695466)\n","decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000818\n","Epoch 900\n","   training loss 2.997542469529435e-05, (2.9196486e-05, 0.0058718733, 0.001917506, 0.5687757)\n","   validation loss 5.5391672503901646e-05, (5.3984957e-05, 0.0105093075, 0.0035578334, 0.5687757)\n","decoder loss ratio: 0.000197, decoder SINDy loss  ratio: 0.001506\n","Epoch 1000\n","   training loss 5.078768481325824e-06, (4.3476366e-06, 0.0061605284, 0.0011507942, 0.5732279)\n","   validation loss 7.234121767396573e-06, (6.0770267e-06, 0.009280226, 0.0022907264, 0.5732279)\n","decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000970\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-e378c3c436ee>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append({**results_dict, **params}, ignore_index=True)\n"]}],"source":["num_experiments = 1\n","df = pd.DataFrame()\n","for i in range(num_experiments):\n","    print('EXPERIMENT %d' % i)\n","\n","    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","\n","    params['save_name'] = 'LV2_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n","\n","    # tf.reset_default_graph() didn't work anymore\n","    tf.compat.v1.reset_default_graph()\n","\n","    results_dict = train_network(training_data, validation_data, params)\n","    df = df.append({**results_dict, **params}, ignore_index=True)\n","\n","df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}