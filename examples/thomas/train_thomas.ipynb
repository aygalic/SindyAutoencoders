{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"../..\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_thomas import get_thomas_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/Aygalic/OneDrive/polimi/COURSES/S10/Computational Stats/SindyAutoencoders_v2/examples/thomas\n",
      "LICENSE\n",
      "README.md\n",
      "examples\n",
      "nate\n",
      "rd_solver\n",
      "robi\n",
      "src\n"
     ]
    }
   ],
   "source": [
    "!pwd \n",
    "!ls ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_thomas_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_thomas_data(50, noise_strength=noise_strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 2\n",
    "params['include_sine'] = True\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "params['print_frequency'] = 1 # for testing\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001 # WAY TOO LONG ON AN M1 MAX\n",
    "params['max_epochs'] = 1000\n",
    "params['refinement_epochs'] = 1001 # idk what this is \n",
    "params['refinement_epochs'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "TRAINING\n",
      "Epoch 0\n",
      "   training loss 0.27228760719299316, (0.27212873, 285.6557, 1.5222338, 0.6643909)\n",
      "   validation loss 0.2891254723072052, (0.28902632, 488.42545, 0.92515945, 0.6643909)\n",
      "decoder loss ratio: 0.602959, decoder SINDy loss  ratio: 59.123707\n",
      "Epoch 1\n",
      "   training loss 0.16994956135749817, (0.16990462, 6.6365457, 0.40834934, 0.41062605)\n",
      "   validation loss 0.1761362999677658, (0.17609882, 6.762764, 0.3335649, 0.41062605)\n",
      "decoder loss ratio: 0.367372, decoder SINDy loss  ratio: 21.316967\n",
      "Epoch 2\n",
      "   training loss 0.1638975888490677, (0.16387555, 1.9116591, 0.19271144, 0.2775983)\n",
      "   validation loss 0.14206191897392273, (0.14204235, 1.9624577, 0.1678712, 0.2775983)\n",
      "decoder loss ratio: 0.296325, decoder SINDy loss  ratio: 10.728062\n",
      "Epoch 3\n",
      "   training loss 0.15845392644405365, (0.15844516, 0.3506659, 0.07081626, 0.1678691)\n",
      "   validation loss 0.1327546238899231, (0.132746, 0.5718062, 0.06948465, 0.1678691)\n",
      "decoder loss ratio: 0.276931, decoder SINDy loss  ratio: 4.440521\n",
      "Epoch 4\n",
      "   training loss 0.15710429847240448, (0.15710035, 0.092291296, 0.027718868, 0.11732078)\n",
      "   validation loss 0.13079454004764557, (0.13078988, 0.2629939, 0.034890447, 0.11732078)\n",
      "decoder loss ratio: 0.272850, decoder SINDy loss  ratio: 2.229727\n",
      "Epoch 5\n",
      "   training loss 0.15620523691177368, (0.15620242, 0.039589595, 0.018884895, 0.09208815)\n",
      "   validation loss 0.12985603511333466, (0.12985276, 0.12695374, 0.023511248, 0.09208815)\n",
      "decoder loss ratio: 0.270895, decoder SINDy loss  ratio: 1.502522\n",
      "Epoch 6\n",
      "   training loss 0.15530630946159363, (0.1553039, 0.021790238, 0.01644874, 0.07714532)\n",
      "   validation loss 0.12909111380577087, (0.1290884, 0.063534915, 0.019298403, 0.07714532)\n",
      "decoder loss ratio: 0.269301, decoder SINDy loss  ratio: 1.233293\n",
      "Epoch 7\n",
      "   training loss 0.15044371783733368, (0.15044107, 0.027962739, 0.019668661, 0.06796151)\n",
      "   validation loss 0.12583091855049133, (0.12582819, 0.052041072, 0.020468704, 0.06796151)\n",
      "decoder loss ratio: 0.262499, decoder SINDy loss  ratio: 1.308083\n",
      "Epoch 8\n",
      "   training loss 0.06629113107919693, (0.0662885, 0.07473556, 0.021762326, 0.045697086)\n",
      "   validation loss 0.05798891559243202, (0.057986088, 0.10092179, 0.023678422, 0.045697086)\n",
      "decoder loss ratio: 0.120969, decoder SINDy loss  ratio: 1.513205\n",
      "Epoch 9\n",
      "   training loss 0.02171383425593376, (0.021712936, 0.036965903, 0.0057521975, 0.032169558)\n",
      "   validation loss 0.02393103577196598, (0.023929905, 0.034160394, 0.008083458, 0.032169558)\n",
      "decoder loss ratio: 0.049922, decoder SINDy loss  ratio: 0.516586\n",
      "Epoch 10\n",
      "   training loss 0.016536055132746696, (0.016535312, 0.011859859, 0.0047761095, 0.02668909)\n",
      "   validation loss 0.019594598561525345, (0.019593662, 0.011260848, 0.006700818, 0.02668909)\n",
      "decoder loss ratio: 0.040876, decoder SINDy loss  ratio: 0.428226\n",
      "Epoch 11\n",
      "   training loss 0.014447130262851715, (0.014446437, 0.004804067, 0.004544132, 0.023858428)\n",
      "   validation loss 0.01738620363175869, (0.01738535, 0.0056360797, 0.006155206, 0.023858428)\n",
      "decoder loss ratio: 0.036269, decoder SINDy loss  ratio: 0.393358\n",
      "Epoch 12\n",
      "   training loss 0.01224339660257101, (0.0122427475, 0.003292632, 0.0043608276, 0.021349788)\n",
      "   validation loss 0.014951974153518677, (0.01495119, 0.004066218, 0.005705964, 0.021349788)\n",
      "decoder loss ratio: 0.031191, decoder SINDy loss  ratio: 0.364648\n",
      "Epoch 13\n",
      "   training loss 0.00986571330577135, (0.009865092, 0.0030702401, 0.00415881, 0.020442607)\n",
      "   validation loss 0.012516596354544163, (0.012515864, 0.003614969, 0.00527328, 0.020442607)\n",
      "decoder loss ratio: 0.026110, decoder SINDy loss  ratio: 0.336997\n",
      "Epoch 14\n",
      "   training loss 0.007591805886477232, (0.0075912224, 0.0029355215, 0.0038291118, 0.02009186)\n",
      "   validation loss 0.010238947346806526, (0.010238257, 0.003451163, 0.0048858104, 0.02009186)\n",
      "decoder loss ratio: 0.021359, decoder SINDy loss  ratio: 0.312235\n",
      "Epoch 15\n",
      "   training loss 0.0057997144758701324, (0.005799162, 0.0027968807, 0.0035323098, 0.019863507)\n",
      "   validation loss 0.008384215645492077, (0.008383558, 0.0033099197, 0.0045942855, 0.019863507)\n",
      "decoder loss ratio: 0.017490, decoder SINDy loss  ratio: 0.293605\n",
      "Epoch 16\n",
      "   training loss 0.004720362834632397, (0.0047198366, 0.0027257765, 0.0032946933, 0.019660573)\n",
      "   validation loss 0.007190329022705555, (0.0071896934, 0.0031023198, 0.004390356, 0.019660573)\n",
      "decoder loss ratio: 0.014999, decoder SINDy loss  ratio: 0.280572\n",
      "Epoch 17\n",
      "   training loss 0.004042219370603561, (0.0040417155, 0.0026924426, 0.0031170668, 0.019242002)\n",
      "   validation loss 0.006394237279891968, (0.0063936207, 0.0029272325, 0.0042442908, 0.019242002)\n",
      "decoder loss ratio: 0.013338, decoder SINDy loss  ratio: 0.271238\n",
      "Epoch 18\n",
      "   training loss 0.003583687823265791, (0.0035832021, 0.0027223674, 0.0029737446, 0.018846137)\n",
      "   validation loss 0.005809602327644825, (0.0058090026, 0.0028168273, 0.0041135442, 0.018846137)\n",
      "decoder loss ratio: 0.012119, decoder SINDy loss  ratio: 0.262882\n",
      "Epoch 19\n",
      "   training loss 0.0033239375334233046, (0.0033234698, 0.0027942676, 0.0028332646, 0.018448811)\n",
      "   validation loss 0.0054068672470748425, (0.0054062842, 0.0027823525, 0.003984806, 0.018448811)\n",
      "decoder loss ratio: 0.011278, decoder SINDy loss  ratio: 0.254655\n",
      "Epoch 20\n",
      "   training loss 0.0031472689006477594, (0.0031468174, 0.0028654027, 0.0026980932, 0.018154055)\n",
      "   validation loss 0.005099857226014137, (0.005099289, 0.0027899842, 0.0038628709, 0.018154055)\n",
      "decoder loss ratio: 0.010638, decoder SINDy loss  ratio: 0.246863\n",
      "Epoch 21\n",
      "   training loss 0.0029996654484421015, (0.002999228, 0.002937224, 0.002580292, 0.017945064)\n",
      "   validation loss 0.0048529235646128654, (0.004852369, 0.0028174433, 0.003752963, 0.017945064)\n",
      "decoder loss ratio: 0.010123, decoder SINDy loss  ratio: 0.239839\n",
      "Epoch 22\n",
      "   training loss 0.002883489476516843, (0.0028830674, 0.002954195, 0.0024550343, 0.017660236)\n",
      "   validation loss 0.004652485251426697, (0.004651945, 0.0028282804, 0.0036374906, 0.017660236)\n",
      "decoder loss ratio: 0.009705, decoder SINDy loss  ratio: 0.232459\n",
      "Epoch 23\n",
      "   training loss 0.002797019900754094, (0.0027966115, 0.0029568553, 0.0023337821, 0.017513458)\n",
      "   validation loss 0.004487736616283655, (0.004487209, 0.002839859, 0.00352551, 0.017513458)\n",
      "decoder loss ratio: 0.009361, decoder SINDy loss  ratio: 0.225303\n",
      "Epoch 24\n",
      "   training loss 0.002722713630646467, (0.0027223164, 0.0029286298, 0.0022282447, 0.017448273)\n",
      "   validation loss 0.004347330890595913, (0.004346814, 0.0028381213, 0.0034213078, 0.017448273)\n",
      "decoder loss ratio: 0.009068, decoder SINDy loss  ratio: 0.218644\n",
      "Epoch 25\n",
      "   training loss 0.0026402012445032597, (0.0026398161, 0.0028647978, 0.0021175658, 0.017342707)\n",
      "   validation loss 0.004218380432575941, (0.0042178743, 0.0028458748, 0.0033273657, 0.017342707)\n",
      "decoder loss ratio: 0.008799, decoder SINDy loss  ratio: 0.212640\n",
      "Epoch 26\n",
      "   training loss 0.00255118147470057, (0.0025508045, 0.0028232262, 0.0020448002, 0.017263139)\n",
      "   validation loss 0.004094019532203674, (0.0040935213, 0.0028685033, 0.00325509, 0.017263139)\n",
      "decoder loss ratio: 0.008540, decoder SINDy loss  ratio: 0.208021\n",
      "Epoch 27\n",
      "   training loss 0.0024575090501457453, (0.0024571407, 0.0027689196, 0.0019623789, 0.017199596)\n",
      "   validation loss 0.003955433610826731, (0.0039549437, 0.0029091907, 0.003179281, 0.017199596)\n",
      "decoder loss ratio: 0.008251, decoder SINDy loss  ratio: 0.203177\n",
      "Epoch 28\n",
      "   training loss 0.002315881662070751, (0.0023155208, 0.0027481827, 0.001895476, 0.017133098)\n",
      "   validation loss 0.0037524010986089706, (0.003751919, 0.0029836206, 0.0031079585, 0.017133098)\n",
      "decoder loss ratio: 0.007827, decoder SINDy loss  ratio: 0.198619\n",
      "Epoch 29\n",
      "   training loss 0.002090597990900278, (0.002090244, 0.002702389, 0.0018247357, 0.017143065)\n",
      "   validation loss 0.003473300486803055, (0.0034728264, 0.0030649472, 0.0030263327, 0.017143065)\n",
      "decoder loss ratio: 0.007245, decoder SINDy loss  ratio: 0.193402\n",
      "Epoch 30\n",
      "   training loss 0.0018366639269515872, (0.001836312, 0.0027092788, 0.0017996195, 0.01719683)\n",
      "   validation loss 0.0032053207978606224, (0.0032048519, 0.0032253186, 0.0029675222, 0.01719683)\n",
      "decoder loss ratio: 0.006686, decoder SINDy loss  ratio: 0.189644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "   training loss 0.0016334877582266927, (0.0016331384, 0.002683928, 0.0017619537, 0.017311892)\n",
      "   validation loss 0.002950007561594248, (0.0029495426, 0.0034150444, 0.002917429, 0.017311892)\n",
      "decoder loss ratio: 0.006153, decoder SINDy loss  ratio: 0.186443\n",
      "Epoch 32\n",
      "   training loss 0.0014715883880853653, (0.0014712412, 0.0026351402, 0.0017373576, 0.017347202)\n",
      "   validation loss 0.0027098844293504953, (0.0027094223, 0.0036034689, 0.0028880048, 0.017347202)\n",
      "decoder loss ratio: 0.005652, decoder SINDy loss  ratio: 0.184562\n",
      "Epoch 33\n",
      "   training loss 0.0013592859031632543, (0.0013589419, 0.002576152, 0.0017148028, 0.017250264)\n",
      "   validation loss 0.0025106805842369795, (0.0025102212, 0.0037836365, 0.0028682186, 0.017250264)\n",
      "decoder loss ratio: 0.005237, decoder SINDy loss  ratio: 0.183298\n",
      "Epoch 34\n",
      "   training loss 0.00127892242744565, (0.0012785788, 0.0025363506, 0.0017086302, 0.017277883)\n",
      "   validation loss 0.0023451673332601786, (0.0023447084, 0.0039459243, 0.0028611114, 0.017277883)\n",
      "decoder loss ratio: 0.004891, decoder SINDy loss  ratio: 0.182844\n",
      "Epoch 35\n",
      "   training loss 0.0011123273288831115, (0.0011119815, 0.002532931, 0.0017264865, 0.0173275)\n",
      "   validation loss 0.002111253095790744, (0.0021107954, 0.0040324545, 0.0028455758, 0.0173275)\n",
      "decoder loss ratio: 0.004403, decoder SINDy loss  ratio: 0.181851\n",
      "Epoch 36\n",
      "   training loss 0.0010319554712623358, (0.0010316105, 0.0024753397, 0.0017172778, 0.01732537)\n",
      "   validation loss 0.0019363064784556627, (0.0019358508, 0.0040857545, 0.0028247335, 0.01732537)\n",
      "decoder loss ratio: 0.004039, decoder SINDy loss  ratio: 0.180519\n",
      "Epoch 37\n",
      "   training loss 0.0009720416273921728, (0.00097169646, 0.0024604655, 0.0017273691, 0.017241823)\n",
      "   validation loss 0.0017753230640664697, (0.0017748708, 0.004118513, 0.0027988858, 0.017241823)\n",
      "decoder loss ratio: 0.003703, decoder SINDy loss  ratio: 0.178867\n",
      "Epoch 38\n",
      "   training loss 0.0009880781872197986, (0.0009877352, 0.0023907423, 0.0016999135, 0.017295571)\n",
      "   validation loss 0.0016994531033560634, (0.0016990036, 0.0041045835, 0.0027643573, 0.017295571)\n",
      "decoder loss ratio: 0.003544, decoder SINDy loss  ratio: 0.176660\n",
      "Epoch 39\n",
      "   training loss 0.0009384158183820546, (0.00093807315, 0.0023625663, 0.0016982844, 0.017282717)\n",
      "   validation loss 0.0016382265603169799, (0.00163778, 0.004056466, 0.0027367326, 0.017282717)\n",
      "decoder loss ratio: 0.003417, decoder SINDy loss  ratio: 0.174895\n",
      "Epoch 40\n",
      "   training loss 0.0010610135504975915, (0.0010606705, 0.0023575176, 0.0017053245, 0.01725836)\n",
      "   validation loss 0.0017636172706261277, (0.0017631738, 0.0040229596, 0.002709429, 0.01725836)\n",
      "decoder loss ratio: 0.003678, decoder SINDy loss  ratio: 0.173150\n",
      "Epoch 41\n",
      "   training loss 0.0008444996201433241, (0.0008441621, 0.0022639886, 0.0016631414, 0.017123612)\n",
      "   validation loss 0.001509758410975337, (0.0015093188, 0.004049371, 0.0026829434, 0.017123612)\n",
      "decoder loss ratio: 0.003149, decoder SINDy loss  ratio: 0.171458\n",
      "Epoch 42\n",
      "   training loss 0.0007608867017552257, (0.00076055113, 0.0021913205, 0.0016380816, 0.01717434)\n",
      "   validation loss 0.0013963212259113789, (0.0013958842, 0.0040089567, 0.0026535809, 0.01717434)\n",
      "decoder loss ratio: 0.002912, decoder SINDy loss  ratio: 0.169581\n",
      "Epoch 43\n",
      "   training loss 0.0007720176363363862, (0.0007716832, 0.002139453, 0.0016287386, 0.017159453)\n",
      "   validation loss 0.0013895818265154958, (0.0013891468, 0.003940418, 0.00263431, 0.017159453)\n",
      "decoder loss ratio: 0.002898, decoder SINDy loss  ratio: 0.168350\n",
      "Epoch 44\n",
      "   training loss 0.0009788140887394547, (0.0009784782, 0.0021424098, 0.0016454008, 0.017137866)\n",
      "   validation loss 0.0015994514105841517, (0.0015990178, 0.0038701978, 0.0026227569, 0.017137866)\n",
      "decoder loss ratio: 0.003336, decoder SINDy loss  ratio: 0.167611\n",
      "Epoch 45\n",
      "   training loss 0.0009941831231117249, (0.0009938511, 0.0020773616, 0.0016169085, 0.01703498)\n",
      "   validation loss 0.0015320359962061048, (0.0015316063, 0.0038614657, 0.002593448, 0.01703498)\n",
      "decoder loss ratio: 0.003195, decoder SINDy loss  ratio: 0.165738\n",
      "Epoch 46\n",
      "   training loss 0.0006189103005453944, (0.0006185827, 0.0019741843, 0.0015616221, 0.017141696)\n",
      "   validation loss 0.001097960746847093, (0.0010975361, 0.0038209937, 0.0025333236, 0.017141696)\n",
      "decoder loss ratio: 0.002290, decoder SINDy loss  ratio: 0.161896\n",
      "Epoch 47\n",
      "   training loss 0.0007395463762804866, (0.0007392202, 0.0019462854, 0.001559181, 0.017028296)\n",
      "   validation loss 0.0012003099545836449, (0.0011998882, 0.0037659872, 0.0025151104, 0.017028296)\n",
      "decoder loss ratio: 0.002503, decoder SINDy loss  ratio: 0.160732\n",
      "Epoch 48\n",
      "   training loss 0.000905142049305141, (0.0009048177, 0.0019229151, 0.0015446646, 0.016985012)\n",
      "   validation loss 0.0013192672049626708, (0.0013188467, 0.0037207243, 0.0025067215, 0.016985012)\n",
      "decoder loss ratio: 0.002751, decoder SINDy loss  ratio: 0.160196\n",
      "Epoch 49\n",
      "   training loss 0.0007681949064135551, (0.0007678714, 0.0019029015, 0.0015397756, 0.016954627)\n",
      "   validation loss 0.001101930858567357, (0.0011015123, 0.003738219, 0.0024896746, 0.016954627)\n",
      "decoder loss ratio: 0.002298, decoder SINDy loss  ratio: 0.159106\n",
      "Epoch 50\n",
      "   training loss 0.0006377518875524402, (0.0006374307, 0.0018791053, 0.0015152278, 0.016969806)\n",
      "   validation loss 0.0010016257874667645, (0.0010012107, 0.003669812, 0.0024545183, 0.016969806)\n",
      "decoder loss ratio: 0.002089, decoder SINDy loss  ratio: 0.156860\n",
      "Epoch 51\n",
      "   training loss 0.0007534099277108908, (0.0007530897, 0.0018492271, 0.0015137802, 0.016882073)\n",
      "   validation loss 0.0010871433187276125, (0.0010867296, 0.0036803125, 0.002448969, 0.016882073)\n",
      "decoder loss ratio: 0.002267, decoder SINDy loss  ratio: 0.156505\n",
      "Epoch 52\n",
      "   training loss 0.0007410001708194613, (0.00074068224, 0.0018337775, 0.001496942, 0.016820008)\n",
      "   validation loss 0.0010284801246598363, (0.0010280693, 0.0036636882, 0.0024260264, 0.016820008)\n",
      "decoder loss ratio: 0.002145, decoder SINDy loss  ratio: 0.155039\n",
      "Epoch 53\n",
      "   training loss 0.0007578413933515549, (0.000757522, 0.001843081, 0.0015075547, 0.01686096)\n",
      "   validation loss 0.0010031615383923054, (0.0010027513, 0.0036606933, 0.0024171753, 0.01686096)\n",
      "decoder loss ratio: 0.002092, decoder SINDy loss  ratio: 0.154473\n",
      "Epoch 54\n",
      "   training loss 0.0006007419433444738, (0.0006004261, 0.001812983, 0.001482171, 0.016762445)\n",
      "   validation loss 0.0008573043742217124, (0.00085689797, 0.0036258814, 0.0023876273, 0.016762445)\n",
      "decoder loss ratio: 0.001788, decoder SINDy loss  ratio: 0.152585\n",
      "Epoch 55\n",
      "   training loss 0.0006028265925124288, (0.0006025116, 0.0018064524, 0.00147769, 0.016723825)\n",
      "   validation loss 0.0008539509144611657, (0.00085354596, 0.003596275, 0.0023770905, 0.016723825)\n",
      "decoder loss ratio: 0.001781, decoder SINDy loss  ratio: 0.151912\n",
      "Epoch 56\n",
      "   training loss 0.0005697141168639064, (0.00056939997, 0.001789798, 0.001464393, 0.016770499)\n",
      "   validation loss 0.0008213688270188868, (0.00082096626, 0.0035163907, 0.0023484302, 0.016770499)\n",
      "decoder loss ratio: 0.001713, decoder SINDy loss  ratio: 0.150080\n",
      "Epoch 57\n",
      "   training loss 0.0005469357711263001, (0.00054662407, 0.0017722991, 0.0014519241, 0.016652256)\n",
      "   validation loss 0.0008012273465283215, (0.0008008271, 0.0034907567, 0.0023371163, 0.016652256)\n",
      "decoder loss ratio: 0.001671, decoder SINDy loss  ratio: 0.149357\n",
      "Epoch 58\n",
      "   training loss 0.0005015211645513773, (0.0005012107, 0.0017526733, 0.0014412664, 0.01663603)\n",
      "   validation loss 0.0007585713756270707, (0.00075817376, 0.0034568326, 0.002312759, 0.01663603)\n",
      "decoder loss ratio: 0.001582, decoder SINDy loss  ratio: 0.147800\n",
      "Epoch 59\n",
      "   training loss 0.00046615369501523674, (0.00046584394, 0.0017270815, 0.0014349979, 0.016624153)\n",
      "   validation loss 0.000724129204172641, (0.0007237336, 0.0034029686, 0.0022931688, 0.016624153)\n",
      "decoder loss ratio: 0.001510, decoder SINDy loss  ratio: 0.146548\n",
      "Epoch 60\n",
      "   training loss 0.0004309573851060122, (0.0004306496, 0.001700703, 0.0014236112, 0.016543543)\n",
      "   validation loss 0.0006874425453133881, (0.00068704924, 0.003376633, 0.0022788565, 0.016543543)\n",
      "decoder loss ratio: 0.001433, decoder SINDy loss  ratio: 0.145634\n",
      "Epoch 61\n",
      "   training loss 0.0004137864743825048, (0.00041348144, 0.0016690525, 0.0014067076, 0.016438259)\n",
      "   validation loss 0.0006630141288042068, (0.00066262373, 0.0033363965, 0.002260246, 0.016438259)\n",
      "decoder loss ratio: 0.001382, decoder SINDy loss  ratio: 0.144444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62\n",
      "   training loss 0.0004005418159067631, (0.0004002385, 0.0016408786, 0.0013921118, 0.016411036)\n",
      "   validation loss 0.0006430043140426278, (0.0006426162, 0.00330865, 0.0022405083, 0.016411036)\n",
      "decoder loss ratio: 0.001341, decoder SINDy loss  ratio: 0.143183\n",
      "Epoch 63\n",
      "   training loss 0.0004049435956403613, (0.00040464065, 0.0016130977, 0.0013874376, 0.016420456)\n",
      "   validation loss 0.0006324643618427217, (0.0006320775, 0.0032793132, 0.0022266388, 0.016420456)\n",
      "decoder loss ratio: 0.001319, decoder SINDy loss  ratio: 0.142297\n",
      "Epoch 64\n",
      "   training loss 0.00043819600250571966, (0.00043789533, 0.0015707975, 0.0013660123, 0.016405582)\n",
      "   validation loss 0.0006410006899386644, (0.0006406173, 0.0031920155, 0.0021935932, 0.016405582)\n",
      "decoder loss ratio: 0.001336, decoder SINDy loss  ratio: 0.140185\n",
      "Epoch 65\n",
      "   training loss 0.0005424459232017398, (0.0005421475, 0.0015432759, 0.0013450837, 0.016388975)\n",
      "   validation loss 0.0006732106558047235, (0.0006728297, 0.0031547344, 0.0021704657, 0.016388975)\n",
      "decoder loss ratio: 0.001404, decoder SINDy loss  ratio: 0.138707\n",
      "Epoch 66\n",
      "   training loss 0.0005823991377837956, (0.00058210175, 0.0015255861, 0.0013408421, 0.016327076)\n",
      "   validation loss 0.0006433194503188133, (0.00064294133, 0.0031504878, 0.002148196, 0.016327076)\n",
      "decoder loss ratio: 0.001341, decoder SINDy loss  ratio: 0.137284\n",
      "Epoch 67\n",
      "   training loss 0.00035545561695471406, (0.00035516007, 0.0015272695, 0.0013292931, 0.01626235)\n",
      "   validation loss 0.0005914171924814582, (0.0005910406, 0.0031204496, 0.0021397986, 0.01626235)\n",
      "decoder loss ratio: 0.001233, decoder SINDy loss  ratio: 0.136747\n",
      "Epoch 68\n",
      "   training loss 0.0003021668817382306, (0.0003018718, 0.0014994568, 0.0013249881, 0.016258772)\n",
      "   validation loss 0.0005338366609066725, (0.00053346046, 0.0030821012, 0.0021363432, 0.016258772)\n",
      "decoder loss ratio: 0.001113, decoder SINDy loss  ratio: 0.136526\n",
      "Epoch 69\n",
      "   training loss 0.0006471622036769986, (0.00064686354, 0.0014986858, 0.001362245, 0.016248576)\n",
      "   validation loss 0.000841622066218406, (0.00084123947, 0.003206461, 0.0022011367, 0.016248576)\n",
      "decoder loss ratio: 0.001755, decoder SINDy loss  ratio: 0.140667\n",
      "Epoch 70\n",
      "   training loss 0.0003307292645331472, (0.00033042772, 0.0015650945, 0.0013779858, 0.016372824)\n",
      "   validation loss 0.0005473271012306213, (0.0005469438, 0.0032083935, 0.0021955944, 0.016372824)\n",
      "decoder loss ratio: 0.001141, decoder SINDy loss  ratio: 0.140313\n",
      "Epoch 71\n",
      "   training loss 0.00029470553272403777, (0.00029440795, 0.00149209, 0.0013331128, 0.016425792)\n",
      "   validation loss 0.0004203396092634648, (0.00041996047, 0.0031490219, 0.0021488785, 0.016425792)\n",
      "decoder loss ratio: 0.000876, decoder SINDy loss  ratio: 0.137327\n",
      "Epoch 72\n",
      "   training loss 0.00037869461812078953, (0.0003783983, 0.0014667994, 0.0013254533, 0.016376702)\n",
      "   validation loss 0.0005546740721911192, (0.00055429735, 0.0030528968, 0.0021297592, 0.016376702)\n",
      "decoder loss ratio: 0.001156, decoder SINDy loss  ratio: 0.136105\n",
      "Epoch 73\n",
      "   training loss 0.00029139648540876806, (0.00029110143, 0.0014607357, 0.0013219984, 0.016287612)\n",
      "   validation loss 0.0004993073525838554, (0.0004989327, 0.0029969644, 0.0021173318, 0.016287612)\n",
      "decoder loss ratio: 0.001041, decoder SINDy loss  ratio: 0.135311\n",
      "Epoch 74\n",
      "   training loss 0.00034389368374831975, (0.0003435994, 0.0014370302, 0.0013161248, 0.016270272)\n",
      "   validation loss 0.000545542046893388, (0.00054516835, 0.0029579373, 0.0021099919, 0.016270272)\n",
      "decoder loss ratio: 0.001137, decoder SINDy loss  ratio: 0.134842\n",
      "Epoch 75\n",
      "   training loss 0.0002475541259627789, (0.00024726105, 0.0014313076, 0.0013103995, 0.016204262)\n",
      "   validation loss 0.0004499262722674757, (0.00044955366, 0.0029770732, 0.0021055902, 0.016204262)\n",
      "decoder loss ratio: 0.000938, decoder SINDy loss  ratio: 0.134561\n",
      "Epoch 76\n",
      "   training loss 0.00024276471231132746, (0.00024247267, 0.0014149491, 0.0012988999, 0.016215608)\n",
      "   validation loss 0.0004623265704140067, (0.00046195384, 0.0029335269, 0.0021056999, 0.016215608)\n",
      "decoder loss ratio: 0.000964, decoder SINDy loss  ratio: 0.134568\n",
      "Epoch 77\n",
      "   training loss 0.00027598999440670013, (0.00027569817, 0.0013999959, 0.0012937034, 0.016245913)\n",
      "   validation loss 0.000444077915744856, (0.00044370713, 0.0029300195, 0.0020833053, 0.016245913)\n",
      "decoder loss ratio: 0.000926, decoder SINDy loss  ratio: 0.133137\n",
      "Epoch 78\n",
      "   training loss 0.00031545397359877825, (0.00031516165, 0.0014013381, 0.0012922324, 0.016308904)\n",
      "   validation loss 0.0005079120164737105, (0.0005075415, 0.0028833563, 0.002074152, 0.016308904)\n",
      "decoder loss ratio: 0.001059, decoder SINDy loss  ratio: 0.132552\n",
      "Epoch 79\n",
      "   training loss 0.00025547962286509573, (0.0002551886, 0.0014068927, 0.0012938816, 0.016161898)\n",
      "   validation loss 0.0004330045485403389, (0.00043263374, 0.0029382177, 0.002092088, 0.016161898)\n",
      "decoder loss ratio: 0.000903, decoder SINDy loss  ratio: 0.133698\n",
      "Epoch 80\n",
      "   training loss 0.00025622188695706427, (0.00025592992, 0.0014078341, 0.0012994384, 0.016201433)\n",
      "   validation loss 0.00043482723413035274, (0.00043445517, 0.0029246754, 0.002100327, 0.016201433)\n",
      "decoder loss ratio: 0.000906, decoder SINDy loss  ratio: 0.134225\n",
      "Epoch 81\n",
      "   training loss 0.0002735950401984155, (0.00027330322, 0.0013905686, 0.0012924848, 0.016258253)\n",
      "   validation loss 0.00042409615707583725, (0.00042372796, 0.0028829365, 0.0020561158, 0.016258253)\n",
      "decoder loss ratio: 0.000884, decoder SINDy loss  ratio: 0.131399\n",
      "Epoch 82\n",
      "   training loss 0.00037942532799206674, (0.00037913537, 0.0013848118, 0.0012787676, 0.01620695)\n",
      "   validation loss 0.0005197757272981107, (0.0005194088, 0.002899541, 0.0020488894, 0.01620695)\n",
      "decoder loss ratio: 0.001084, decoder SINDy loss  ratio: 0.130937\n",
      "Epoch 83\n",
      "   training loss 0.00023444514954462647, (0.00023415289, 0.0014088094, 0.0012998083, 0.016227758)\n",
      "   validation loss 0.00044253526721149683, (0.00044216347, 0.0028805635, 0.002095186, 0.016227758)\n",
      "decoder loss ratio: 0.000922, decoder SINDy loss  ratio: 0.133896\n",
      "Epoch 84\n",
      "   training loss 0.0002045609289780259, (0.0002042687, 0.0013985373, 0.0012875923, 0.01634798)\n",
      "   validation loss 0.00032418029149994254, (0.00032381096, 0.002913398, 0.002058454, 0.01634798)\n",
      "decoder loss ratio: 0.000676, decoder SINDy loss  ratio: 0.131549\n",
      "Epoch 85\n",
      "   training loss 0.00022192629694472998, (0.00022163606, 0.0013734145, 0.001274185, 0.01628248)\n",
      "   validation loss 0.0003708429867401719, (0.00037047654, 0.0028295228, 0.0020361193, 0.01628248)\n",
      "decoder loss ratio: 0.000773, decoder SINDy loss  ratio: 0.130121\n",
      "Epoch 86\n",
      "   training loss 0.00023327022790908813, (0.00023298083, 0.0013695526, 0.0012706206, 0.016233295)\n",
      "   validation loss 0.00041339368908666074, (0.0004130296, 0.0027471746, 0.002017607, 0.016233295)\n",
      "decoder loss ratio: 0.000862, decoder SINDy loss  ratio: 0.128938\n",
      "Epoch 87\n",
      "   training loss 0.00020077404042240232, (0.00020048696, 0.0013436273, 0.0012565295, 0.016142419)\n",
      "   validation loss 0.0003448136558290571, (0.00034444846, 0.0027866843, 0.0020379084, 0.016142419)\n",
      "decoder loss ratio: 0.000719, decoder SINDy loss  ratio: 0.130236\n",
      "Epoch 88\n",
      "   training loss 0.0002878435770981014, (0.0002875513, 0.0014068959, 0.0013076001, 0.016153524)\n",
      "   validation loss 0.0005264239734970033, (0.00052605424, 0.0027832927, 0.0020822263, 0.016153524)\n",
      "decoder loss ratio: 0.001097, decoder SINDy loss  ratio: 0.133068\n",
      "Epoch 89\n",
      "   training loss 0.00020939481328241527, (0.00020910472, 0.0013708066, 0.0012699824, 0.016309587)\n",
      "   validation loss 0.0003279906522948295, (0.00032762432, 0.002822728, 0.002032402, 0.016309587)\n",
      "decoder loss ratio: 0.000683, decoder SINDy loss  ratio: 0.129884\n",
      "Epoch 90\n",
      "   training loss 0.00018627577810548246, (0.00018598721, 0.0013691225, 0.0012659609, 0.016196948)\n",
      "   validation loss 0.0003267746069468558, (0.00032641034, 0.0028099064, 0.002023041, 0.016196948)\n",
      "decoder loss ratio: 0.000681, decoder SINDy loss  ratio: 0.129285\n",
      "Epoch 91\n",
      "   training loss 0.00018719375657383353, (0.00018690649, 0.0013733958, 0.0012671428, 0.016055554)\n",
      "   validation loss 0.0003390682686585933, (0.00033870444, 0.0027391065, 0.0020325668, 0.016055554)\n",
      "decoder loss ratio: 0.000707, decoder SINDy loss  ratio: 0.129894\n",
      "Epoch 92\n",
      "   training loss 0.00015964973135851324, (0.00015936319, 0.0013647181, 0.0012530051, 0.016123956)\n",
      "   validation loss 0.000312108633806929, (0.0003117469, 0.002750207, 0.0020049554, 0.016123956)\n",
      "decoder loss ratio: 0.000650, decoder SINDy loss  ratio: 0.128130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93\n",
      "   training loss 0.0003399705747142434, (0.0003396821, 0.001380661, 0.0012647054, 0.016203502)\n",
      "   validation loss 0.0005037631490267813, (0.0005033985, 0.0028320984, 0.0020263437, 0.016203502)\n",
      "decoder loss ratio: 0.001050, decoder SINDy loss  ratio: 0.129497\n",
      "Epoch 94\n",
      "   training loss 0.00018524059851188213, (0.00018494835, 0.0014109627, 0.001298098, 0.016244145)\n",
      "   validation loss 0.0003785214794334024, (0.0003781538, 0.0027878096, 0.0020525407, 0.016244145)\n",
      "decoder loss ratio: 0.000789, decoder SINDy loss  ratio: 0.131171\n",
      "Epoch 95\n",
      "   training loss 0.00016503449296578765, (0.00016474638, 0.0013412753, 0.0012460273, 0.016350707)\n",
      "   validation loss 0.00030719494679942727, (0.0003068306, 0.0027704842, 0.0020084532, 0.016350707)\n",
      "decoder loss ratio: 0.000640, decoder SINDy loss  ratio: 0.128353\n",
      "Epoch 96\n",
      "   training loss 0.00017854210454970598, (0.0001782547, 0.0013519702, 0.0012475624, 0.016264807)\n",
      "   validation loss 0.0003393929509911686, (0.00033903084, 0.002763454, 0.001994363, 0.016264807)\n",
      "decoder loss ratio: 0.000707, decoder SINDy loss  ratio: 0.127453\n",
      "Epoch 97\n",
      "   training loss 0.00014433791511692107, (0.00014405118, 0.0013615222, 0.0012515008, 0.016158292)\n",
      "   validation loss 0.0002863494155462831, (0.0002859876, 0.0026972422, 0.0020022169, 0.016158292)\n",
      "decoder loss ratio: 0.000597, decoder SINDy loss  ratio: 0.127955\n",
      "Epoch 98\n",
      "   training loss 0.00019265340233687311, (0.0001923667, 0.0013612495, 0.0012463467, 0.016206648)\n",
      "   validation loss 0.00035162203130312264, (0.000351262, 0.0026511778, 0.0019795438, 0.016206648)\n",
      "decoder loss ratio: 0.000733, decoder SINDy loss  ratio: 0.126506\n",
      "Epoch 99\n",
      "   training loss 0.0003745901631191373, (0.00037430262, 0.0014003679, 0.0012607346, 0.016146854)\n",
      "   validation loss 0.000550385273527354, (0.0005500233, 0.0027911726, 0.0020055047, 0.016146854)\n",
      "decoder loss ratio: 0.001147, decoder SINDy loss  ratio: 0.128165\n",
      "Epoch 100\n",
      "   training loss 0.00020856618357356638, (0.00020827711, 0.0013967777, 0.001273336, 0.016174046)\n",
      "   validation loss 0.0003854040114674717, (0.00038503966, 0.0027528552, 0.0020262727, 0.016174046)\n",
      "decoder loss ratio: 0.000803, decoder SINDy loss  ratio: 0.129492\n",
      "Epoch 101\n",
      "   training loss 0.00014066568110138178, (0.00014037902, 0.0013691122, 0.0012432374, 0.016234288)\n",
      "   validation loss 0.0002820882364176214, (0.00028172653, 0.0027566298, 0.001993593, 0.016234288)\n",
      "decoder loss ratio: 0.000588, decoder SINDy loss  ratio: 0.127404\n",
      "Epoch 102\n",
      "   training loss 0.00017405505059286952, (0.0001737703, 0.0013606547, 0.0012303245, 0.016172042)\n",
      "   validation loss 0.00036460900446400046, (0.00036425056, 0.002694694, 0.001967185, 0.016172042)\n",
      "decoder loss ratio: 0.000760, decoder SINDy loss  ratio: 0.125716\n",
      "Epoch 103\n",
      "   training loss 0.00015202624490484595, (0.00015174154, 0.0013577123, 0.0012298864, 0.016171494)\n",
      "   validation loss 0.00033121503656730056, (0.00033085808, 0.0026478015, 0.0019525393, 0.016171494)\n",
      "decoder loss ratio: 0.000690, decoder SINDy loss  ratio: 0.124780\n",
      "Epoch 104\n",
      "   training loss 0.00016187835717573762, (0.00016159407, 0.0013650632, 0.0012306442, 0.016121512)\n",
      "   validation loss 0.00032590559567324817, (0.00032554788, 0.0026268712, 0.0019650282, 0.016121512)\n",
      "decoder loss ratio: 0.000679, decoder SINDy loss  ratio: 0.125578\n",
      "Epoch 105\n",
      "   training loss 0.00018218335753772408, (0.00018189944, 0.0013549976, 0.0012256785, 0.016135653)\n",
      "   validation loss 0.0003668442368507385, (0.00036648384, 0.00270219, 0.0019904997, 0.016135653)\n",
      "decoder loss ratio: 0.000765, decoder SINDy loss  ratio: 0.127206\n",
      "Epoch 106\n",
      "   training loss 0.0002485728182364255, (0.00024828778, 0.0014252478, 0.0012301514, 0.016202716)\n",
      "   validation loss 0.0004005347436759621, (0.00040017514, 0.0027403813, 0.0019757184, 0.016202716)\n",
      "decoder loss ratio: 0.000835, decoder SINDy loss  ratio: 0.126261\n",
      "Epoch 107\n",
      "   training loss 0.00013852091797161847, (0.0001382371, 0.0013997223, 0.0012271907, 0.016110001)\n",
      "   validation loss 0.00027836859226226807, (0.00027801044, 0.002741086, 0.0019705417, 0.016110001)\n",
      "decoder loss ratio: 0.000580, decoder SINDy loss  ratio: 0.125930\n",
      "Epoch 108\n",
      "   training loss 0.00011278413148829713, (0.00011249993, 0.0013902299, 0.0012320653, 0.016099373)\n",
      "   validation loss 0.0002902934211306274, (0.00028993704, 0.00269487, 0.0019537695, 0.016099373)\n",
      "decoder loss ratio: 0.000605, decoder SINDy loss  ratio: 0.124859\n",
      "Epoch 109\n",
      "   training loss 0.00020031025633215904, (0.0002000291, 0.0013637049, 0.0012058518, 0.016056037)\n",
      "   validation loss 0.0004189278988633305, (0.00041857405, 0.002665647, 0.0019326825, 0.016056037)\n",
      "decoder loss ratio: 0.000873, decoder SINDy loss  ratio: 0.123511\n",
      "Epoch 110\n",
      "   training loss 0.00023027582210488617, (0.00022999429, 0.0013501059, 0.0011923823, 0.016229428)\n",
      "   validation loss 0.00037861670716665685, (0.00037826013, 0.0027105892, 0.0019429969, 0.016229428)\n",
      "decoder loss ratio: 0.000789, decoder SINDy loss  ratio: 0.124170\n",
      "Epoch 111\n",
      "   training loss 0.00012200056517031044, (0.00012171824, 0.001375664, 0.0012046532, 0.016185723)\n",
      "   validation loss 0.00026895286282524467, (0.00026859634, 0.0026871394, 0.0019467758, 0.016185723)\n",
      "decoder loss ratio: 0.000560, decoder SINDy loss  ratio: 0.124412\n",
      "Epoch 112\n",
      "   training loss 0.00013099430361762643, (0.00013071416, 0.0013754881, 0.0011921299, 0.016092245)\n",
      "   validation loss 0.00023590809723827988, (0.00023555425, 0.002666831, 0.0019291908, 0.016092245)\n",
      "decoder loss ratio: 0.000491, decoder SINDy loss  ratio: 0.123288\n",
      "Epoch 113\n",
      "   training loss 0.00022208361770026386, (0.0002218014, 0.0013732961, 0.0012181948, 0.01604086)\n",
      "   validation loss 0.0003729682066477835, (0.0003726118, 0.0026896088, 0.001959962, 0.01604086)\n",
      "decoder loss ratio: 0.000777, decoder SINDy loss  ratio: 0.125254\n",
      "Epoch 114\n",
      "   training loss 0.00014598849520552903, (0.00014570708, 0.0013248952, 0.0012011456, 0.01613111)\n",
      "   validation loss 0.0003231203882023692, (0.00032276544, 0.002692148, 0.0019362598, 0.01613111)\n",
      "decoder loss ratio: 0.000673, decoder SINDy loss  ratio: 0.123740\n",
      "Epoch 115\n",
      "   training loss 0.00021784919954370707, (0.00021756947, 0.0013023554, 0.0011844249, 0.016128918)\n",
      "   validation loss 0.00047566756256856024, (0.0004753148, 0.0026932182, 0.0019148272, 0.016128918)\n",
      "decoder loss ratio: 0.000992, decoder SINDy loss  ratio: 0.122370\n",
      "Epoch 116\n",
      "   training loss 0.00017349333211313933, (0.00017321351, 0.0012839322, 0.0011776462, 0.016205303)\n",
      "   validation loss 0.00031138138729147613, (0.00031102757, 0.0026914487, 0.0019176563, 0.016205303)\n",
      "decoder loss ratio: 0.000649, decoder SINDy loss  ratio: 0.122551\n",
      "Epoch 117\n",
      "   training loss 0.00017294917779508978, (0.00017266697, 0.0013803636, 0.0012165079, 0.016054457)\n",
      "   validation loss 0.00028997345361858606, (0.00028961856, 0.0026999863, 0.0019435693, 0.016054457)\n",
      "decoder loss ratio: 0.000604, decoder SINDy loss  ratio: 0.124207\n",
      "Epoch 118\n",
      "   training loss 7.77786408434622e-05, (7.749694e-05, 0.0013552046, 0.0011998813, 0.016171785)\n",
      "   validation loss 0.00022663510753773153, (0.00022628151, 0.0026879436, 0.0019187796, 0.016171785)\n",
      "decoder loss ratio: 0.000472, decoder SINDy loss  ratio: 0.122622\n",
      "Epoch 119\n",
      "   training loss 0.00016282493015751243, (0.00016254578, 0.0013285113, 0.0011871995, 0.0160433)\n",
      "   validation loss 0.00039604376070201397, (0.00039569262, 0.0027226135, 0.001907154, 0.0160433)\n",
      "decoder loss ratio: 0.000825, decoder SINDy loss  ratio: 0.121880\n",
      "Epoch 120\n",
      "   training loss 0.0002289856201969087, (0.00022870721, 0.0013043704, 0.0011655567, 0.016184619)\n",
      "   validation loss 0.000314525852445513, (0.00031417323, 0.0027251272, 0.0019078259, 0.016184619)\n",
      "decoder loss ratio: 0.000655, decoder SINDy loss  ratio: 0.121922\n",
      "Epoch 121\n",
      "   training loss 0.0002823209506459534, (0.00028204138, 0.001253119, 0.0011772732, 0.016185408)\n",
      "   validation loss 0.0005041045369580388, (0.00050375017, 0.0026857024, 0.0019247717, 0.016185408)\n",
      "decoder loss ratio: 0.001051, decoder SINDy loss  ratio: 0.123005\n",
      "Epoch 122\n",
      "   training loss 0.00013832429249305278, (0.00013804241, 0.0013811773, 0.0012108046, 0.016079273)\n",
      "   validation loss 0.0002579919819254428, (0.00025763852, 0.0026710602, 0.001926626, 0.016079273)\n",
      "decoder loss ratio: 0.000537, decoder SINDy loss  ratio: 0.123124\n",
      "Epoch 123\n",
      "   training loss 0.0001117929132306017, (0.00011151342, 0.001340557, 0.0011763636, 0.016185183)\n",
      "   validation loss 0.00027277195476926863, (0.00027242088, 0.0026364846, 0.0018922861, 0.016185183)\n",
      "decoder loss ratio: 0.000568, decoder SINDy loss  ratio: 0.120929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124\n",
      "   training loss 0.0001751979871187359, (0.00017492141, 0.0012871854, 0.0011450204, 0.016206995)\n",
      "   validation loss 0.0003491000388748944, (0.00034874986, 0.0027069747, 0.0018810125, 0.016206995)\n",
      "decoder loss ratio: 0.000728, decoder SINDy loss  ratio: 0.120209\n",
      "Epoch 125\n",
      "   training loss 8.081541454885155e-05, (8.053539e-05, 0.0013659237, 0.0011808563, 0.01619332)\n",
      "   validation loss 0.000219969660975039, (0.00021961777, 0.0026947688, 0.0018995398, 0.01619332)\n",
      "decoder loss ratio: 0.000458, decoder SINDy loss  ratio: 0.121393\n",
      "Epoch 126\n",
      "   training loss 5.396838241722435e-05, (5.3688404e-05, 0.0013477448, 0.0011826743, 0.016171323)\n",
      "   validation loss 0.00017526275769341737, (0.00017491255, 0.0026780749, 0.0018849337, 0.016171323)\n",
      "decoder loss ratio: 0.000365, decoder SINDy loss  ratio: 0.120460\n",
      "Epoch 127\n",
      "   training loss 9.312549809692428e-05, (9.284823e-05, 0.0012802759, 0.0011602284, 0.016124392)\n",
      "   validation loss 0.0002555101236794144, (0.0002551613, 0.0026428462, 0.0018758266, 0.016124392)\n",
      "decoder loss ratio: 0.000532, decoder SINDy loss  ratio: 0.119878\n",
      "Epoch 128\n",
      "   training loss 0.0001324443583143875, (0.00013216712, 0.0013074932, 0.0011618832, 0.016105492)\n",
      "   validation loss 0.00029802569770254195, (0.00029767753, 0.002679718, 0.0018711725, 0.016105492)\n",
      "decoder loss ratio: 0.000621, decoder SINDy loss  ratio: 0.119580\n",
      "Epoch 129\n",
      "   training loss 0.0004963069804944098, (0.000496025, 0.0013539257, 0.0012092935, 0.016101645)\n",
      "   validation loss 0.0005569645436480641, (0.0005566098, 0.0027476219, 0.0019370072, 0.016101645)\n",
      "decoder loss ratio: 0.001161, decoder SINDy loss  ratio: 0.123787\n",
      "Epoch 130\n",
      "   training loss 0.00010259693954139948, (0.0001023183, 0.001296649, 0.0011645795, 0.01621791)\n",
      "   validation loss 0.00024632111308164895, (0.00024597067, 0.0026805054, 0.0018827564, 0.01621791)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.120320\n",
      "Epoch 131\n",
      "   training loss 0.00011781241482822224, (0.00011753422, 0.0012945143, 0.0011620973, 0.016198706)\n",
      "   validation loss 0.00030749625875614583, (0.0003071481, 0.0026777152, 0.0018619073, 0.016198706)\n",
      "decoder loss ratio: 0.000641, decoder SINDy loss  ratio: 0.118988\n",
      "Epoch 132\n",
      "   training loss 0.0001796498108888045, (0.00017937178, 0.0012596425, 0.0011614275, 0.016188316)\n",
      "   validation loss 0.00043009009095840156, (0.00042974134, 0.0026746648, 0.0018686297, 0.016188316)\n",
      "decoder loss ratio: 0.000897, decoder SINDy loss  ratio: 0.119418\n",
      "Epoch 133\n",
      "   training loss 0.0002975523239001632, (0.0002972716, 0.0013637108, 0.0011929838, 0.016144885)\n",
      "   validation loss 0.0003469647781457752, (0.00034661367, 0.0027229094, 0.0018966931, 0.016144885)\n",
      "decoder loss ratio: 0.000723, decoder SINDy loss  ratio: 0.121211\n",
      "Epoch 134\n",
      "   training loss 0.00019743647135328501, (0.00019715814, 0.001307113, 0.0011637736, 0.016196284)\n",
      "   validation loss 0.0004069651186000556, (0.00040661453, 0.0026900736, 0.0018862598, 0.016196284)\n",
      "decoder loss ratio: 0.000848, decoder SINDy loss  ratio: 0.120544\n",
      "Epoch 135\n",
      "   training loss 0.00016839156160131097, (0.0001681099, 0.0013766154, 0.0012039386, 0.01612817)\n",
      "   validation loss 0.00028489730902947485, (0.0002845463, 0.0027499746, 0.0018972058, 0.01612817)\n",
      "decoder loss ratio: 0.000594, decoder SINDy loss  ratio: 0.121244\n",
      "Epoch 136\n",
      "   training loss 0.0004465347155928612, (0.0004462564, 0.0013120048, 0.0011497305, 0.016334787)\n",
      "   validation loss 0.0006401236751116812, (0.0006397744, 0.0026222966, 0.0018598997, 0.016334787)\n",
      "decoder loss ratio: 0.001335, decoder SINDy loss  ratio: 0.118860\n",
      "Epoch 137\n",
      "   training loss 7.665123121114448e-05, (7.637394e-05, 0.001345052, 0.0011524216, 0.016204873)\n",
      "   validation loss 0.00022078902111388743, (0.00022044033, 0.0027513208, 0.001866453, 0.016204873)\n",
      "decoder loss ratio: 0.000460, decoder SINDy loss  ratio: 0.119278\n",
      "Epoch 138\n",
      "   training loss 5.678910747519694e-05, (5.6511257e-05, 0.0013499028, 0.0011588276, 0.016196543)\n",
      "   validation loss 0.00017530554032418877, (0.00017495669, 0.0027303468, 0.0018688438, 0.016196543)\n",
      "decoder loss ratio: 0.000365, decoder SINDy loss  ratio: 0.119431\n",
      "Epoch 139\n",
      "   training loss 5.175110709387809e-05, (5.1471656e-05, 0.0013519082, 0.0011745349, 0.016200101)\n",
      "   validation loss 0.0001757232384989038, (0.0001753751, 0.0026804118, 0.0018613453, 0.016200101)\n",
      "decoder loss ratio: 0.000366, decoder SINDy loss  ratio: 0.118952\n",
      "Epoch 140\n",
      "   training loss 0.00014699329040013254, (0.00014671328, 0.0013134512, 0.0011828071, 0.01617318)\n",
      "   validation loss 0.0003817963879555464, (0.00038144662, 0.0027074178, 0.0018804971, 0.01617318)\n",
      "decoder loss ratio: 0.000796, decoder SINDy loss  ratio: 0.120176\n",
      "Epoch 141\n",
      "   training loss 0.00026126907323487103, (0.00026098656, 0.0013867925, 0.0012039478, 0.016210858)\n",
      "   validation loss 0.00035426285467110574, (0.0003539111, 0.002730655, 0.0018965274, 0.016210858)\n",
      "decoder loss ratio: 0.000738, decoder SINDy loss  ratio: 0.121200\n",
      "Epoch 142\n",
      "   training loss 0.00013362814206629992, (0.00013334845, 0.0013703586, 0.0011722913, 0.016246349)\n",
      "   validation loss 0.0002457580412738025, (0.00024540818, 0.0027781304, 0.0018739151, 0.016246349)\n",
      "decoder loss ratio: 0.000512, decoder SINDy loss  ratio: 0.119755\n",
      "Epoch 143\n",
      "   training loss 0.0001481873623561114, (0.00014790843, 0.0013450376, 0.0011601583, 0.016290974)\n",
      "   validation loss 0.0002803979441523552, (0.000280049, 0.0027880326, 0.0018603207, 0.016290974)\n",
      "decoder loss ratio: 0.000584, decoder SINDy loss  ratio: 0.118887\n",
      "Epoch 144\n",
      "   training loss 9.355210931971669e-05, (9.3272385e-05, 0.0012932318, 0.0011641248, 0.016330991)\n",
      "   validation loss 0.00026154343504458666, (0.0002611941, 0.0026411128, 0.0018603256, 0.016330991)\n",
      "decoder loss ratio: 0.000545, decoder SINDy loss  ratio: 0.118887\n",
      "Epoch 145\n",
      "   training loss 0.00012236869952175766, (0.0001220892, 0.0014790787, 0.0011693959, 0.016256122)\n",
      "   validation loss 0.0002637401339598, (0.00026339112, 0.0028900146, 0.001864471, 0.016256122)\n",
      "decoder loss ratio: 0.000549, decoder SINDy loss  ratio: 0.119152\n",
      "Epoch 146\n",
      "   training loss 7.118783832993358e-05, (7.0909446e-05, 0.0013997344, 0.0011633242, 0.0162061)\n",
      "   validation loss 0.0002111291396431625, (0.00021078132, 0.0027282357, 0.0018575786, 0.0162061)\n",
      "decoder loss ratio: 0.000440, decoder SINDy loss  ratio: 0.118711\n",
      "Epoch 147\n",
      "   training loss 4.996365532861091e-05, (4.9685365e-05, 0.0013689391, 0.0011618175, 0.016211001)\n",
      "   validation loss 0.00017382646910846233, (0.00017347984, 0.0026732972, 0.001845249, 0.016211001)\n",
      "decoder loss ratio: 0.000362, decoder SINDy loss  ratio: 0.117923\n",
      "Epoch 148\n",
      "   training loss 0.00011129070480819792, (0.000111010704, 0.0014278168, 0.001185494, 0.01614541)\n",
      "   validation loss 0.00021286001720000058, (0.00021251207, 0.0027122279, 0.0018649657, 0.01614541)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.119183\n",
      "Epoch 149\n",
      "   training loss 7.944870594656095e-05, (7.9170524e-05, 0.0013542728, 0.0011641018, 0.016177462)\n",
      "   validation loss 0.0002300757623743266, (0.0002297306, 0.0026173003, 0.0018338823, 0.016177462)\n",
      "decoder loss ratio: 0.000479, decoder SINDy loss  ratio: 0.117197\n",
      "Epoch 150\n",
      "   training loss 0.00014488724991679192, (0.00014460966, 0.0013370183, 0.001154183, 0.016218765)\n",
      "   validation loss 0.0003410762292332947, (0.00034072972, 0.0026967234, 0.0018431788, 0.016218765)\n",
      "decoder loss ratio: 0.000711, decoder SINDy loss  ratio: 0.117791\n",
      "Epoch 151\n",
      "   training loss 0.000159587842063047, (0.00015930802, 0.0013928047, 0.0011705209, 0.016276741)\n",
      "   validation loss 0.0002273798454552889, (0.00022703156, 0.00272505, 0.0018552919, 0.016276741)\n",
      "decoder loss ratio: 0.000474, decoder SINDy loss  ratio: 0.118565\n",
      "Epoch 152\n",
      "   training loss 8.768850238993764e-05, (8.740794e-05, 0.0014159856, 0.0011826048, 0.016229741)\n",
      "   validation loss 0.00018870683561544865, (0.00018836014, 0.0027146062, 0.0018440473, 0.016229741)\n",
      "decoder loss ratio: 0.000393, decoder SINDy loss  ratio: 0.117847\n",
      "Epoch 153\n",
      "   training loss 0.00023756315931677818, (0.00023728512, 0.0014148898, 0.0011572978, 0.016231703)\n",
      "   validation loss 0.00046938122250139713, (0.00046903515, 0.0026103852, 0.0018376758, 0.016231703)\n",
      "decoder loss ratio: 0.000978, decoder SINDy loss  ratio: 0.117439\n",
      "Epoch 154\n",
      "   training loss 0.00012782163685187697, (0.00012753613, 0.0015718763, 0.0012382435, 0.016167946)\n",
      "   validation loss 0.0003276040661148727, (0.00032725226, 0.0029391316, 0.0019013319, 0.016167946)\n",
      "decoder loss ratio: 0.000683, decoder SINDy loss  ratio: 0.121507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155\n",
      "   training loss 0.0001480168430134654, (0.00014773771, 0.0014100209, 0.0011460127, 0.016453713)\n",
      "   validation loss 0.000332327006617561, (0.0003319793, 0.00267006, 0.0018317554, 0.016453713)\n",
      "decoder loss ratio: 0.000693, decoder SINDy loss  ratio: 0.117061\n",
      "Epoch 156\n",
      "   training loss 8.630249067209661e-05, (8.6021624e-05, 0.0014241841, 0.0011683044, 0.0164037)\n",
      "   validation loss 0.00027761273668147624, (0.00027726486, 0.0027275803, 0.0018385357, 0.0164037)\n",
      "decoder loss ratio: 0.000578, decoder SINDy loss  ratio: 0.117494\n",
      "Epoch 157\n",
      "   training loss 0.00017631631635595113, (0.00017603792, 0.0014081692, 0.0011578609, 0.016260283)\n",
      "   validation loss 0.0003595904854591936, (0.00035924453, 0.0027213308, 0.001833461, 0.016260283)\n",
      "decoder loss ratio: 0.000749, decoder SINDy loss  ratio: 0.117170\n",
      "Epoch 158\n",
      "   training loss 0.00020042256801389158, (0.00020014371, 0.0014045957, 0.0011567569, 0.016318206)\n",
      "   validation loss 0.0004404489300213754, (0.0004401024, 0.002722634, 0.0018336396, 0.016318206)\n",
      "decoder loss ratio: 0.000918, decoder SINDy loss  ratio: 0.117181\n",
      "Epoch 159\n",
      "   training loss 0.00012825423618778586, (0.00012797568, 0.0014095533, 0.0011553236, 0.016303204)\n",
      "   validation loss 0.0003246351261623204, (0.00032428905, 0.0027180803, 0.0018302347, 0.016303204)\n",
      "decoder loss ratio: 0.000677, decoder SINDy loss  ratio: 0.116964\n",
      "Epoch 160\n",
      "   training loss 0.0001510822185082361, (0.00015080188, 0.0014315048, 0.001169985, 0.016334232)\n",
      "   validation loss 0.0003257832140661776, (0.0003254373, 0.0027330332, 0.0018259498, 0.016334232)\n",
      "decoder loss ratio: 0.000679, decoder SINDy loss  ratio: 0.116690\n",
      "Epoch 161\n",
      "   training loss 0.00011766629904741421, (0.00011738825, 0.0013989065, 0.0011525493, 0.016279193)\n",
      "   validation loss 0.0002912917116191238, (0.0002909472, 0.0026984203, 0.001817367, 0.016279193)\n",
      "decoder loss ratio: 0.000607, decoder SINDy loss  ratio: 0.116142\n",
      "Epoch 162\n",
      "   training loss 0.0001784896303433925, (0.0001782097, 0.0014349559, 0.0011665423, 0.016329259)\n",
      "   validation loss 0.00029502902179956436, (0.00029468286, 0.0027082635, 0.0018286188, 0.016329259)\n",
      "decoder loss ratio: 0.000615, decoder SINDy loss  ratio: 0.116861\n",
      "Epoch 163\n",
      "   training loss 0.0001316477864747867, (0.00013136928, 0.0014382042, 0.001167562, 0.016176464)\n",
      "   validation loss 0.0003278530202805996, (0.00032750954, 0.002726353, 0.0018171892, 0.016176464)\n",
      "decoder loss ratio: 0.000683, decoder SINDy loss  ratio: 0.116130\n",
      "Epoch 164\n",
      "   training loss 0.000106110775959678, (0.00010583255, 0.0014471778, 0.0011580095, 0.01624189)\n",
      "   validation loss 0.00024404200667049736, (0.000243699, 0.0026777012, 0.0018059326, 0.01624189)\n",
      "decoder loss ratio: 0.000508, decoder SINDy loss  ratio: 0.115411\n",
      "Epoch 165\n",
      "   training loss 0.00012511061504483223, (0.00012483302, 0.0014021859, 0.0011469363, 0.016289102)\n",
      "   validation loss 0.00027408331516198814, (0.00027373867, 0.002665955, 0.0018174534, 0.016289102)\n",
      "decoder loss ratio: 0.000571, decoder SINDy loss  ratio: 0.116147\n",
      "Epoch 166\n",
      "   training loss 0.00019538970082066953, (0.00019511269, 0.001445009, 0.0011500178, 0.016201008)\n",
      "   validation loss 0.00028687145095318556, (0.00028652878, 0.0026466995, 0.0018063739, 0.016201008)\n",
      "decoder loss ratio: 0.000598, decoder SINDy loss  ratio: 0.115439\n",
      "Epoch 167\n",
      "   training loss 5.3056890465086326e-05, (5.277816e-05, 0.0014736205, 0.0011575726, 0.01629732)\n",
      "   validation loss 0.00019545451505109668, (0.00019511019, 0.0027164302, 0.0018136761, 0.01629732)\n",
      "decoder loss ratio: 0.000407, decoder SINDy loss  ratio: 0.115906\n",
      "Epoch 168\n",
      "   training loss 0.00022335024550557137, (0.00022306544, 0.0015755394, 0.0012215169, 0.016266678)\n",
      "   validation loss 0.00034436865826137364, (0.00034401935, 0.0027624492, 0.0018663455, 0.016266678)\n",
      "decoder loss ratio: 0.000718, decoder SINDy loss  ratio: 0.119272\n",
      "Epoch 169\n",
      "   training loss 0.0001565700804349035, (0.00015628988, 0.0015913259, 0.0011757163, 0.016262637)\n",
      "   validation loss 0.00023883550602477044, (0.00023848898, 0.0027534855, 0.0018389734, 0.016262637)\n",
      "decoder loss ratio: 0.000498, decoder SINDy loss  ratio: 0.117522\n",
      "Epoch 170\n",
      "   training loss 0.00012911157682538033, (0.00012882974, 0.0015283977, 0.0011891339, 0.016292106)\n",
      "   validation loss 0.00027048788615502417, (0.0002701404, 0.002723643, 0.0018458042, 0.016292106)\n",
      "decoder loss ratio: 0.000564, decoder SINDy loss  ratio: 0.117959\n",
      "Epoch 171\n",
      "   training loss 0.00017788232071325183, (0.000177604, 0.0014783746, 0.0011512935, 0.016318344)\n",
      "   validation loss 0.0005041445838287473, (0.0005038004, 0.0026704369, 0.0018105241, 0.016318344)\n",
      "decoder loss ratio: 0.001051, decoder SINDy loss  ratio: 0.115704\n",
      "Epoch 172\n",
      "   training loss 0.00014862128591630608, (0.00014834267, 0.001496598, 0.0011525815, 0.01633614)\n",
      "   validation loss 0.0003636976471170783, (0.00036335384, 0.002670665, 0.0018044135, 0.01633614)\n",
      "decoder loss ratio: 0.000758, decoder SINDy loss  ratio: 0.115314\n",
      "Epoch 173\n",
      "   training loss 0.0001554582704557106, (0.0001551793, 0.0015288246, 0.0011578399, 0.0163183)\n",
      "   validation loss 0.0003106507065240294, (0.00031030658, 0.0027072798, 0.0018094213, 0.0163183)\n",
      "decoder loss ratio: 0.000647, decoder SINDy loss  ratio: 0.115634\n",
      "Epoch 174\n",
      "   training loss 0.00019460948533378541, (0.00019432994, 0.001528095, 0.0011615576, 0.01633877)\n",
      "   validation loss 0.0004401003534439951, (0.00043975745, 0.0027067196, 0.001795242, 0.01633877)\n",
      "decoder loss ratio: 0.000917, decoder SINDy loss  ratio: 0.114728\n",
      "Epoch 175\n",
      "   training loss 0.00011408785940147936, (0.00011380903, 0.0015303182, 0.00114831, 0.016400099)\n",
      "   validation loss 0.0004342327010817826, (0.00043388866, 0.0026747445, 0.0018003491, 0.016400099)\n",
      "decoder loss ratio: 0.000905, decoder SINDy loss  ratio: 0.115054\n",
      "Epoch 176\n",
      "   training loss 0.00013870952534489334, (0.00013842947, 0.0015706547, 0.0011650423, 0.016355049)\n",
      "   validation loss 0.00024869528715498745, (0.00024835012, 0.002708648, 0.0018159414, 0.016355049)\n",
      "decoder loss ratio: 0.000518, decoder SINDy loss  ratio: 0.116050\n",
      "Epoch 177\n",
      "   training loss 0.00011721916234819219, (0.000116940006, 0.0015970594, 0.0011590801, 0.016324982)\n",
      "   validation loss 0.00021679623750969768, (0.0002164511, 0.0027504826, 0.0018189359, 0.016324982)\n",
      "decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.116242\n",
      "Epoch 178\n",
      "   training loss 8.218416041927412e-05, (8.1905804e-05, 0.0015981091, 0.0011467503, 0.016368335)\n",
      "   validation loss 0.0001704933529254049, (0.00017014964, 0.0027140249, 0.001800385, 0.016368335)\n",
      "decoder loss ratio: 0.000355, decoder SINDy loss  ratio: 0.115056\n",
      "Epoch 179\n",
      "   training loss 0.00019760361465159804, (0.00019731568, 0.0017701631, 0.0012492226, 0.01630128)\n",
      "   validation loss 0.00046585279051214457, (0.00046550162, 0.0028669573, 0.0018815738, 0.01630128)\n",
      "decoder loss ratio: 0.000971, decoder SINDy loss  ratio: 0.120245\n",
      "Epoch 180\n",
      "   training loss 0.0001047168843797408, (0.000104434264, 0.0016217668, 0.001182716, 0.016435083)\n",
      "   validation loss 0.00026012162561528385, (0.000259775, 0.0027001107, 0.001822753, 0.016435083)\n",
      "decoder loss ratio: 0.000542, decoder SINDy loss  ratio: 0.116486\n",
      "Epoch 181\n",
      "   training loss 7.180245302151889e-05, (7.151854e-05, 0.0017125196, 0.0011978303, 0.016413266)\n",
      "   validation loss 0.00022756097314413637, (0.00022721305, 0.0028561242, 0.0018379558, 0.016413266)\n",
      "decoder loss ratio: 0.000474, decoder SINDy loss  ratio: 0.117457\n",
      "Epoch 182\n",
      "   training loss 5.960758062428795e-05, (5.9325048e-05, 0.001665655, 0.0011833418, 0.016419943)\n",
      "   validation loss 0.00017572568322066218, (0.00017537888, 0.002779272, 0.001825957, 0.016419943)\n",
      "decoder loss ratio: 0.000366, decoder SINDy loss  ratio: 0.116691\n",
      "Epoch 183\n",
      "   training loss 6.852518708910793e-05, (6.82446e-05, 0.0016586375, 0.0011766561, 0.01629245)\n",
      "   validation loss 0.0001766069617588073, (0.00017626204, 0.0027513038, 0.0018199817, 0.01629245)\n",
      "decoder loss ratio: 0.000368, decoder SINDy loss  ratio: 0.116309\n",
      "Epoch 184\n",
      "   training loss 0.00015337674994952977, (0.0001530952, 0.0016926173, 0.0011846162, 0.016307894)\n",
      "   validation loss 0.00022921427444089204, (0.00022886816, 0.0028183293, 0.0018303077, 0.016307894)\n",
      "decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.116969\n",
      "Epoch 185\n",
      "   training loss 0.0001533265894977376, (0.00015304616, 0.001654732, 0.001170823, 0.016334636)\n",
      "   validation loss 0.00024110298545565456, (0.00024075806, 0.0027373799, 0.0018158539, 0.016334636)\n",
      "decoder loss ratio: 0.000502, decoder SINDy loss  ratio: 0.116045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186\n",
      "   training loss 0.00021332409232854843, (0.00021304286, 0.0015830853, 0.0011732569, 0.016389957)\n",
      "   validation loss 0.0004161800316069275, (0.00041583602, 0.0027144756, 0.0018008237, 0.016389957)\n",
      "decoder loss ratio: 0.000868, decoder SINDy loss  ratio: 0.115084\n",
      "Epoch 187\n",
      "   training loss 0.00016124214744195342, (0.00016096255, 0.0016250162, 0.0011524206, 0.016436057)\n",
      "   validation loss 0.00033407489536330104, (0.0003337309, 0.0027690234, 0.0017966616, 0.016436057)\n",
      "decoder loss ratio: 0.000696, decoder SINDy loss  ratio: 0.114818\n",
      "Epoch 188\n",
      "   training loss 0.00011933022324228659, (0.00011905166, 0.0016119978, 0.0011468936, 0.016387042)\n",
      "   validation loss 0.00027039615088142455, (0.00027005374, 0.0027102313, 0.0017853372, 0.016387042)\n",
      "decoder loss ratio: 0.000563, decoder SINDy loss  ratio: 0.114095\n",
      "Epoch 189\n",
      "   training loss 0.00018989641102962196, (0.00018961745, 0.0015430067, 0.0011356899, 0.016539391)\n",
      "   validation loss 0.00046647360431961715, (0.00046612977, 0.0026958045, 0.0017844827, 0.016539391)\n",
      "decoder loss ratio: 0.000972, decoder SINDy loss  ratio: 0.114040\n",
      "Epoch 190\n",
      "   training loss 0.00011524029105203226, (0.00011496125, 0.001601949, 0.0011364935, 0.016538842)\n",
      "   validation loss 0.0002536992251407355, (0.00025335612, 0.0027030588, 0.0017770553, 0.016538842)\n",
      "decoder loss ratio: 0.000529, decoder SINDy loss  ratio: 0.113565\n",
      "Epoch 191\n",
      "   training loss 0.00012922070163767785, (0.00012894298, 0.0016172113, 0.0011361912, 0.016410649)\n",
      "   validation loss 0.0002873020712286234, (0.00028695993, 0.0027209367, 0.0017801451, 0.016410649)\n",
      "decoder loss ratio: 0.000599, decoder SINDy loss  ratio: 0.113763\n",
      "Epoch 192\n",
      "   training loss 0.00013156332715880126, (0.0001312847, 0.0016059275, 0.0011335283, 0.016526552)\n",
      "   validation loss 0.0004391272959765047, (0.00043878495, 0.0027086067, 0.0017708892, 0.016526552)\n",
      "decoder loss ratio: 0.000915, decoder SINDy loss  ratio: 0.113171\n",
      "Epoch 193\n",
      "   training loss 0.00011816084588645026, (0.00011788211, 0.0016562078, 0.0011425859, 0.016446957)\n",
      "   validation loss 0.0002519022091291845, (0.00025155992, 0.0027085629, 0.001778172, 0.016446957)\n",
      "decoder loss ratio: 0.000525, decoder SINDy loss  ratio: 0.113637\n",
      "Epoch 194\n",
      "   training loss 0.00013097000191919506, (0.00013068921, 0.0016915174, 0.0011582426, 0.016497742)\n",
      "   validation loss 0.00023913764744065702, (0.0002387936, 0.0027697228, 0.0017907431, 0.016497742)\n",
      "decoder loss ratio: 0.000498, decoder SINDy loss  ratio: 0.114440\n",
      "Epoch 195\n",
      "   training loss 0.00012498848082032055, (0.00012470948, 0.0017125277, 0.001144032, 0.01645929)\n",
      "   validation loss 0.00018971317331306636, (0.00018937029, 0.0027940255, 0.0017828805, 0.01645929)\n",
      "decoder loss ratio: 0.000395, decoder SINDy loss  ratio: 0.113938\n",
      "Epoch 196\n",
      "   training loss 0.0002739218180067837, (0.0002736364, 0.0018808163, 0.0012187045, 0.016355978)\n",
      "   validation loss 0.00029286506469361484, (0.00029251777, 0.0029009916, 0.0018374104, 0.016355978)\n",
      "decoder loss ratio: 0.000610, decoder SINDy loss  ratio: 0.117422\n",
      "Epoch 197\n",
      "   training loss 0.0001485539396526292, (0.00014827246, 0.0017442062, 0.0011761677, 0.016385267)\n",
      "   validation loss 0.00022807314235251397, (0.00022772922, 0.0028270602, 0.0018006273, 0.016385267)\n",
      "decoder loss ratio: 0.000475, decoder SINDy loss  ratio: 0.115072\n",
      "Epoch 198\n",
      "   training loss 7.453273428836837e-05, (7.425164e-05, 0.0017047375, 0.0011648487, 0.016460504)\n",
      "   validation loss 0.0001868108956841752, (0.00018646584, 0.0028178536, 0.0018044703, 0.016460504)\n",
      "decoder loss ratio: 0.000389, decoder SINDy loss  ratio: 0.115317\n",
      "Epoch 199\n",
      "   training loss 0.0001362301700282842, (0.00013594821, 0.0017755311, 0.0011764944, 0.016430626)\n",
      "   validation loss 0.0002491794293746352, (0.0002488342, 0.0028834098, 0.0018091658, 0.016430626)\n",
      "decoder loss ratio: 0.000519, decoder SINDy loss  ratio: 0.115617\n",
      "Epoch 200\n",
      "   training loss 0.0001649392070248723, (0.00016466014, 0.0017297101, 0.00114992, 0.016407883)\n",
      "   validation loss 0.00022987480042502284, (0.00022953232, 0.002809257, 0.0017839981, 0.016407883)\n",
      "decoder loss ratio: 0.000479, decoder SINDy loss  ratio: 0.114009\n",
      "Epoch 201\n",
      "   training loss 0.00015112111577764153, (0.00015083823, 0.0017819083, 0.0011857776, 0.016430158)\n",
      "   validation loss 0.00022289075423032045, (0.00022254644, 0.0028572013, 0.0018001199, 0.016430158)\n",
      "decoder loss ratio: 0.000464, decoder SINDy loss  ratio: 0.115039\n",
      "Epoch 202\n",
      "   training loss 0.00015608753892593086, (0.00015580837, 0.0016997792, 0.001145409, 0.01646269)\n",
      "   validation loss 0.00020229656365700066, (0.0002019547, 0.0028041296, 0.0017724271, 0.01646269)\n",
      "decoder loss ratio: 0.000421, decoder SINDy loss  ratio: 0.113270\n",
      "Epoch 203\n",
      "   training loss 0.0002560965367592871, (0.00025581577, 0.0016538679, 0.0011525443, 0.016550956)\n",
      "   validation loss 0.00038463191594928503, (0.00038428887, 0.0027771732, 0.0017754715, 0.016550956)\n",
      "decoder loss ratio: 0.000802, decoder SINDy loss  ratio: 0.113464\n",
      "Epoch 204\n",
      "   training loss 0.00012926847557537258, (0.00012898675, 0.0017056847, 0.00116652, 0.01650783)\n",
      "   validation loss 0.0002598826540634036, (0.00025953792, 0.002898064, 0.0017966231, 0.01650783)\n",
      "decoder loss ratio: 0.000541, decoder SINDy loss  ratio: 0.114816\n",
      "Epoch 205\n",
      "   training loss 9.238168422598392e-05, (9.210298e-05, 0.0016930882, 0.0011452343, 0.016417893)\n",
      "   validation loss 0.00017964886501431465, (0.00017930722, 0.002804813, 0.0017748022, 0.016417893)\n",
      "decoder loss ratio: 0.000374, decoder SINDy loss  ratio: 0.113421\n",
      "Epoch 206\n",
      "   training loss 0.00011933610221603885, (0.00011905769, 0.0017017667, 0.0011318384, 0.01652302)\n",
      "   validation loss 0.0003355424269102514, (0.00033520127, 0.0028849393, 0.0017592204, 0.01652302)\n",
      "decoder loss ratio: 0.000699, decoder SINDy loss  ratio: 0.112426\n",
      "Epoch 207\n",
      "   training loss 0.00011093769717263058, (0.000110659865, 0.0016084799, 0.0011170047, 0.016612867)\n",
      "   validation loss 0.0003874578105751425, (0.000387115, 0.0027425378, 0.0017668264, 0.016612867)\n",
      "decoder loss ratio: 0.000808, decoder SINDy loss  ratio: 0.112912\n",
      "Epoch 208\n",
      "   training loss 0.00011275373253738508, (0.000112472975, 0.0017498854, 0.0011532297, 0.016543096)\n",
      "   validation loss 0.00021473232482094318, (0.00021438832, 0.0028899293, 0.0017858527, 0.016543096)\n",
      "decoder loss ratio: 0.000447, decoder SINDy loss  ratio: 0.114128\n",
      "Epoch 209\n",
      "   training loss 8.876182982930914e-05, (8.848077e-05, 0.001785932, 0.0011530565, 0.016576193)\n",
      "   validation loss 0.00020791238057427108, (0.00020756779, 0.0029043108, 0.0017882366, 0.016576193)\n",
      "decoder loss ratio: 0.000433, decoder SINDy loss  ratio: 0.114280\n",
      "Epoch 210\n",
      "   training loss 0.00010781620949273929, (0.00010753618, 0.0017801666, 0.0011476444, 0.016526785)\n",
      "   validation loss 0.00017940739053301513, (0.00017906407, 0.0029006442, 0.001780618, 0.016526785)\n",
      "decoder loss ratio: 0.000374, decoder SINDy loss  ratio: 0.113793\n",
      "Epoch 211\n",
      "   training loss 0.00017679216398391873, (0.00017651259, 0.00178244, 0.0011491074, 0.016466156)\n",
      "   validation loss 0.00020484242122620344, (0.0002044999, 0.0028665983, 0.0017787294, 0.016466156)\n",
      "decoder loss ratio: 0.000427, decoder SINDy loss  ratio: 0.113672\n",
      "Epoch 212\n",
      "   training loss 0.00023484425037167966, (0.00023456276, 0.0018466249, 0.0011714629, 0.016435461)\n",
      "   validation loss 0.00026886144769378006, (0.00026851916, 0.002895095, 0.0017794424, 0.016435461)\n",
      "decoder loss ratio: 0.000560, decoder SINDy loss  ratio: 0.113718\n",
      "Epoch 213\n",
      "   training loss 0.00019170423911418766, (0.0001914215, 0.0018451487, 0.0011864805, 0.016409583)\n",
      "   validation loss 0.0002842406975105405, (0.00028389727, 0.002909944, 0.0017934741, 0.016409583)\n",
      "decoder loss ratio: 0.000592, decoder SINDy loss  ratio: 0.114615\n",
      "Epoch 214\n",
      "   training loss 0.00012902919843327254, (0.00012874967, 0.0017998484, 0.0011469026, 0.01648393)\n",
      "   validation loss 0.0001562029792694375, (0.00015586156, 0.0029057038, 0.0017656975, 0.01648393)\n",
      "decoder loss ratio: 0.000325, decoder SINDy loss  ratio: 0.112840\n",
      "Epoch 215\n",
      "   training loss 0.00023502086696680635, (0.00023474287, 0.0016911523, 0.0011105211, 0.01669491)\n",
      "   validation loss 0.0003686630807351321, (0.00036832085, 0.0028300302, 0.0017529089, 0.01669491)\n",
      "decoder loss ratio: 0.000768, decoder SINDy loss  ratio: 0.112022\n",
      "Epoch 216\n",
      "   training loss 6.817278335802257e-05, (6.789423e-05, 0.0017337538, 0.0011269022, 0.016586058)\n",
      "   validation loss 0.000186205463251099, (0.00018586424, 0.0028415467, 0.0017535861, 0.016586058)\n",
      "decoder loss ratio: 0.000388, decoder SINDy loss  ratio: 0.112066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217\n",
      "   training loss 7.16717477189377e-05, (7.139289e-05, 0.0016745729, 0.0011216638, 0.016669406)\n",
      "   validation loss 0.00026112934574484825, (0.00026078738, 0.002807663, 0.0017525097, 0.016669406)\n",
      "decoder loss ratio: 0.000544, decoder SINDy loss  ratio: 0.111997\n",
      "Epoch 218\n",
      "   training loss 0.00014705018838867545, (0.00014676967, 0.001693552, 0.0011440043, 0.016611677)\n",
      "   validation loss 0.00027968749054707587, (0.00027934578, 0.0027967864, 0.0017559257, 0.016611677)\n",
      "decoder loss ratio: 0.000583, decoder SINDy loss  ratio: 0.112215\n",
      "Epoch 219\n",
      "   training loss 0.00014845040277577937, (0.00014817115, 0.0017489806, 0.0011386698, 0.01653851)\n",
      "   validation loss 0.00037268310552462935, (0.00037234227, 0.0028754931, 0.0017542923, 0.01653851)\n",
      "decoder loss ratio: 0.000777, decoder SINDy loss  ratio: 0.112111\n",
      "Epoch 220\n",
      "   training loss 0.00011419317161198705, (0.000113913484, 0.0016826256, 0.0011207135, 0.016761765)\n",
      "   validation loss 0.00038029480492696166, (0.00037995147, 0.0027794803, 0.0017573221, 0.016761765)\n",
      "decoder loss ratio: 0.000793, decoder SINDy loss  ratio: 0.112304\n",
      "Epoch 221\n",
      "   training loss 0.00020800044876523316, (0.00020771954, 0.0018049747, 0.0011449079, 0.01664105)\n",
      "   validation loss 0.0002550724020693451, (0.00025472915, 0.0028665024, 0.0017682577, 0.01664105)\n",
      "decoder loss ratio: 0.000531, decoder SINDy loss  ratio: 0.113003\n",
      "Epoch 222\n",
      "   training loss 0.00012422955478541553, (0.00012394733, 0.0019194178, 0.0011623468, 0.01659815)\n",
      "   validation loss 0.00023629560018889606, (0.0002359516, 0.002996791, 0.0017802338, 0.01659815)\n",
      "decoder loss ratio: 0.000492, decoder SINDy loss  ratio: 0.113769\n",
      "Epoch 223\n",
      "   training loss 0.0001400299952365458, (0.00013974913, 0.0018912465, 0.0011462551, 0.016624251)\n",
      "   validation loss 0.00020470769959501922, (0.00020436433, 0.0029797016, 0.0017713284, 0.016624251)\n",
      "decoder loss ratio: 0.000426, decoder SINDy loss  ratio: 0.113199\n",
      "Epoch 224\n",
      "   training loss 0.00015963739133439958, (0.00015935536, 0.0019402701, 0.0011662929, 0.016539723)\n",
      "   validation loss 0.0002159360738005489, (0.00021559262, 0.003009755, 0.0017806367, 0.016539723)\n",
      "decoder loss ratio: 0.000450, decoder SINDy loss  ratio: 0.113794\n",
      "Epoch 225\n",
      "   training loss 0.00023391448485199362, (0.00023363417, 0.0019225832, 0.0011484763, 0.016546348)\n",
      "   validation loss 0.0002931307826656848, (0.0002927893, 0.0030257325, 0.0017602757, 0.016546348)\n",
      "decoder loss ratio: 0.000611, decoder SINDy loss  ratio: 0.112493\n",
      "Epoch 226\n",
      "   training loss 0.00018559934687800705, (0.00018531588, 0.0019237349, 0.001180872, 0.016538661)\n",
      "   validation loss 0.00025023557827807963, (0.00024989247, 0.0029492606, 0.0017769949, 0.016538661)\n",
      "decoder loss ratio: 0.000521, decoder SINDy loss  ratio: 0.113562\n",
      "Epoch 227\n",
      "   training loss 0.00024284041137434542, (0.00024256116, 0.001891234, 0.0011268819, 0.016656308)\n",
      "   validation loss 0.0002548077027313411, (0.0002544663, 0.003068259, 0.0017484833, 0.016656308)\n",
      "decoder loss ratio: 0.000531, decoder SINDy loss  ratio: 0.111739\n",
      "Epoch 228\n",
      "   training loss 0.00036314871977083385, (0.0003628686, 0.0018116637, 0.0011322045, 0.016690968)\n",
      "   validation loss 0.0003771392803173512, (0.00037679728, 0.002951563, 0.0017507762, 0.016690968)\n",
      "decoder loss ratio: 0.000786, decoder SINDy loss  ratio: 0.111886\n",
      "Epoch 229\n",
      "   training loss 0.0001362009788863361, (0.00013592117, 0.0017825561, 0.0011303744, 0.016675843)\n",
      "   validation loss 0.00021884289162699133, (0.00021850159, 0.0028917687, 0.0017453594, 0.016675843)\n",
      "decoder loss ratio: 0.000456, decoder SINDy loss  ratio: 0.111540\n",
      "Epoch 230\n",
      "   training loss 0.00011723061470547691, (0.00011695236, 0.0017833501, 0.0011185224, 0.01664004)\n",
      "   validation loss 0.00020113115897402167, (0.00020079098, 0.0028794536, 0.0017378461, 0.01664004)\n",
      "decoder loss ratio: 0.000419, decoder SINDy loss  ratio: 0.111060\n",
      "Epoch 231\n",
      "   training loss 0.00014453032054007053, (0.00014424983, 0.0016702582, 0.0011169256, 0.016880136)\n",
      "   validation loss 0.0004306377668399364, (0.00043029358, 0.0028539335, 0.0017539145, 0.016880136)\n",
      "decoder loss ratio: 0.000898, decoder SINDy loss  ratio: 0.112087\n",
      "Epoch 232\n",
      "   training loss 0.00013359585136640817, (0.00013331452, 0.0018599989, 0.0011412944, 0.016720168)\n",
      "   validation loss 0.00022751463984604925, (0.00022717213, 0.0028960737, 0.0017530359, 0.016720168)\n",
      "decoder loss ratio: 0.000474, decoder SINDy loss  ratio: 0.112030\n",
      "Epoch 233\n",
      "   training loss 0.00015669017739128321, (0.00015640783, 0.0019375234, 0.0011570756, 0.016665239)\n",
      "   validation loss 0.00026973141939379275, (0.00026938829, 0.002997989, 0.0017649555, 0.016665239)\n",
      "decoder loss ratio: 0.000562, decoder SINDy loss  ratio: 0.112792\n",
      "Epoch 234\n",
      "   training loss 0.0001396463339915499, (0.00013936496, 0.00191963, 0.0011436527, 0.016701698)\n",
      "   validation loss 0.00022254249779507518, (0.00022219986, 0.0030396988, 0.0017562628, 0.016701698)\n",
      "decoder loss ratio: 0.000464, decoder SINDy loss  ratio: 0.112237\n",
      "Epoch 235\n",
      "   training loss 0.0001439335464965552, (0.00014365253, 0.0019115711, 0.0011483693, 0.016617348)\n",
      "   validation loss 0.0001962450915016234, (0.00019590346, 0.0030315535, 0.0017547052, 0.016617348)\n",
      "decoder loss ratio: 0.000409, decoder SINDy loss  ratio: 0.112137\n",
      "Epoch 236\n",
      "   training loss 0.0001993010810110718, (0.00019902243, 0.001807149, 0.0011150222, 0.016716223)\n",
      "   validation loss 0.0004152389010414481, (0.0004148982, 0.0029620496, 0.0017352469, 0.016716223)\n",
      "decoder loss ratio: 0.000866, decoder SINDy loss  ratio: 0.110894\n",
      "Epoch 237\n",
      "   training loss 0.00022374329273588955, (0.00022346346, 0.0019440497, 0.0011172307, 0.01681106)\n",
      "   validation loss 0.000361273909220472, (0.00036093037, 0.003172036, 0.0017544446, 0.01681106)\n",
      "decoder loss ratio: 0.000753, decoder SINDy loss  ratio: 0.112120\n",
      "Epoch 238\n",
      "   training loss 9.871701331576332e-05, (9.843732e-05, 0.001899995, 0.0011269599, 0.01669981)\n",
      "   validation loss 0.00018763441767077893, (0.000187293, 0.003050857, 0.001744228, 0.01669981)\n",
      "decoder loss ratio: 0.000391, decoder SINDy loss  ratio: 0.111468\n",
      "Epoch 239\n",
      "   training loss 0.00016872418927960098, (0.00016844361, 0.0018855954, 0.0011469042, 0.016589483)\n",
      "   validation loss 0.0002458410453982651, (0.000245501, 0.0029712166, 0.0017414539, 0.016589483)\n",
      "decoder loss ratio: 0.000512, decoder SINDy loss  ratio: 0.111290\n",
      "Epoch 240\n",
      "   training loss 0.00024987291544675827, (0.0002495904, 0.001961454, 0.0011632827, 0.016619733)\n",
      "   validation loss 0.00028338722768239677, (0.00028304523, 0.0030441743, 0.0017581487, 0.016619733)\n",
      "decoder loss ratio: 0.000590, decoder SINDy loss  ratio: 0.112357\n",
      "Epoch 241\n",
      "   training loss 0.0003624559030868113, (0.000362177, 0.001823017, 0.0011117138, 0.016772578)\n",
      "   validation loss 0.00037463943590410054, (0.0003742979, 0.0029914686, 0.0017379507, 0.016772578)\n",
      "decoder loss ratio: 0.000781, decoder SINDy loss  ratio: 0.111066\n",
      "Epoch 242\n",
      "   training loss 0.00015076380805112422, (0.0001504847, 0.0018569358, 0.0011231801, 0.016679777)\n",
      "   validation loss 0.0002858703664969653, (0.00028552965, 0.00295354, 0.0017391652, 0.016679777)\n",
      "decoder loss ratio: 0.000596, decoder SINDy loss  ratio: 0.111144\n",
      "Epoch 243\n",
      "   training loss 0.00015803515270818025, (0.00015775228, 0.0019239307, 0.0011627804, 0.016659478)\n",
      "   validation loss 0.00024627274251542985, (0.00024593007, 0.0029866414, 0.0017607915, 0.016659478)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.112526\n",
      "Epoch 244\n",
      "   training loss 0.00017152924556285143, (0.00017124941, 0.0018954765, 0.0011324954, 0.01665889)\n",
      "   validation loss 0.00020314889843575656, (0.00020280822, 0.0030510721, 0.0017408518, 0.01665889)\n",
      "decoder loss ratio: 0.000423, decoder SINDy loss  ratio: 0.111252\n",
      "Epoch 245\n",
      "   training loss 0.0002513261861167848, (0.00025104787, 0.0017782181, 0.0011032801, 0.01679741)\n",
      "   validation loss 0.0004308714997023344, (0.00043052953, 0.0029544623, 0.0017399514, 0.01679741)\n",
      "decoder loss ratio: 0.000898, decoder SINDy loss  ratio: 0.111194\n",
      "Epoch 246\n",
      "   training loss 0.00011103273573098704, (0.00011075112, 0.0019501176, 0.0011426422, 0.016735135)\n",
      "   validation loss 0.0002103474544128403, (0.00021000527, 0.0031316904, 0.001748469, 0.016735135)\n",
      "decoder loss ratio: 0.000438, decoder SINDy loss  ratio: 0.111739\n",
      "Epoch 247\n",
      "   training loss 0.00015638918557669967, (0.00015610854, 0.0019575888, 0.0011335525, 0.016728507)\n",
      "   validation loss 0.00021486465993802994, (0.00021452295, 0.0031125792, 0.001744146, 0.016728507)\n",
      "decoder loss ratio: 0.000448, decoder SINDy loss  ratio: 0.111462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248\n",
      "   training loss 0.00016005363431759179, (0.00015977427, 0.0018787482, 0.0011240575, 0.016697196)\n",
      "   validation loss 0.00023665011394768953, (0.0002363104, 0.003087122, 0.0017274764, 0.016697196)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.110397\n",
      "Epoch 249\n",
      "   training loss 0.00013043949729762971, (0.00013015996, 0.0018178206, 0.001114508, 0.016808935)\n",
      "   validation loss 0.0002538278349675238, (0.00025348723, 0.0030134402, 0.0017250226, 0.016808935)\n",
      "decoder loss ratio: 0.000529, decoder SINDy loss  ratio: 0.110240\n",
      "Epoch 250\n",
      "   training loss 0.000123760721180588, (0.00012347866, 0.0020086286, 0.0011491338, 0.016714195)\n",
      "   validation loss 0.00022180929954629391, (0.00022146673, 0.0032593228, 0.0017542285, 0.016714195)\n",
      "decoder loss ratio: 0.000462, decoder SINDy loss  ratio: 0.112107\n",
      "Epoch 251\n",
      "   training loss 0.00018758806982077658, (0.000187308, 0.001955733, 0.0011352815, 0.01665388)\n",
      "   validation loss 0.00023561771376989782, (0.0002352767, 0.0032067248, 0.0017447501, 0.01665388)\n",
      "decoder loss ratio: 0.000491, decoder SINDy loss  ratio: 0.111501\n",
      "Epoch 252\n",
      "   training loss 0.00014516603550873697, (0.00014488812, 0.0018602432, 0.0011104067, 0.016686127)\n",
      "   validation loss 0.00022496189922094345, (0.00022462249, 0.003123817, 0.0017253588, 0.016686127)\n",
      "decoder loss ratio: 0.000469, decoder SINDy loss  ratio: 0.110262\n",
      "Epoch 253\n",
      "   training loss 0.0002495466615073383, (0.0002492642, 0.0019668213, 0.0011540446, 0.016704267)\n",
      "   validation loss 0.0003279712109360844, (0.00032762982, 0.0030811394, 0.0017432985, 0.016704267)\n",
      "decoder loss ratio: 0.000683, decoder SINDy loss  ratio: 0.111408\n",
      "Epoch 254\n",
      "   training loss 0.0002555084356572479, (0.00025522654, 0.0019924743, 0.0011451212, 0.016737338)\n",
      "   validation loss 0.00036594204721041024, (0.00036559964, 0.0032273524, 0.0017502243, 0.016737338)\n",
      "decoder loss ratio: 0.000763, decoder SINDy loss  ratio: 0.111851\n",
      "Epoch 255\n",
      "   training loss 0.00022732853540219367, (0.00022704886, 0.0019085273, 0.0011136268, 0.016830279)\n",
      "   validation loss 0.0003660799702629447, (0.0003657378, 0.0032632467, 0.0017387564, 0.016830279)\n",
      "decoder loss ratio: 0.000763, decoder SINDy loss  ratio: 0.111118\n",
      "Epoch 256\n",
      "   training loss 0.0001533425966044888, (0.00015306227, 0.001980423, 0.0011225608, 0.016807139)\n",
      "   validation loss 0.0002383894461672753, (0.00023804841, 0.0031976926, 0.0017295921, 0.016807139)\n",
      "decoder loss ratio: 0.000497, decoder SINDy loss  ratio: 0.110532\n",
      "Epoch 257\n",
      "   training loss 0.00010975808254443109, (0.00010947809, 0.0019157734, 0.0011156675, 0.016842345)\n",
      "   validation loss 0.00028093441505916417, (0.0002805946, 0.0031347373, 0.001713818, 0.016842345)\n",
      "decoder loss ratio: 0.000585, decoder SINDy loss  ratio: 0.109524\n",
      "Epoch 258\n",
      "   training loss 8.919034735299647e-05, (8.8911234e-05, 0.0017994632, 0.001106042, 0.016851356)\n",
      "   validation loss 0.0002921455889008939, (0.00029180388, 0.0030531532, 0.00173194, 0.016851356)\n",
      "decoder loss ratio: 0.000609, decoder SINDy loss  ratio: 0.110682\n",
      "Epoch 259\n",
      "   training loss 0.00021316377387847751, (0.00021288292, 0.0020036038, 0.0011269888, 0.016814569)\n",
      "   validation loss 0.0003073647676501423, (0.0003070236, 0.0031500163, 0.0017303312, 0.016814569)\n",
      "decoder loss ratio: 0.000641, decoder SINDy loss  ratio: 0.110579\n",
      "Epoch 260\n",
      "   training loss 0.00015443091979250312, (0.0001541509, 0.0020403066, 0.001124084, 0.016760843)\n",
      "   validation loss 0.00026372165302746, (0.00026338038, 0.0033330997, 0.0017367456, 0.016760843)\n",
      "decoder loss ratio: 0.000549, decoder SINDy loss  ratio: 0.110989\n",
      "Epoch 261\n",
      "   training loss 0.00015998836897779256, (0.00015970723, 0.0020121173, 0.0011348203, 0.01676732)\n",
      "   validation loss 0.0002469414030201733, (0.0002466008, 0.0032737236, 0.001729423, 0.01676732)\n",
      "decoder loss ratio: 0.000514, decoder SINDy loss  ratio: 0.110521\n",
      "Epoch 262\n",
      "   training loss 0.00010017790918936953, (9.989855e-05, 0.0019441227, 0.0011163556, 0.016772432)\n",
      "   validation loss 0.00019667093874886632, (0.00019633192, 0.0031755413, 0.0017129757, 0.016772432)\n",
      "decoder loss ratio: 0.000410, decoder SINDy loss  ratio: 0.109470\n",
      "Epoch 263\n",
      "   training loss 0.0002618424186948687, (0.00026156183, 0.001696486, 0.0011023748, 0.017035736)\n",
      "   validation loss 0.0004455965245142579, (0.00044525132, 0.0030404546, 0.0017484839, 0.017035736)\n",
      "decoder loss ratio: 0.000929, decoder SINDy loss  ratio: 0.111739\n",
      "Epoch 264\n",
      "   training loss 0.00012157706078141928, (0.00012129545, 0.0020141848, 0.0011224739, 0.016936405)\n",
      "   validation loss 0.00021851540077477694, (0.00021817285, 0.003244842, 0.0017318808, 0.016936405)\n",
      "decoder loss ratio: 0.000455, decoder SINDy loss  ratio: 0.110678\n",
      "Epoch 265\n",
      "   training loss 0.00014157241093926132, (0.0001412912, 0.0020223714, 0.0011248083, 0.016873082)\n",
      "   validation loss 0.00023209716891869903, (0.00023175585, 0.0032193393, 0.0017257986, 0.016873082)\n",
      "decoder loss ratio: 0.000483, decoder SINDy loss  ratio: 0.110290\n",
      "Epoch 266\n",
      "   training loss 0.00015806961164344102, (0.0001577888, 0.0020607102, 0.0011281116, 0.016800191)\n",
      "   validation loss 0.0002031044423347339, (0.000202764, 0.0032178978, 0.0017244525, 0.016800191)\n",
      "decoder loss ratio: 0.000423, decoder SINDy loss  ratio: 0.110204\n",
      "Epoch 267\n",
      "   training loss 0.00027974904514849186, (0.0002794693, 0.0019749878, 0.0011169648, 0.0168032)\n",
      "   validation loss 0.0003755881916731596, (0.00037524838, 0.0032333503, 0.0017176273, 0.0168032)\n",
      "decoder loss ratio: 0.000783, decoder SINDy loss  ratio: 0.109768\n",
      "Epoch 268\n",
      "   training loss 0.0001465058739995584, (0.00014622549, 0.0019792113, 0.0011219025, 0.016819322)\n",
      "   validation loss 0.000246912008151412, (0.00024657245, 0.003140771, 0.0017136798, 0.016819322)\n",
      "decoder loss ratio: 0.000514, decoder SINDy loss  ratio: 0.109515\n",
      "Epoch 269\n",
      "   training loss 0.00019108597189188004, (0.00019080714, 0.0020569314, 0.0011132585, 0.016750578)\n",
      "   validation loss 0.0003697281645145267, (0.00036938943, 0.003260806, 0.0017124545, 0.016750578)\n",
      "decoder loss ratio: 0.000771, decoder SINDy loss  ratio: 0.109437\n",
      "Epoch 270\n",
      "   training loss 0.0001691448997007683, (0.00016886556, 0.001791528, 0.0010917184, 0.017016502)\n",
      "   validation loss 0.0003053848340641707, (0.00030504254, 0.0031542515, 0.0017212915, 0.017016502)\n",
      "decoder loss ratio: 0.000636, decoder SINDy loss  ratio: 0.110002\n",
      "Epoch 271\n",
      "   training loss 0.00015670900756958872, (0.00015642897, 0.0020163162, 0.0011192341, 0.016811255)\n",
      "   validation loss 0.0002581828448455781, (0.0002578422, 0.0032391553, 0.001725361, 0.016811255)\n",
      "decoder loss ratio: 0.000538, decoder SINDy loss  ratio: 0.110262\n",
      "Epoch 272\n",
      "   training loss 0.00013070223212707788, (0.00013042171, 0.0019969929, 0.0011215478, 0.016836304)\n",
      "   validation loss 0.00021650694543495774, (0.0002161672, 0.003159008, 0.0017137814, 0.016836304)\n",
      "decoder loss ratio: 0.000451, decoder SINDy loss  ratio: 0.109522\n",
      "Epoch 273\n",
      "   training loss 0.0001415141741745174, (0.0001412355, 0.0019972874, 0.0010972491, 0.016894124)\n",
      "   validation loss 0.0004491930012591183, (0.00044885537, 0.003252496, 0.0016868612, 0.016894124)\n",
      "decoder loss ratio: 0.000936, decoder SINDy loss  ratio: 0.107801\n",
      "Epoch 274\n",
      "   training loss 0.0001717846025712788, (0.00017150585, 0.0017526775, 0.0010846015, 0.017029716)\n",
      "   validation loss 0.0003205714747309685, (0.00032022878, 0.003042478, 0.0017241174, 0.017029716)\n",
      "decoder loss ratio: 0.000668, decoder SINDy loss  ratio: 0.110182\n",
      "Epoch 275\n",
      "   training loss 0.00017281193868257105, (0.00017252921, 0.0021033946, 0.001138012, 0.016893731)\n",
      "   validation loss 0.00025966696557588875, (0.0002593249, 0.0033446222, 0.001731113, 0.016893731)\n",
      "decoder loss ratio: 0.000541, decoder SINDy loss  ratio: 0.110629\n",
      "Epoch 276\n",
      "   training loss 0.00015214447921607643, (0.00015186486, 0.0020494373, 0.001104648, 0.016915454)\n",
      "   validation loss 0.0002300424821441993, (0.0002297028, 0.0032604665, 0.0017053882, 0.016915454)\n",
      "decoder loss ratio: 0.000479, decoder SINDy loss  ratio: 0.108985\n",
      "Epoch 277\n",
      "   training loss 0.0001652758801355958, (0.00016499453, 0.0020949978, 0.0011223484, 0.016910354)\n",
      "   validation loss 0.00018403686408419162, (0.00018369744, 0.0032848848, 0.001703125, 0.016910354)\n",
      "decoder loss ratio: 0.000383, decoder SINDy loss  ratio: 0.108841\n",
      "Epoch 278\n",
      "   training loss 0.00046524772187694907, (0.00046496931, 0.0018792812, 0.0010798968, 0.017043192)\n",
      "   validation loss 0.0004300750733818859, (0.00042973374, 0.00322694, 0.0017088405, 0.017043192)\n",
      "decoder loss ratio: 0.000896, decoder SINDy loss  ratio: 0.109206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279\n",
      "   training loss 0.00011932943743886426, (0.000119048804, 0.002033645, 0.0011100478, 0.016963072)\n",
      "   validation loss 0.00022321664437185973, (0.00022287562, 0.003206138, 0.0017139878, 0.016963072)\n",
      "decoder loss ratio: 0.000465, decoder SINDy loss  ratio: 0.109535\n",
      "Epoch 280\n",
      "   training loss 0.00015214989252854139, (0.00015187035, 0.0020780466, 0.0011019062, 0.016935619)\n",
      "   validation loss 0.00022910577536094934, (0.00022876574, 0.0033013131, 0.0017068489, 0.016935619)\n",
      "decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.109079\n",
      "Epoch 281\n",
      "   training loss 0.0001372942642774433, (0.00013701429, 0.0020676672, 0.0011151789, 0.016846329)\n",
      "   validation loss 0.0002100168785545975, (0.00020967808, 0.0032623406, 0.0017032691, 0.016846329)\n",
      "decoder loss ratio: 0.000437, decoder SINDy loss  ratio: 0.108850\n",
      "Epoch 282\n",
      "   training loss 0.0001242294383700937, (0.00012394998, 0.0020234406, 0.0011061532, 0.0168843)\n",
      "   validation loss 0.0002858403604477644, (0.00028550316, 0.0032304702, 0.0016835363, 0.0168843)\n",
      "decoder loss ratio: 0.000596, decoder SINDy loss  ratio: 0.107589\n",
      "Epoch 283\n",
      "   training loss 7.928509876364842e-05, (7.90055e-05, 0.0019007954, 0.0010953895, 0.017006148)\n",
      "   validation loss 0.0002346355322515592, (0.00023429512, 0.0031923065, 0.0017033813, 0.017006148)\n",
      "decoder loss ratio: 0.000489, decoder SINDy loss  ratio: 0.108857\n",
      "Epoch 284\n",
      "   training loss 0.00016649815370328724, (0.00016621544, 0.0021690417, 0.0011360964, 0.01691053)\n",
      "   validation loss 0.00022839901794213802, (0.00022805826, 0.0033629418, 0.0017165953, 0.01691053)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.109702\n",
      "Epoch 285\n",
      "   training loss 0.0002152476372430101, (0.00021496674, 0.002112237, 0.0011179794, 0.016908988)\n",
      "   validation loss 0.0002321429637959227, (0.00023180265, 0.0034469978, 0.0017122148, 0.016908988)\n",
      "decoder loss ratio: 0.000484, decoder SINDy loss  ratio: 0.109422\n",
      "Epoch 286\n",
      "   training loss 0.00021988037042319775, (0.000219601, 0.0020043498, 0.0010981258, 0.016956104)\n",
      "   validation loss 0.00030918250558897853, (0.00030884406, 0.0033680147, 0.0016890317, 0.016956104)\n",
      "decoder loss ratio: 0.000644, decoder SINDy loss  ratio: 0.107940\n",
      "Epoch 287\n",
      "   training loss 0.000158461625687778, (0.0001581824, 0.0020554943, 0.0010988454, 0.016933938)\n",
      "   validation loss 0.0003113428538199514, (0.00031100435, 0.0032931778, 0.0016918739, 0.016933938)\n",
      "decoder loss ratio: 0.000649, decoder SINDy loss  ratio: 0.108122\n",
      "Epoch 288\n",
      "   training loss 0.00015435997920576483, (0.00015408022, 0.002138912, 0.0011026434, 0.016950332)\n",
      "   validation loss 0.00025628769071772695, (0.00025594776, 0.0033908377, 0.0017043927, 0.016950332)\n",
      "decoder loss ratio: 0.000534, decoder SINDy loss  ratio: 0.108922\n",
      "Epoch 289\n",
      "   training loss 0.0001282965240534395, (0.00012801736, 0.0021429642, 0.0010934651, 0.016981732)\n",
      "   validation loss 0.0001921812363434583, (0.00019184107, 0.0035135904, 0.0017033771, 0.016981732)\n",
      "decoder loss ratio: 0.000400, decoder SINDy loss  ratio: 0.108857\n",
      "Epoch 290\n",
      "   training loss 0.00012447344488464296, (0.00012419638, 0.002014423, 0.0010850867, 0.016855493)\n",
      "   validation loss 0.00025292442296631634, (0.0002525872, 0.0033874726, 0.0016866012, 0.016855493)\n",
      "decoder loss ratio: 0.000527, decoder SINDy loss  ratio: 0.107785\n",
      "Epoch 291\n",
      "   training loss 0.00012694246834143996, (0.00012666246, 0.0020772151, 0.0011141171, 0.016859416)\n",
      "   validation loss 0.0002938987745437771, (0.00029356018, 0.0033429028, 0.001699858, 0.016859416)\n",
      "decoder loss ratio: 0.000612, decoder SINDy loss  ratio: 0.108632\n",
      "Epoch 292\n",
      "   training loss 0.00015295871708076447, (0.00015267993, 0.002103049, 0.0010913666, 0.016964735)\n",
      "   validation loss 0.00027009713812731206, (0.00026975817, 0.0033679232, 0.0016931462, 0.016964735)\n",
      "decoder loss ratio: 0.000563, decoder SINDy loss  ratio: 0.108203\n",
      "Epoch 293\n",
      "   training loss 0.00013124839460942894, (0.00013096922, 0.0022845136, 0.0010933547, 0.016984671)\n",
      "   validation loss 0.000294337747618556, (0.00029399723, 0.003724657, 0.0017067904, 0.016984671)\n",
      "decoder loss ratio: 0.000613, decoder SINDy loss  ratio: 0.109075\n",
      "Epoch 294\n",
      "   training loss 0.00015691723092459142, (0.00015663818, 0.0021530916, 0.0010917573, 0.016987547)\n",
      "   validation loss 0.0002302386419614777, (0.0002298993, 0.003595053, 0.0016945546, 0.016987547)\n",
      "decoder loss ratio: 0.000480, decoder SINDy loss  ratio: 0.108293\n",
      "Epoch 295\n",
      "   training loss 0.00013599735393654555, (0.00013571806, 0.00207158, 0.0011006037, 0.016923489)\n",
      "   validation loss 0.00023398263147100806, (0.00023364443, 0.0034682879, 0.0016896786, 0.016923489)\n",
      "decoder loss ratio: 0.000487, decoder SINDy loss  ratio: 0.107981\n",
      "Epoch 296\n",
      "   training loss 0.00012086857168469578, (0.00012059038, 0.002053236, 0.00108395, 0.016979083)\n",
      "   validation loss 0.00025717346579767764, (0.00025683627, 0.0033767591, 0.0016739581, 0.016979083)\n",
      "decoder loss ratio: 0.000536, decoder SINDy loss  ratio: 0.106977\n",
      "Epoch 297\n",
      "   training loss 0.00020080094691365957, (0.00020052, 0.0021950789, 0.0011205566, 0.01689065)\n",
      "   validation loss 0.0002979951968882233, (0.00029765652, 0.0034032862, 0.0016977626, 0.01689065)\n",
      "decoder loss ratio: 0.000621, decoder SINDy loss  ratio: 0.108498\n",
      "Epoch 298\n",
      "   training loss 0.00017015637422446162, (0.00016987673, 0.0021695166, 0.0011063357, 0.016900599)\n",
      "   validation loss 0.0002708835818339139, (0.00027054612, 0.0034613884, 0.0016846736, 0.016900599)\n",
      "decoder loss ratio: 0.000564, decoder SINDy loss  ratio: 0.107662\n",
      "Epoch 299\n",
      "   training loss 7.322253077290952e-05, (7.29461e-05, 0.0019388878, 0.0010683185, 0.01695939)\n",
      "   validation loss 0.0002578160201665014, (0.00025747708, 0.0033345178, 0.0016935635, 0.01695939)\n",
      "decoder loss ratio: 0.000537, decoder SINDy loss  ratio: 0.108230\n",
      "Epoch 300\n",
      "   training loss 0.00020289835811126977, (0.00020261949, 0.002211205, 0.0010925127, 0.016961807)\n",
      "   validation loss 0.0002922588028013706, (0.00029191884, 0.0035933687, 0.0017035553, 0.016961807)\n",
      "decoder loss ratio: 0.000609, decoder SINDy loss  ratio: 0.108868\n",
      "Epoch 301\n",
      "   training loss 8.293867722386494e-05, (8.2661034e-05, 0.0021057087, 0.001076338, 0.017000856)\n",
      "   validation loss 0.00019400239398237318, (0.0001936641, 0.0035060241, 0.0016828247, 0.017000856)\n",
      "decoder loss ratio: 0.000404, decoder SINDy loss  ratio: 0.107543\n",
      "Epoch 302\n",
      "   training loss 9.469333599554375e-05, (9.4414034e-05, 0.002134441, 0.0010990206, 0.016939785)\n",
      "   validation loss 0.0002138370182365179, (0.0002134998, 0.003393245, 0.0016781291, 0.016939785)\n",
      "decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.107243\n",
      "Epoch 303\n",
      "   training loss 0.0002471753105055541, (0.00024689466, 0.0022777508, 0.0011129894, 0.01693513)\n",
      "   validation loss 0.0003534512361511588, (0.00035311366, 0.003479856, 0.0016823168, 0.01693513)\n",
      "decoder loss ratio: 0.000737, decoder SINDy loss  ratio: 0.107511\n",
      "Epoch 304\n",
      "   training loss 0.00022155381157062948, (0.00022127564, 0.0019812945, 0.001084945, 0.01696754)\n",
      "   validation loss 0.00033853566856123507, (0.00033819565, 0.0033916843, 0.0017033959, 0.01696754)\n",
      "decoder loss ratio: 0.000706, decoder SINDy loss  ratio: 0.108858\n",
      "Epoch 305\n",
      "   training loss 0.0001777069119270891, (0.0001774281, 0.002213088, 0.0010926018, 0.016956164)\n",
      "   validation loss 0.00025326284230686724, (0.0002529235, 0.0036346493, 0.0016979038, 0.016956164)\n",
      "decoder loss ratio: 0.000528, decoder SINDy loss  ratio: 0.108507\n",
      "Epoch 306\n",
      "   training loss 0.00014055159408599138, (0.00014027306, 0.0022347157, 0.0010826339, 0.017027644)\n",
      "   validation loss 0.000245316099608317, (0.00024497733, 0.0035740219, 0.0016846823, 0.017027644)\n",
      "decoder loss ratio: 0.000511, decoder SINDy loss  ratio: 0.107662\n",
      "Epoch 307\n",
      "   training loss 9.227729606209323e-05, (9.1998365e-05, 0.0021726552, 0.0010915291, 0.016977796)\n",
      "   validation loss 0.0001936344342539087, (0.00019329658, 0.0035078544, 0.0016807723, 0.016977796)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.107412\n",
      "Epoch 308\n",
      "   training loss 0.00010937528713839129, (0.00010909754, 0.0021322144, 0.001083006, 0.01694435)\n",
      "   validation loss 0.00030150709790177643, (0.00030117057, 0.003451994, 0.0016707202, 0.01694435)\n",
      "decoder loss ratio: 0.000628, decoder SINDy loss  ratio: 0.106770\n",
      "Epoch 309\n",
      "   training loss 0.00012904373579658568, (0.00012876593, 0.0021679346, 0.0010805263, 0.016976526)\n",
      "   validation loss 0.0003046898345928639, (0.0003043518, 0.0034463138, 0.0016827289, 0.016976526)\n",
      "decoder loss ratio: 0.000635, decoder SINDy loss  ratio: 0.107537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310\n",
      "   training loss 0.0002200304443249479, (0.00021975239, 0.002312972, 0.0010841971, 0.01696373)\n",
      "   validation loss 0.0004029586852993816, (0.00040261867, 0.0038720365, 0.0017036346, 0.01696373)\n",
      "decoder loss ratio: 0.000840, decoder SINDy loss  ratio: 0.108873\n",
      "Epoch 311\n",
      "   training loss 0.00013027254317421466, (0.00012999475, 0.0023098753, 0.0010775395, 0.017004207)\n",
      "   validation loss 0.0002260648034280166, (0.00022572598, 0.0037837862, 0.0016879339, 0.017004207)\n",
      "decoder loss ratio: 0.000471, decoder SINDy loss  ratio: 0.107870\n",
      "Epoch 312\n",
      "   training loss 0.00010612041660351679, (0.000105842766, 0.0022253618, 0.0010798759, 0.016966084)\n",
      "   validation loss 0.00020069562015123665, (0.00020035762, 0.0036620037, 0.001683437, 0.016966084)\n",
      "decoder loss ratio: 0.000418, decoder SINDy loss  ratio: 0.107583\n",
      "Epoch 313\n",
      "   training loss 7.071503205224872e-05, (7.043744e-05, 0.0021206574, 0.0010761383, 0.016998285)\n",
      "   validation loss 0.0002203231560997665, (0.00021998628, 0.0035321119, 0.0016689943, 0.016998285)\n",
      "decoder loss ratio: 0.000459, decoder SINDy loss  ratio: 0.106660\n",
      "Epoch 314\n",
      "   training loss 0.0001594031200511381, (0.0001591222, 0.0022903753, 0.0011095472, 0.016996467)\n",
      "   validation loss 0.00027199822943657637, (0.00027166028, 0.0035482754, 0.0016798148, 0.016996467)\n",
      "decoder loss ratio: 0.000567, decoder SINDy loss  ratio: 0.107351\n",
      "Epoch 315\n",
      "   training loss 0.00023234574473463, (0.00023206758, 0.0021845696, 0.0010872402, 0.016944073)\n",
      "   validation loss 0.000380195677280426, (0.00037985793, 0.0035639047, 0.0016832179, 0.016944073)\n",
      "decoder loss ratio: 0.000792, decoder SINDy loss  ratio: 0.107569\n",
      "Epoch 316\n",
      "   training loss 0.0003520561149343848, (0.0003517776, 0.002261202, 0.0010702906, 0.017150247)\n",
      "   validation loss 0.0004995218478143215, (0.00049918, 0.0037674808, 0.0017034996, 0.017150247)\n",
      "decoder loss ratio: 0.001041, decoder SINDy loss  ratio: 0.108865\n",
      "Epoch 317\n",
      "   training loss 0.00013137332280166447, (0.00013109537, 0.0022702774, 0.0010771472, 0.01702424)\n",
      "   validation loss 0.00022249706671573222, (0.00022215807, 0.0036700822, 0.0016876047, 0.01702424)\n",
      "decoder loss ratio: 0.000463, decoder SINDy loss  ratio: 0.107849\n",
      "Epoch 318\n",
      "   training loss 0.0001505618420196697, (0.00015028351, 0.0022780837, 0.0010820939, 0.017012753)\n",
      "   validation loss 0.0002617380814626813, (0.0002614007, 0.0036386142, 0.0016723603, 0.017012753)\n",
      "decoder loss ratio: 0.000545, decoder SINDy loss  ratio: 0.106875\n",
      "Epoch 319\n",
      "   training loss 7.986274431459606e-05, (7.9585676e-05, 0.0022102203, 0.0010727218, 0.01698008)\n",
      "   validation loss 0.00022858456941321492, (0.00022824787, 0.0035819241, 0.0016689847, 0.01698008)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.106659\n",
      "Epoch 320\n",
      "   training loss 0.00022339654969982803, (0.00022311625, 0.0023478575, 0.001110759, 0.016922275)\n",
      "   validation loss 0.00030587351648136973, (0.00030553565, 0.0035626437, 0.0016865082, 0.016922275)\n",
      "decoder loss ratio: 0.000637, decoder SINDy loss  ratio: 0.107779\n",
      "Epoch 321\n",
      "   training loss 8.18250045995228e-05, (8.1548045e-05, 0.0022397172, 0.001072587, 0.01696957)\n",
      "   validation loss 0.00022218876983970404, (0.00022185232, 0.003613462, 0.00166772, 0.01696957)\n",
      "decoder loss ratio: 0.000463, decoder SINDy loss  ratio: 0.106578\n",
      "Epoch 322\n",
      "   training loss 0.00010611274774419144, (0.000105837025, 0.0020545872, 0.001053714, 0.017035259)\n",
      "   validation loss 0.000339438091032207, (0.00033910066, 0.0035598031, 0.001670883, 0.017035259)\n",
      "decoder loss ratio: 0.000707, decoder SINDy loss  ratio: 0.106780\n",
      "Epoch 323\n",
      "   training loss 0.00026973479543812573, (0.00026945496, 0.0024387166, 0.0011010086, 0.016974056)\n",
      "   validation loss 0.00041837405296973884, (0.00041803424, 0.0038019062, 0.0017008269, 0.016974056)\n",
      "decoder loss ratio: 0.000872, decoder SINDy loss  ratio: 0.108694\n",
      "Epoch 324\n",
      "   training loss 0.00022332562366500497, (0.00022304864, 0.0023758078, 0.0010613927, 0.017084006)\n",
      "   validation loss 0.000321580795571208, (0.00032124226, 0.0039920704, 0.0016769551, 0.017084006)\n",
      "decoder loss ratio: 0.000670, decoder SINDy loss  ratio: 0.107168\n",
      "Epoch 325\n",
      "   training loss 0.00025687276502139866, (0.00025659503, 0.0023978914, 0.0010787059, 0.016987216)\n",
      "   validation loss 0.00036411662586033344, (0.00036377838, 0.003960112, 0.0016837155, 0.016987216)\n",
      "decoder loss ratio: 0.000759, decoder SINDy loss  ratio: 0.107600\n",
      "Epoch 326\n",
      "   training loss 0.0001700723369140178, (0.00016979504, 0.0023446085, 0.0010714795, 0.017015431)\n",
      "   validation loss 0.00026260942104272544, (0.00026227252, 0.003828064, 0.0016675673, 0.017015431)\n",
      "decoder loss ratio: 0.000547, decoder SINDy loss  ratio: 0.106568\n",
      "Epoch 327\n",
      "   training loss 0.00013111974112689495, (0.00013084308, 0.0022799617, 0.0010708155, 0.016957311)\n",
      "   validation loss 0.00027208690880797803, (0.00027175125, 0.0036800415, 0.0016609362, 0.016957311)\n",
      "decoder loss ratio: 0.000567, decoder SINDy loss  ratio: 0.106145\n",
      "Epoch 328\n",
      "   training loss 0.00013699625560548156, (0.00013672016, 0.0023079237, 0.0010698679, 0.016911207)\n",
      "   validation loss 0.00024886929895728827, (0.00024853385, 0.0036969685, 0.0016633405, 0.016911207)\n",
      "decoder loss ratio: 0.000518, decoder SINDy loss  ratio: 0.106298\n",
      "Epoch 329\n",
      "   training loss 0.00010542930249357596, (0.00010515227, 0.0022304442, 0.001070928, 0.016993549)\n",
      "   validation loss 0.00031852585379965603, (0.00031818953, 0.003669951, 0.0016638672, 0.016993549)\n",
      "decoder loss ratio: 0.000664, decoder SINDy loss  ratio: 0.106332\n",
      "Epoch 330\n",
      "   training loss 0.00030634721042588353, (0.00030606345, 0.002730246, 0.0011377371, 0.017000012)\n",
      "   validation loss 0.00046739057870581746, (0.0004670491, 0.00411895, 0.0017147883, 0.017000012)\n",
      "decoder loss ratio: 0.000974, decoder SINDy loss  ratio: 0.109586\n",
      "Epoch 331\n",
      "   training loss 0.00027287195553071797, (0.000272597, 0.002469755, 0.0010450925, 0.017042097)\n",
      "   validation loss 0.00033203259226866066, (0.00033169455, 0.004113265, 0.0016760712, 0.017042097)\n",
      "decoder loss ratio: 0.000692, decoder SINDy loss  ratio: 0.107112\n",
      "Epoch 332\n",
      "   training loss 7.714259118074551e-05, (7.6866716e-05, 0.00236461, 0.0010631514, 0.016955992)\n",
      "   validation loss 0.00018302245007362217, (0.00018268668, 0.0037739633, 0.0016621785, 0.016955992)\n",
      "decoder loss ratio: 0.000381, decoder SINDy loss  ratio: 0.106224\n",
      "Epoch 333\n",
      "   training loss 0.0001546858693473041, (0.00015440896, 0.0023513876, 0.0010732627, 0.016959429)\n",
      "   validation loss 0.00023162532306741923, (0.00023128853, 0.003777928, 0.0016720361, 0.016959429)\n",
      "decoder loss ratio: 0.000483, decoder SINDy loss  ratio: 0.106854\n",
      "Epoch 334\n",
      "   training loss 7.420174370054156e-05, (7.392604e-05, 0.0022385998, 0.0010559309, 0.017010117)\n",
      "   validation loss 0.0002835678751580417, (0.00028323254, 0.0036880567, 0.0016521381, 0.017010117)\n",
      "decoder loss ratio: 0.000591, decoder SINDy loss  ratio: 0.105582\n",
      "Epoch 335\n",
      "   training loss 7.39004390197806e-05, (7.3622854e-05, 0.0022891995, 0.0010787394, 0.016971529)\n",
      "   validation loss 0.00024226438836194575, (0.00024192849, 0.0036451237, 0.0016617621, 0.016971529)\n",
      "decoder loss ratio: 0.000505, decoder SINDy loss  ratio: 0.106197\n",
      "Epoch 336\n",
      "   training loss 0.0001385502255288884, (0.00013827338, 0.0022956738, 0.0010650132, 0.017034132)\n",
      "   validation loss 0.00029071394237689674, (0.0002903779, 0.0035846925, 0.0016570052, 0.017034132)\n",
      "decoder loss ratio: 0.000606, decoder SINDy loss  ratio: 0.105893\n",
      "Epoch 337\n",
      "   training loss 0.00012565197539515793, (0.00012537304, 0.002595797, 0.0010899226, 0.016993178)\n",
      "   validation loss 0.0002566147886682302, (0.0002562757, 0.00413282, 0.0016913909, 0.016993178)\n",
      "decoder loss ratio: 0.000535, decoder SINDy loss  ratio: 0.108091\n",
      "Epoch 338\n",
      "   training loss 0.00033609310048632324, (0.00033581798, 0.0024394016, 0.0010480401, 0.017031964)\n",
      "   validation loss 0.0005144146853126585, (0.0005140771, 0.004036329, 0.001672735, 0.017031964)\n",
      "decoder loss ratio: 0.001072, decoder SINDy loss  ratio: 0.106899\n",
      "Epoch 339\n",
      "   training loss 6.598000618396327e-05, (6.570369e-05, 0.0023445075, 0.0010620786, 0.017011326)\n",
      "   validation loss 0.00018268011626787484, (0.00018234404, 0.003792534, 0.001659611, 0.017011326)\n",
      "decoder loss ratio: 0.000380, decoder SINDy loss  ratio: 0.106060\n",
      "Epoch 340\n",
      "   training loss 0.00012313295155763626, (0.00012285706, 0.0023485145, 0.001061568, 0.016973456)\n",
      "   validation loss 0.0002545475435908884, (0.0002542114, 0.0037951213, 0.0016640327, 0.016973456)\n",
      "decoder loss ratio: 0.000530, decoder SINDy loss  ratio: 0.106343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341\n",
      "   training loss 5.332331420504488e-05, (5.3048643e-05, 0.0021955548, 0.0010456466, 0.017010437)\n",
      "   validation loss 0.0002570360666140914, (0.00025670123, 0.0037093265, 0.0016473111, 0.017010437)\n",
      "decoder loss ratio: 0.000536, decoder SINDy loss  ratio: 0.105274\n",
      "Epoch 342\n",
      "   training loss 0.00011503270798129961, (0.00011475729, 0.0022719535, 0.0010532951, 0.017008856)\n",
      "   validation loss 0.00026955557405017316, (0.00026922015, 0.003704196, 0.0016534037, 0.017008856)\n",
      "decoder loss ratio: 0.000562, decoder SINDy loss  ratio: 0.105663\n",
      "Epoch 343\n",
      "   training loss 0.0002671799738891423, (0.00026690122, 0.0025483114, 0.0010882979, 0.016993083)\n",
      "   validation loss 0.00032545626163482666, (0.00032511857, 0.0040014884, 0.0016776184, 0.016993083)\n",
      "decoder loss ratio: 0.000678, decoder SINDy loss  ratio: 0.107211\n",
      "Epoch 344\n",
      "   training loss 0.00014062656555324793, (0.00014034969, 0.0023718663, 0.0010533625, 0.017153807)\n",
      "   validation loss 0.00032492788159288466, (0.00032459036, 0.0040360577, 0.0016598098, 0.017153807)\n",
      "decoder loss ratio: 0.000677, decoder SINDy loss  ratio: 0.106073\n",
      "Epoch 345\n",
      "   training loss 0.00020408381533343345, (0.00020380753, 0.0024389229, 0.0010565391, 0.017063733)\n",
      "   validation loss 0.000341824721544981, (0.0003414882, 0.0040106187, 0.0016587968, 0.017063733)\n",
      "decoder loss ratio: 0.000712, decoder SINDy loss  ratio: 0.106008\n",
      "Epoch 346\n",
      "   training loss 0.00027221982600167394, (0.00027194212, 0.002472907, 0.001075747, 0.017015249)\n",
      "   validation loss 0.00041840161429718137, (0.00041806465, 0.0040608332, 0.0016681113, 0.017015249)\n",
      "decoder loss ratio: 0.000872, decoder SINDy loss  ratio: 0.106603\n",
      "Epoch 347\n",
      "   training loss 0.00010001769260270521, (9.9742116e-05, 0.0024176044, 0.001058253, 0.016975014)\n",
      "   validation loss 0.00021379214012995362, (0.00021345723, 0.0038905037, 0.001651679, 0.016975014)\n",
      "decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.105553\n",
      "Epoch 348\n",
      "   training loss 0.00017532423953525722, (0.00017504775, 0.0024173108, 0.0010658357, 0.016991297)\n",
      "   validation loss 0.0002759756753221154, (0.00027564052, 0.0038409578, 0.001652426, 0.016991297)\n",
      "decoder loss ratio: 0.000575, decoder SINDy loss  ratio: 0.105601\n",
      "Epoch 349\n",
      "   training loss 0.00010065765673061833, (0.00010038215, 0.0022989216, 0.0010464342, 0.017086055)\n",
      "   validation loss 0.00035961513640359044, (0.0003592794, 0.0038150195, 0.0016487271, 0.017086055)\n",
      "decoder loss ratio: 0.000750, decoder SINDy loss  ratio: 0.105364\n",
      "Epoch 350\n",
      "   training loss 0.00014128164912108332, (0.00014100428, 0.0024276187, 0.0010675106, 0.017061997)\n",
      "   validation loss 0.00023528002202510834, (0.00023494408, 0.003824196, 0.0016531773, 0.017061997)\n",
      "decoder loss ratio: 0.000490, decoder SINDy loss  ratio: 0.105649\n",
      "Epoch 351\n",
      "   training loss 0.0001556399802211672, (0.0001553658, 0.002325123, 0.0010304283, 0.017113782)\n",
      "   validation loss 0.00036995357368141413, (0.00036961693, 0.0039433767, 0.0016552131, 0.017113782)\n",
      "decoder loss ratio: 0.000771, decoder SINDy loss  ratio: 0.105779\n",
      "Epoch 352\n",
      "   training loss 0.0001189609247376211, (0.00011868423, 0.0024654923, 0.0010600453, 0.017069295)\n",
      "   validation loss 0.00024368602316826582, (0.00024334992, 0.0038597237, 0.0016540927, 0.017069295)\n",
      "decoder loss ratio: 0.000508, decoder SINDy loss  ratio: 0.105707\n",
      "Epoch 353\n",
      "   training loss 0.0002483183052390814, (0.0002480414, 0.0024860173, 0.0010654812, 0.017033607)\n",
      "   validation loss 0.0003805164305958897, (0.0003801798, 0.004030288, 0.0016631299, 0.017033607)\n",
      "decoder loss ratio: 0.000793, decoder SINDy loss  ratio: 0.106285\n",
      "Epoch 354\n",
      "   training loss 0.00023039182997308671, (0.00023011302, 0.0025988028, 0.0010757386, 0.01712516)\n",
      "   validation loss 0.0003504407941363752, (0.00035010176, 0.0042196657, 0.0016778489, 0.01712516)\n",
      "decoder loss ratio: 0.000730, decoder SINDy loss  ratio: 0.107225\n",
      "Epoch 355\n",
      "   training loss 5.405236879596487e-05, (5.3777832e-05, 0.0024770289, 0.0010287438, 0.017166307)\n",
      "   validation loss 0.0001766713394317776, (0.00017633602, 0.003908168, 0.0016365106, 0.017166307)\n",
      "decoder loss ratio: 0.000368, decoder SINDy loss  ratio: 0.104584\n",
      "Epoch 356\n",
      "   training loss 0.00017926849250216037, (0.00017899228, 0.002497208, 0.0010549593, 0.01707121)\n",
      "   validation loss 0.0002632604737300426, (0.00026292467, 0.0039302395, 0.0016506586, 0.01707121)\n",
      "decoder loss ratio: 0.000549, decoder SINDy loss  ratio: 0.105488\n",
      "Epoch 357\n",
      "   training loss 8.213581168092787e-05, (8.186017e-05, 0.0023635735, 0.001039641, 0.017167594)\n",
      "   validation loss 0.000276287057204172, (0.00027595143, 0.0038743978, 0.0016394099, 0.017167594)\n",
      "decoder loss ratio: 0.000576, decoder SINDy loss  ratio: 0.104769\n",
      "Epoch 358\n",
      "   training loss 0.0001228495384566486, (0.00012257183, 0.0024929403, 0.0010710198, 0.017060576)\n",
      "   validation loss 0.00023343820066656917, (0.00023310217, 0.0038202412, 0.0016542489, 0.017060576)\n",
      "decoder loss ratio: 0.000486, decoder SINDy loss  ratio: 0.105717\n",
      "Epoch 359\n",
      "   training loss 0.00014135666424408555, (0.0001410816, 0.0023632164, 0.0010365682, 0.017140293)\n",
      "   validation loss 0.0003974532592110336, (0.0003971172, 0.0038944734, 0.0016466473, 0.017140293)\n",
      "decoder loss ratio: 0.000828, decoder SINDy loss  ratio: 0.105231\n",
      "Epoch 360\n",
      "   training loss 0.0001749111688695848, (0.00017463227, 0.0025879527, 0.0010783619, 0.017106924)\n",
      "   validation loss 0.0003162186767440289, (0.00031588145, 0.003914535, 0.0016616494, 0.017106924)\n",
      "decoder loss ratio: 0.000659, decoder SINDy loss  ratio: 0.106190\n",
      "Epoch 361\n",
      "   training loss 0.00019099396013189107, (0.00019071816, 0.0026466714, 0.001048483, 0.017095877)\n",
      "   validation loss 0.0002967837208416313, (0.00029644652, 0.004188607, 0.0016624484, 0.017095877)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.106241\n",
      "Epoch 362\n",
      "   training loss 9.122226038016379e-05, (9.0947186e-05, 0.0025377264, 0.0010395434, 0.017112348)\n",
      "   validation loss 0.00021739109070040286, (0.0002170568, 0.0038841586, 0.0016316007, 0.017112348)\n",
      "decoder loss ratio: 0.000453, decoder SINDy loss  ratio: 0.104270\n",
      "Epoch 363\n",
      "   training loss 0.00013899117766413838, (0.00013871546, 0.0025729362, 0.0010492839, 0.017078727)\n",
      "   validation loss 0.00021971626847516745, (0.00021938099, 0.00401194, 0.0016450173, 0.017078727)\n",
      "decoder loss ratio: 0.000458, decoder SINDy loss  ratio: 0.105127\n",
      "Epoch 364\n",
      "   training loss 8.89096554601565e-05, (8.863532e-05, 0.0024295452, 0.0010298414, 0.017134668)\n",
      "   validation loss 0.0002808951830957085, (0.00028055967, 0.0039666137, 0.001641795, 0.017134668)\n",
      "decoder loss ratio: 0.000585, decoder SINDy loss  ratio: 0.104921\n",
      "Epoch 365\n",
      "   training loss 8.481803524773568e-05, (8.454233e-05, 0.0024839817, 0.0010412491, 0.017157849)\n",
      "   validation loss 0.0001885654346551746, (0.00018823057, 0.0038221711, 0.001632925, 0.017157849)\n",
      "decoder loss ratio: 0.000393, decoder SINDy loss  ratio: 0.104355\n",
      "Epoch 366\n",
      "   training loss 0.00013763764582108706, (0.00013736254, 0.0024263654, 0.0010310404, 0.017199693)\n",
      "   validation loss 0.0003664160904008895, (0.0003660796, 0.003951766, 0.0016450853, 0.017199693)\n",
      "decoder loss ratio: 0.000764, decoder SINDy loss  ratio: 0.105132\n",
      "Epoch 367\n",
      "   training loss 0.00010357108840253204, (0.00010329527, 0.0025019122, 0.0010431355, 0.017150018)\n",
      "   validation loss 0.0002346670808037743, (0.00023433189, 0.0038654883, 0.0016369055, 0.017150018)\n",
      "decoder loss ratio: 0.000489, decoder SINDy loss  ratio: 0.104609\n",
      "Epoch 368\n",
      "   training loss 0.0002964940795209259, (0.00029621553, 0.0026561131, 0.0010734247, 0.017121557)\n",
      "   validation loss 0.0004219714319333434, (0.0004216348, 0.0040828483, 0.0016543783, 0.017121557)\n",
      "decoder loss ratio: 0.000880, decoder SINDy loss  ratio: 0.105726\n",
      "Epoch 369\n",
      "   training loss 0.0001580647221999243, (0.00015778815, 0.002553745, 0.0010529535, 0.01712733)\n",
      "   validation loss 0.00027505651814863086, (0.00027471926, 0.0041593406, 0.0016598349, 0.01712733)\n",
      "decoder loss ratio: 0.000573, decoder SINDy loss  ratio: 0.106074\n",
      "Epoch 370\n",
      "   training loss 5.826857886859216e-05, (5.79947e-05, 0.0025689425, 0.0010232315, 0.01715552)\n",
      "   validation loss 0.00019029639952350408, (0.0001899614, 0.003974629, 0.001634404, 0.01715552)\n",
      "decoder loss ratio: 0.000396, decoder SINDy loss  ratio: 0.104449\n",
      "Epoch 371\n",
      "   training loss 0.00013564103574026376, (0.00013536685, 0.0025733737, 0.0010349686, 0.017068954)\n",
      "   validation loss 0.00024235702585428953, (0.00024202243, 0.0039752778, 0.0016389182, 0.017068954)\n",
      "decoder loss ratio: 0.000505, decoder SINDy loss  ratio: 0.104738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372\n",
      "   training loss 7.73610663600266e-05, (7.708534e-05, 0.0024011089, 0.0010291701, 0.017280813)\n",
      "   validation loss 0.0002588033676147461, (0.00025846733, 0.003851138, 0.0016321248, 0.017280813)\n",
      "decoder loss ratio: 0.000539, decoder SINDy loss  ratio: 0.104303\n",
      "Epoch 373\n",
      "   training loss 8.207184873754159e-05, (8.179665e-05, 0.0024898662, 0.0010402475, 0.01711708)\n",
      "   validation loss 0.00019925847300328314, (0.00019892432, 0.0038035247, 0.0016298398, 0.01711708)\n",
      "decoder loss ratio: 0.000415, decoder SINDy loss  ratio: 0.104157\n",
      "Epoch 374\n",
      "   training loss 0.00012905104085803032, (0.00012877617, 0.0024030907, 0.0010260402, 0.017226886)\n",
      "   validation loss 0.0004169934836681932, (0.0004166568, 0.0038955184, 0.0016441729, 0.017226886)\n",
      "decoder loss ratio: 0.000869, decoder SINDy loss  ratio: 0.105073\n",
      "Epoch 375\n",
      "   training loss 0.0001092308884835802, (0.00010895066, 0.0025978666, 0.0010783968, 0.017239003)\n",
      "   validation loss 0.0002210224629379809, (0.00022068524, 0.0038169327, 0.0016483597, 0.017239003)\n",
      "decoder loss ratio: 0.000460, decoder SINDy loss  ratio: 0.105341\n",
      "Epoch 376\n",
      "   training loss 0.00019675851217471063, (0.0001964827, 0.0026392778, 0.0010452061, 0.017129138)\n",
      "   validation loss 0.00033314136089757085, (0.00033280542, 0.004121356, 0.0016465243, 0.017129138)\n",
      "decoder loss ratio: 0.000694, decoder SINDy loss  ratio: 0.105224\n",
      "Epoch 377\n",
      "   training loss 8.937941311160102e-05, (8.910366e-05, 0.0025935713, 0.0010427025, 0.017148025)\n",
      "   validation loss 0.00020897948706988245, (0.00020864481, 0.0040180143, 0.0016320166, 0.017148025)\n",
      "decoder loss ratio: 0.000435, decoder SINDy loss  ratio: 0.104296\n",
      "Epoch 378\n",
      "   training loss 0.00011252249532844871, (0.00011224569, 0.002632455, 0.0010510553, 0.017169615)\n",
      "   validation loss 0.0002020774409174919, (0.00020174282, 0.0039206175, 0.0016292398, 0.017169615)\n",
      "decoder loss ratio: 0.000421, decoder SINDy loss  ratio: 0.104119\n",
      "Epoch 379\n",
      "   training loss 0.0001044996315613389, (0.00010422467, 0.002558795, 0.0010312815, 0.017182637)\n",
      "   validation loss 0.00028281041886657476, (0.00028247584, 0.0039628027, 0.0016273966, 0.017182637)\n",
      "decoder loss ratio: 0.000589, decoder SINDy loss  ratio: 0.104001\n",
      "Epoch 380\n",
      "   training loss 8.153462840709835e-05, (8.125966e-05, 0.002497007, 0.0010321203, 0.017175764)\n",
      "   validation loss 0.00024379005481023341, (0.00024345545, 0.0038913363, 0.0016285385, 0.017175764)\n",
      "decoder loss ratio: 0.000508, decoder SINDy loss  ratio: 0.104074\n",
      "Epoch 381\n",
      "   training loss 0.00021724375255871564, (0.00021696545, 0.0026930105, 0.0010694388, 0.017135771)\n",
      "   validation loss 0.00028451031539589167, (0.00028417428, 0.0039805486, 0.0016467023, 0.017135771)\n",
      "decoder loss ratio: 0.000593, decoder SINDy loss  ratio: 0.105235\n",
      "Epoch 382\n",
      "   training loss 0.0001434619043720886, (0.00014318543, 0.0026332336, 0.0010452843, 0.01719457)\n",
      "   validation loss 0.00027698802296072245, (0.00027665164, 0.004116088, 0.001644297, 0.01719457)\n",
      "decoder loss ratio: 0.000577, decoder SINDy loss  ratio: 0.105081\n",
      "Epoch 383\n",
      "   training loss 6.853954255348071e-05, (6.826457e-05, 0.0026547748, 0.0010305366, 0.017191889)\n",
      "   validation loss 0.00017298819147981703, (0.00017265392, 0.003947383, 0.0016235214, 0.017191889)\n",
      "decoder loss ratio: 0.000360, decoder SINDy loss  ratio: 0.103754\n",
      "Epoch 384\n",
      "   training loss 0.00011887357686646283, (0.000118598415, 0.0026112602, 0.0010321591, 0.01719453)\n",
      "   validation loss 0.0002662582555785775, (0.0002659236, 0.003993649, 0.0016272774, 0.01719453)\n",
      "decoder loss ratio: 0.000555, decoder SINDy loss  ratio: 0.103994\n",
      "Epoch 385\n",
      "   training loss 0.00011632221139734611, (0.00011604572, 0.002519909, 0.0010372645, 0.017276963)\n",
      "   validation loss 0.0002927301393356174, (0.00029239396, 0.0039930353, 0.001634312, 0.017276963)\n",
      "decoder loss ratio: 0.000610, decoder SINDy loss  ratio: 0.104443\n",
      "Epoch 386\n",
      "   training loss 8.7200831330847e-05, (8.692306e-05, 0.0027197732, 0.0010549945, 0.017227225)\n",
      "   validation loss 0.00018316942441742867, (0.00018283405, 0.0039497893, 0.0016311373, 0.017227225)\n",
      "decoder loss ratio: 0.000381, decoder SINDy loss  ratio: 0.104240\n",
      "Epoch 387\n",
      "   training loss 0.0001451274729333818, (0.00014485189, 0.002708315, 0.0010359574, 0.017198842)\n",
      "   validation loss 0.00027760895318351686, (0.0002772736, 0.0041165496, 0.0016340006, 0.017198842)\n",
      "decoder loss ratio: 0.000578, decoder SINDy loss  ratio: 0.104423\n",
      "Epoch 388\n",
      "   training loss 7.849019311834127e-05, (7.821388e-05, 0.0026450146, 0.0010421097, 0.01720977)\n",
      "   validation loss 0.00020700089226011187, (0.0002066662, 0.0040288763, 0.001625994, 0.01720977)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.103912\n",
      "Epoch 389\n",
      "   training loss 0.00011206824274268001, (0.000111794056, 0.002592332, 0.0010291587, 0.017126514)\n",
      "   validation loss 0.00030573332333005965, (0.00030540008, 0.003996802, 0.0016196176, 0.017126514)\n",
      "decoder loss ratio: 0.000637, decoder SINDy loss  ratio: 0.103504\n",
      "Epoch 390\n",
      "   training loss 0.00011889166489709169, (0.00011861581, 0.0026172202, 0.0010405574, 0.017180122)\n",
      "   validation loss 0.00028848942019976676, (0.0002881546, 0.004052983, 0.0016301821, 0.017180122)\n",
      "decoder loss ratio: 0.000601, decoder SINDy loss  ratio: 0.104179\n",
      "Epoch 391\n",
      "   training loss 0.00018021198047790676, (0.00017993132, 0.0029198348, 0.0010894361, 0.017171336)\n",
      "   validation loss 0.0003199100901838392, (0.0003195728, 0.0041635456, 0.0016557977, 0.017171336)\n",
      "decoder loss ratio: 0.000667, decoder SINDy loss  ratio: 0.105816\n",
      "Epoch 392\n",
      "   training loss 8.824164979159832e-05, (8.796701e-05, 0.0027390237, 0.0010150293, 0.017314222)\n",
      "   validation loss 0.0002647755900397897, (0.0002644403, 0.0040975646, 0.001621234, 0.017314222)\n",
      "decoder loss ratio: 0.000552, decoder SINDy loss  ratio: 0.103607\n",
      "Epoch 393\n",
      "   training loss 0.00018309774168301374, (0.00018282233, 0.00283039, 0.001030161, 0.017239222)\n",
      "   validation loss 0.00029469100991263986, (0.0002943557, 0.004150017, 0.0016292387, 0.017239222)\n",
      "decoder loss ratio: 0.000614, decoder SINDy loss  ratio: 0.104119\n",
      "Epoch 394\n",
      "   training loss 0.00012058106949552894, (0.000120306504, 0.002661601, 0.001027485, 0.017181396)\n",
      "   validation loss 0.00027015601517632604, (0.00026982123, 0.0041859252, 0.0016298163, 0.017181396)\n",
      "decoder loss ratio: 0.000563, decoder SINDy loss  ratio: 0.104156\n",
      "Epoch 395\n",
      "   training loss 9.024503378896043e-05, (8.997122e-05, 0.0024673215, 0.0010117306, 0.01726469)\n",
      "   validation loss 0.0002461798139847815, (0.00024584495, 0.004015384, 0.00162223, 0.01726469)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.103671\n",
      "Epoch 396\n",
      "   training loss 0.000143098906846717, (0.00014282107, 0.0027077796, 0.0010594042, 0.017190317)\n",
      "   validation loss 0.0002370341680943966, (0.00023669888, 0.004004153, 0.0016339014, 0.017190317)\n",
      "decoder loss ratio: 0.000494, decoder SINDy loss  ratio: 0.104417\n",
      "Epoch 397\n",
      "   training loss 0.00012111480464227498, (0.000120840225, 0.002565702, 0.0010218207, 0.01723995)\n",
      "   validation loss 0.00031248843879438937, (0.0003121529, 0.0040969816, 0.0016312423, 0.01723995)\n",
      "decoder loss ratio: 0.000651, decoder SINDy loss  ratio: 0.104247\n",
      "Epoch 398\n",
      "   training loss 8.681603503646329e-05, (8.653993e-05, 0.0026822498, 0.0010342572, 0.01726773)\n",
      "   validation loss 0.00019883771892637014, (0.0001985028, 0.003979183, 0.0016223728, 0.01726773)\n",
      "decoder loss ratio: 0.000414, decoder SINDy loss  ratio: 0.103680\n",
      "Epoch 399\n",
      "   training loss 0.00016575718473177403, (0.00016548131, 0.0027308967, 0.0010396988, 0.017189698)\n",
      "   validation loss 0.00031085588852874935, (0.0003105213, 0.004155489, 0.0016269065, 0.017189698)\n",
      "decoder loss ratio: 0.000648, decoder SINDy loss  ratio: 0.103970\n",
      "Epoch 400\n",
      "   training loss 8.180474833352491e-05, (8.152964e-05, 0.0027376758, 0.0010288984, 0.017222434)\n",
      "   validation loss 0.00022528774570673704, (0.00022495365, 0.0041371533, 0.0016187737, 0.017222434)\n",
      "decoder loss ratio: 0.000469, decoder SINDy loss  ratio: 0.103450\n",
      "Epoch 401\n",
      "   training loss 0.0001381781476084143, (0.00013790166, 0.0028010986, 0.0010445795, 0.017202547)\n",
      "   validation loss 0.00023277560831047595, (0.00023244123, 0.004123292, 0.0016235681, 0.017202547)\n",
      "decoder loss ratio: 0.000485, decoder SINDy loss  ratio: 0.103757\n",
      "Epoch 402\n",
      "   training loss 0.00010317222768208012, (0.00010289733, 0.0027050842, 0.0010254019, 0.017235741)\n",
      "   validation loss 0.00025112013099715114, (0.00025078587, 0.0041062124, 0.0016191691, 0.017235741)\n",
      "decoder loss ratio: 0.000523, decoder SINDy loss  ratio: 0.103475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403\n",
      "   training loss 0.00015844820882193744, (0.00015817324, 0.0026385842, 0.0010104165, 0.017392049)\n",
      "   validation loss 0.00038905953988432884, (0.00038872467, 0.0040410166, 0.0016094181, 0.017392049)\n",
      "decoder loss ratio: 0.000811, decoder SINDy loss  ratio: 0.102852\n",
      "Epoch 404\n",
      "   training loss 0.00013095707981847227, (0.00013068192, 0.0028199938, 0.0010233524, 0.017283456)\n",
      "   validation loss 0.00025227724108844995, (0.00025194272, 0.0041426485, 0.0016166539, 0.017283456)\n",
      "decoder loss ratio: 0.000526, decoder SINDy loss  ratio: 0.103315\n",
      "Epoch 405\n",
      "   training loss 0.00016699728439562023, (0.00016672218, 0.0027974292, 0.0010231984, 0.017278377)\n",
      "   validation loss 0.00027178999152965844, (0.00027145524, 0.0042683925, 0.0016194847, 0.017278377)\n",
      "decoder loss ratio: 0.000566, decoder SINDy loss  ratio: 0.103496\n",
      "Epoch 406\n",
      "   training loss 8.95192424650304e-05, (8.92459e-05, 0.0025487638, 0.0010117203, 0.017217452)\n",
      "   validation loss 0.0002768409322015941, (0.00027650676, 0.0041581313, 0.0016198218, 0.017217452)\n",
      "decoder loss ratio: 0.000577, decoder SINDy loss  ratio: 0.103517\n",
      "Epoch 407\n",
      "   training loss 6.655264587607235e-05, (6.6277644e-05, 0.0025094242, 0.0010300988, 0.017198712)\n",
      "   validation loss 0.00021774751076009125, (0.00021741344, 0.0040212995, 0.0016207504, 0.017198712)\n",
      "decoder loss ratio: 0.000454, decoder SINDy loss  ratio: 0.103576\n",
      "Epoch 408\n",
      "   training loss 0.0003610907879192382, (0.00036081244, 0.002847854, 0.001060802, 0.017226769)\n",
      "   validation loss 0.0004242073919158429, (0.0004238709, 0.004271726, 0.0016424634, 0.017226769)\n",
      "decoder loss ratio: 0.000884, decoder SINDy loss  ratio: 0.104964\n",
      "Epoch 409\n",
      "   training loss 0.00013698234397452325, (0.00013670717, 0.002665118, 0.0010145012, 0.01737262)\n",
      "   validation loss 0.00023542869894299656, (0.00023509293, 0.00429311, 0.0016204938, 0.01737262)\n",
      "decoder loss ratio: 0.000490, decoder SINDy loss  ratio: 0.103560\n",
      "Epoch 410\n",
      "   training loss 5.5246207921300083e-05, (5.4973167e-05, 0.0026495985, 0.0009998874, 0.017305275)\n",
      "   validation loss 0.00017854571342468262, (0.00017821223, 0.0040962687, 0.0016043757, 0.017305275)\n",
      "decoder loss ratio: 0.000372, decoder SINDy loss  ratio: 0.102530\n",
      "Epoch 411\n",
      "   training loss 9.913459507515654e-05, (9.886036e-05, 0.0026094404, 0.0010131368, 0.017292796)\n",
      "   validation loss 0.00025985861429944634, (0.00025952517, 0.0040095737, 0.0016049542, 0.017292796)\n",
      "decoder loss ratio: 0.000541, decoder SINDy loss  ratio: 0.102567\n",
      "Epoch 412\n",
      "   training loss 6.874527753097937e-05, (6.8470225e-05, 0.0025912463, 0.0010186457, 0.017319234)\n",
      "   validation loss 0.00022315695241559297, (0.00022282335, 0.0039626663, 0.0016040779, 0.017319234)\n",
      "decoder loss ratio: 0.000465, decoder SINDy loss  ratio: 0.102511\n",
      "Epoch 413\n",
      "   training loss 0.0003655172185972333, (0.0003652415, 0.0027056923, 0.0010362947, 0.017208304)\n",
      "   validation loss 0.0005373141611926258, (0.000536979, 0.004251544, 0.001631212, 0.017208304)\n",
      "decoder loss ratio: 0.001120, decoder SINDy loss  ratio: 0.104245\n",
      "Epoch 414\n",
      "   training loss 0.00016355984553229064, (0.00016328343, 0.0025913254, 0.0010364604, 0.017275406)\n",
      "   validation loss 0.00029323887429200113, (0.00029290214, 0.004185035, 0.0016397473, 0.017275406)\n",
      "decoder loss ratio: 0.000611, decoder SINDy loss  ratio: 0.104791\n",
      "Epoch 415\n",
      "   training loss 5.5766118748579174e-05, (5.5491913e-05, 0.002703708, 0.0010160286, 0.017260293)\n",
      "   validation loss 0.0001937753550009802, (0.00019344132, 0.004114402, 0.0016144251, 0.017260293)\n",
      "decoder loss ratio: 0.000404, decoder SINDy loss  ratio: 0.103172\n",
      "Epoch 416\n",
      "   training loss 0.00011852987518068403, (0.000118254924, 0.0027102802, 0.0010205082, 0.017289631)\n",
      "   validation loss 0.00025587878189980984, (0.00025554426, 0.0041368594, 0.0016161893, 0.017289631)\n",
      "decoder loss ratio: 0.000533, decoder SINDy loss  ratio: 0.103285\n",
      "Epoch 417\n",
      "   training loss 8.880604582373053e-05, (8.853141e-05, 0.0024788987, 0.0010109695, 0.017353974)\n",
      "   validation loss 0.00032668901258148253, (0.00032635388, 0.0039864145, 0.0016158228, 0.017353974)\n",
      "decoder loss ratio: 0.000681, decoder SINDy loss  ratio: 0.103262\n",
      "Epoch 418\n",
      "   training loss 0.0001128358198911883, (0.0001125588, 0.0026584438, 0.0010356699, 0.017345177)\n",
      "   validation loss 0.00023829011479392648, (0.00023795567, 0.004010593, 0.0016099472, 0.017345177)\n",
      "decoder loss ratio: 0.000496, decoder SINDy loss  ratio: 0.102886\n",
      "Epoch 419\n",
      "   training loss 0.00013112177839502692, (0.00013084593, 0.0028224944, 0.0010252728, 0.017330656)\n",
      "   validation loss 0.00027492904337123036, (0.00027459432, 0.0042420933, 0.0016139628, 0.017330656)\n",
      "decoder loss ratio: 0.000573, decoder SINDy loss  ratio: 0.103143\n",
      "Epoch 420\n",
      "   training loss 0.00012205791426822543, (0.000121782214, 0.0025639087, 0.001020866, 0.017360812)\n",
      "   validation loss 0.0003359045658726245, (0.0003355677, 0.0042028297, 0.0016327159, 0.017360812)\n",
      "decoder loss ratio: 0.000700, decoder SINDy loss  ratio: 0.104341\n",
      "Epoch 421\n",
      "   training loss 9.363096614833921e-05, (9.335531e-05, 0.0026257897, 0.0010176558, 0.017389048)\n",
      "   validation loss 0.00023581973800901324, (0.0002354853, 0.004070555, 0.0016053974, 0.017389048)\n",
      "decoder loss ratio: 0.000491, decoder SINDy loss  ratio: 0.102595\n",
      "Epoch 422\n",
      "   training loss 0.00014596356777474284, (0.00014568791, 0.0027461853, 0.0010297105, 0.017269365)\n",
      "   validation loss 0.00029042887035757303, (0.00029009455, 0.0042748144, 0.0016161436, 0.017269365)\n",
      "decoder loss ratio: 0.000605, decoder SINDy loss  ratio: 0.103282\n",
      "Epoch 423\n",
      "   training loss 0.00010913873120443895, (0.00010886304, 0.0024537558, 0.001020439, 0.017364666)\n",
      "   validation loss 0.00029400919447652996, (0.0002936731, 0.004153042, 0.0016245163, 0.017364666)\n",
      "decoder loss ratio: 0.000613, decoder SINDy loss  ratio: 0.103817\n",
      "Epoch 424\n",
      "   training loss 7.422248745569959e-05, (7.3946416e-05, 0.0026955886, 0.0010216427, 0.017390966)\n",
      "   validation loss 0.0002310212585143745, (0.00023068674, 0.0041595525, 0.0016060333, 0.017390966)\n",
      "decoder loss ratio: 0.000481, decoder SINDy loss  ratio: 0.102636\n",
      "Epoch 425\n",
      "   training loss 0.0001423180365236476, (0.00014204078, 0.0027188521, 0.0010378106, 0.01734805)\n",
      "   validation loss 0.0002672387345228344, (0.0002669038, 0.0043175705, 0.0016143791, 0.01734805)\n",
      "decoder loss ratio: 0.000557, decoder SINDy loss  ratio: 0.103169\n",
      "Epoch 426\n",
      "   training loss 0.00011099370021838695, (0.000110718596, 0.0024680137, 0.0010194906, 0.017315373)\n",
      "   validation loss 0.0002943766303360462, (0.00029404103, 0.0041942904, 0.001624382, 0.017315373)\n",
      "decoder loss ratio: 0.000613, decoder SINDy loss  ratio: 0.103809\n",
      "Epoch 427\n",
      "   training loss 6.671175651717931e-05, (6.643463e-05, 0.002722503, 0.0010363457, 0.017349638)\n",
      "   validation loss 0.00020819142810069025, (0.00020785688, 0.0042161467, 0.0016104559, 0.017349638)\n",
      "decoder loss ratio: 0.000434, decoder SINDy loss  ratio: 0.102919\n",
      "Epoch 428\n",
      "   training loss 0.0001089526922442019, (0.00010867718, 0.0025570558, 0.0010236512, 0.017314898)\n",
      "   validation loss 0.00028567633125931025, (0.00028534236, 0.004203569, 0.0016082189, 0.017314898)\n",
      "decoder loss ratio: 0.000595, decoder SINDy loss  ratio: 0.102776\n",
      "Epoch 429\n",
      "   training loss 0.00015627899847459048, (0.0001560045, 0.0024737676, 0.0010051593, 0.017397845)\n",
      "   validation loss 0.00039859602111391723, (0.00039826104, 0.004110823, 0.0016099148, 0.017397845)\n",
      "decoder loss ratio: 0.000831, decoder SINDy loss  ratio: 0.102884\n",
      "Epoch 430\n",
      "   training loss 8.076677477220073e-05, (8.0491176e-05, 0.0027166072, 0.0010253184, 0.017306658)\n",
      "   validation loss 0.0002285030495841056, (0.0002281694, 0.00431179, 0.0016058756, 0.017306658)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.102626\n",
      "Epoch 431\n",
      "   training loss 0.00018448912305757403, (0.00018421409, 0.002671385, 0.0010204162, 0.017298898)\n",
      "   validation loss 0.0002957862743642181, (0.0002954525, 0.0044052377, 0.0016076617, 0.017298898)\n",
      "decoder loss ratio: 0.000616, decoder SINDy loss  ratio: 0.102740\n",
      "Epoch 432\n",
      "   training loss 0.00011777963663917035, (0.00011750583, 0.0025619972, 0.0010069569, 0.017310703)\n",
      "   validation loss 0.000247164280153811, (0.0002468305, 0.0042530755, 0.0016067424, 0.017310703)\n",
      "decoder loss ratio: 0.000515, decoder SINDy loss  ratio: 0.102681\n",
      "Epoch 433\n",
      "   training loss 9.56854346441105e-05, (9.541056e-05, 0.0026350843, 0.001020185, 0.017285408)\n",
      "   validation loss 0.00020612245134543628, (0.00020578975, 0.004185479, 0.0015985144, 0.017285408)\n",
      "decoder loss ratio: 0.000429, decoder SINDy loss  ratio: 0.102155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434\n",
      "   training loss 9.660608338890597e-05, (9.633211e-05, 0.0026075747, 0.0010102289, 0.017295387)\n",
      "   validation loss 0.00029678671853616834, (0.00029645325, 0.0042115073, 0.0016050165, 0.017295387)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.102571\n",
      "Epoch 435\n",
      "   training loss 0.0002918953832704574, (0.00029161648, 0.00293726, 0.0010519355, 0.017373087)\n",
      "   validation loss 0.0004054585879202932, (0.00040512337, 0.004288744, 0.0016149007, 0.017373087)\n",
      "decoder loss ratio: 0.000845, decoder SINDy loss  ratio: 0.103203\n",
      "Epoch 436\n",
      "   training loss 8.916293154470623e-05, (8.8889225e-05, 0.002826646, 0.0009961445, 0.017409092)\n",
      "   validation loss 0.00020154631056357175, (0.00020121278, 0.0044160085, 0.0015943915, 0.017409092)\n",
      "decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.101892\n",
      "Epoch 437\n",
      "   training loss 9.477439016336575e-05, (9.450079e-05, 0.0027965687, 0.001000052, 0.017359048)\n",
      "   validation loss 0.00019332169904373586, (0.00019298878, 0.004265937, 0.0015933451, 0.017359048)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.101825\n",
      "Epoch 438\n",
      "   training loss 0.00011062932753702626, (0.00011035646, 0.0027436595, 0.0010007492, 0.01727948)\n",
      "   validation loss 0.00023941081599332392, (0.0002390778, 0.004241014, 0.0016023184, 0.01727948)\n",
      "decoder loss ratio: 0.000499, decoder SINDy loss  ratio: 0.102399\n",
      "Epoch 439\n",
      "   training loss 9.096909343497828e-05, (9.06932e-05, 0.0026375598, 0.0010228253, 0.017360823)\n",
      "   validation loss 0.00028667974402196705, (0.0002863454, 0.0041027614, 0.0016073596, 0.017360823)\n",
      "decoder loss ratio: 0.000597, decoder SINDy loss  ratio: 0.102721\n",
      "Epoch 440\n",
      "   training loss 0.00021802281844429672, (0.00021774413, 0.0029792755, 0.0010533025, 0.017335445)\n",
      "   validation loss 0.00028013583505526185, (0.00027980204, 0.0043169577, 0.0016044385, 0.017335445)\n",
      "decoder loss ratio: 0.000584, decoder SINDy loss  ratio: 0.102534\n",
      "Epoch 441\n",
      "   training loss 0.00010831599502125755, (0.00010804158, 0.0028118372, 0.0010097813, 0.017343711)\n",
      "   validation loss 0.0002543239388614893, (0.00025399026, 0.004398797, 0.0016023525, 0.017343711)\n",
      "decoder loss ratio: 0.000530, decoder SINDy loss  ratio: 0.102401\n",
      "Epoch 442\n",
      "   training loss 0.0001085693875211291, (0.000108294975, 0.0027299682, 0.0010118207, 0.017323527)\n",
      "   validation loss 0.0002285293157910928, (0.00022819599, 0.004305603, 0.0016008957, 0.017323527)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.102308\n",
      "Epoch 443\n",
      "   training loss 0.00016041198978200555, (0.0001601365, 0.0028066274, 0.0010202317, 0.017346779)\n",
      "   validation loss 0.0002492530911695212, (0.00024891965, 0.004304651, 0.0015999415, 0.017346779)\n",
      "decoder loss ratio: 0.000519, decoder SINDy loss  ratio: 0.102247\n",
      "Epoch 444\n",
      "   training loss 0.0001078069326467812, (0.000107529515, 0.0027590476, 0.001028459, 0.017457407)\n",
      "   validation loss 0.00022248635650612414, (0.00022215112, 0.0042752605, 0.0016065305, 0.017457407)\n",
      "decoder loss ratio: 0.000463, decoder SINDy loss  ratio: 0.102668\n",
      "Epoch 445\n",
      "   training loss 0.0002363409148529172, (0.00023606181, 0.0031720877, 0.0010449573, 0.01746094)\n",
      "   validation loss 0.00033875962253659964, (0.0003384245, 0.0044533005, 0.0016051686, 0.01746094)\n",
      "decoder loss ratio: 0.000706, decoder SINDy loss  ratio: 0.102581\n",
      "Epoch 446\n",
      "   training loss 0.00015345339488703758, (0.00015317815, 0.0028948644, 0.001008291, 0.017442428)\n",
      "   validation loss 0.00027666837559081614, (0.00027633327, 0.004488991, 0.0016069222, 0.017442428)\n",
      "decoder loss ratio: 0.000576, decoder SINDy loss  ratio: 0.102693\n",
      "Epoch 447\n",
      "   training loss 5.740201231674291e-05, (5.7127625e-05, 0.0028742913, 0.0010034598, 0.017404169)\n",
      "   validation loss 0.00018748780712485313, (0.00018715454, 0.0043607317, 0.0015923043, 0.017404169)\n",
      "decoder loss ratio: 0.000390, decoder SINDy loss  ratio: 0.101759\n",
      "Epoch 448\n",
      "   training loss 9.154253348242491e-05, (9.126702e-05, 0.0028784499, 0.0010169919, 0.01738179)\n",
      "   validation loss 0.00021368500893004239, (0.00021335165, 0.0043708277, 0.0015953018, 0.01738179)\n",
      "decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.101950\n",
      "Epoch 449\n",
      "   training loss 0.0001219715632032603, (0.00012169496, 0.0028343312, 0.0010271579, 0.017388757)\n",
      "   validation loss 0.00024484231835231185, (0.0002445082, 0.0043135686, 0.00160212, 0.017388757)\n",
      "decoder loss ratio: 0.000510, decoder SINDy loss  ratio: 0.102386\n",
      "Epoch 450\n",
      "   training loss 6.0339687479427084e-05, (6.006442e-05, 0.002752403, 0.0010153721, 0.017373133)\n",
      "   validation loss 0.00020823140221182257, (0.00020789861, 0.0041929614, 0.0015905475, 0.017373133)\n",
      "decoder loss ratio: 0.000434, decoder SINDy loss  ratio: 0.101646\n",
      "Epoch 451\n",
      "   training loss 0.00017121304699685425, (0.00017093548, 0.0030851972, 0.0010354177, 0.01740304)\n",
      "   validation loss 0.00032535940408706665, (0.00032502442, 0.004541222, 0.0016094452, 0.01740304)\n",
      "decoder loss ratio: 0.000678, decoder SINDy loss  ratio: 0.102854\n",
      "Epoch 452\n",
      "   training loss 0.00011443680705269799, (0.000114162955, 0.002941263, 0.0010027785, 0.017357854)\n",
      "   validation loss 0.00022864386846777052, (0.00022830984, 0.004506989, 0.0016045505, 0.017357854)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.102541\n",
      "Epoch 453\n",
      "   training loss 9.467846393818036e-05, (9.44041e-05, 0.0028475532, 0.001002139, 0.01741509)\n",
      "   validation loss 0.00024698226479813457, (0.00024664876, 0.004331883, 0.0015934735, 0.01741509)\n",
      "decoder loss ratio: 0.000515, decoder SINDy loss  ratio: 0.101833\n",
      "Epoch 454\n",
      "   training loss 0.00012659044296015054, (0.00012631512, 0.002792333, 0.001018082, 0.01735178)\n",
      "   validation loss 0.00031682653934694827, (0.00031649292, 0.0042573153, 0.0016009428, 0.01735178)\n",
      "decoder loss ratio: 0.000660, decoder SINDy loss  ratio: 0.102311\n",
      "Epoch 455\n",
      "   training loss 9.712918836157769e-05, (9.685199e-05, 0.0029545862, 0.0010302421, 0.017417168)\n",
      "   validation loss 0.0001925723918247968, (0.00019223877, 0.004424383, 0.0015943985, 0.017417168)\n",
      "decoder loss ratio: 0.000401, decoder SINDy loss  ratio: 0.101892\n",
      "Epoch 456\n",
      "   training loss 8.156217518262565e-05, (8.1287944e-05, 0.0026809766, 0.0009992311, 0.017431239)\n",
      "   validation loss 0.00031384226167574525, (0.0003135078, 0.0044420473, 0.0016016961, 0.017431239)\n",
      "decoder loss ratio: 0.000654, decoder SINDy loss  ratio: 0.102359\n",
      "Epoch 457\n",
      "   training loss 0.00011848723806906492, (0.0001182113, 0.0027841243, 0.0010211007, 0.017382918)\n",
      "   validation loss 0.00025351191288791597, (0.00025317792, 0.004327571, 0.0016015206, 0.017382918)\n",
      "decoder loss ratio: 0.000528, decoder SINDy loss  ratio: 0.102348\n",
      "Epoch 458\n",
      "   training loss 0.00013876199955120683, (0.00013848505, 0.002932853, 0.0010281596, 0.017413802)\n",
      "   validation loss 0.00023683653853368014, (0.00023650276, 0.004470136, 0.0015963943, 0.017413802)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.102020\n",
      "Epoch 459\n",
      "   training loss 0.00012321630492806435, (0.00012294209, 0.0026675, 0.0009976027, 0.017446538)\n",
      "   validation loss 0.00030646356754004955, (0.00030612826, 0.0044397404, 0.0016083304, 0.017446538)\n",
      "decoder loss ratio: 0.000639, decoder SINDy loss  ratio: 0.102783\n",
      "Epoch 460\n",
      "   training loss 0.0001206806191476062, (0.000120405304, 0.0027833285, 0.0010056813, 0.017475005)\n",
      "   validation loss 0.00023754590074531734, (0.00023721231, 0.0042832, 0.0015884051, 0.017475005)\n",
      "decoder loss ratio: 0.000495, decoder SINDy loss  ratio: 0.101509\n",
      "Epoch 461\n",
      "   training loss 0.0002471562766004354, (0.00024687886, 0.0029734506, 0.0010370276, 0.017372573)\n",
      "   validation loss 0.00032510681194253266, (0.000324773, 0.004470621, 0.0016008695, 0.017372573)\n",
      "decoder loss ratio: 0.000678, decoder SINDy loss  ratio: 0.102306\n",
      "Epoch 462\n",
      "   training loss 0.0001418804458808154, (0.00014160488, 0.0028045892, 0.0010154597, 0.01740245)\n",
      "   validation loss 0.0002656855504028499, (0.00026535083, 0.0045006736, 0.001607143, 0.01740245)\n",
      "decoder loss ratio: 0.000554, decoder SINDy loss  ratio: 0.102707\n",
      "Epoch 463\n",
      "   training loss 5.858006625203416e-05, (5.830478e-05, 0.002867867, 0.0010123528, 0.017405093)\n",
      "   validation loss 0.000154268040205352, (0.0001539351, 0.0043595107, 0.0015887145, 0.017405093)\n",
      "decoder loss ratio: 0.000321, decoder SINDy loss  ratio: 0.101529\n",
      "Epoch 464\n",
      "   training loss 0.00012075771519448608, (0.00012048318, 0.0028874548, 0.001014936, 0.017304119)\n",
      "   validation loss 0.0001959961373358965, (0.00019566414, 0.0044002803, 0.0015896345, 0.017304119)\n",
      "decoder loss ratio: 0.000408, decoder SINDy loss  ratio: 0.101588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465\n",
      "   training loss 0.0001379157038172707, (0.00013763612, 0.0028217647, 0.0010444522, 0.017515086)\n",
      "   validation loss 0.00021892119548283517, (0.00021858532, 0.0043286984, 0.0016073248, 0.017515086)\n",
      "decoder loss ratio: 0.000456, decoder SINDy loss  ratio: 0.102719\n",
      "Epoch 466\n",
      "   training loss 0.00015621259808540344, (0.00015593521, 0.0030493278, 0.0010214148, 0.017524395)\n",
      "   validation loss 0.00029788020765408874, (0.00029754598, 0.0044702208, 0.0015898935, 0.017524395)\n",
      "decoder loss ratio: 0.000621, decoder SINDy loss  ratio: 0.101605\n",
      "Epoch 467\n",
      "   training loss 0.0001808919187169522, (0.00018061465, 0.003071937, 0.0010208925, 0.017517751)\n",
      "   validation loss 0.0002518018882256001, (0.00025146717, 0.0046136677, 0.0015955727, 0.017517751)\n",
      "decoder loss ratio: 0.000525, decoder SINDy loss  ratio: 0.101967\n",
      "Epoch 468\n",
      "   training loss 0.0001454232697142288, (0.00014514831, 0.0028752831, 0.0010088757, 0.01740676)\n",
      "   validation loss 0.0002830346638802439, (0.00028269977, 0.0045902473, 0.0016082957, 0.01740676)\n",
      "decoder loss ratio: 0.000590, decoder SINDy loss  ratio: 0.102781\n",
      "Epoch 469\n",
      "   training loss 7.133660983527079e-05, (7.1061804e-05, 0.0028513828, 0.0010065105, 0.017416008)\n",
      "   validation loss 0.0001829704560805112, (0.00018263748, 0.004395726, 0.001588135, 0.017416008)\n",
      "decoder loss ratio: 0.000381, decoder SINDy loss  ratio: 0.101492\n",
      "Epoch 470\n",
      "   training loss 0.00018314456974621862, (0.00018286519, 0.00300081, 0.0010416096, 0.017521743)\n",
      "   validation loss 0.0002462853444740176, (0.00024595062, 0.0044442764, 0.001595308, 0.017521743)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.101951\n",
      "Epoch 471\n",
      "   training loss 0.00016403522749897093, (0.0001637586, 0.0030285353, 0.0010234029, 0.017429339)\n",
      "   validation loss 0.0003160574415232986, (0.00031572374, 0.0045224978, 0.0015941013, 0.017429339)\n",
      "decoder loss ratio: 0.000659, decoder SINDy loss  ratio: 0.101873\n",
      "Epoch 472\n",
      "   training loss 0.00019164012337569147, (0.00019136295, 0.0030369023, 0.0010326207, 0.017390953)\n",
      "   validation loss 0.00031519439653493464, (0.00031486037, 0.0046038344, 0.0016013538, 0.017390953)\n",
      "decoder loss ratio: 0.000657, decoder SINDy loss  ratio: 0.102337\n",
      "Epoch 473\n",
      "   training loss 9.118792513618246e-05, (9.091429e-05, 0.002891318, 0.0010008519, 0.01735491)\n",
      "   validation loss 0.000233951403060928, (0.00023361859, 0.004507877, 0.0015926696, 0.01735491)\n",
      "decoder loss ratio: 0.000487, decoder SINDy loss  ratio: 0.101782\n",
      "Epoch 474\n",
      "   training loss 0.0001640116679482162, (0.0001637319, 0.0030123359, 0.0010452287, 0.017525293)\n",
      "   validation loss 0.0002753357985056937, (0.00027500067, 0.004459474, 0.0015986848, 0.017525293)\n",
      "decoder loss ratio: 0.000574, decoder SINDy loss  ratio: 0.102166\n",
      "Epoch 475\n",
      "   training loss 9.881454025162384e-05, (9.8538716e-05, 0.0030011653, 0.0010119377, 0.017462905)\n",
      "   validation loss 0.00023893159232102334, (0.00023859795, 0.004561824, 0.0015902151, 0.017462905)\n",
      "decoder loss ratio: 0.000498, decoder SINDy loss  ratio: 0.101625\n",
      "Epoch 476\n",
      "   training loss 0.00021415582159534097, (0.00021388078, 0.002939459, 0.0010067911, 0.017435709)\n",
      "   validation loss 0.00040405194158665836, (0.0004037177, 0.0045548966, 0.0015985708, 0.017435709)\n",
      "decoder loss ratio: 0.000842, decoder SINDy loss  ratio: 0.102159\n",
      "Epoch 477\n",
      "   training loss 0.00012527729268185794, (0.00012500158, 0.0028187695, 0.0010160584, 0.017411826)\n",
      "   validation loss 0.00030667876126244664, (0.00030634485, 0.0043973024, 0.0015977636, 0.017411826)\n",
      "decoder loss ratio: 0.000639, decoder SINDy loss  ratio: 0.102107\n",
      "Epoch 478\n",
      "   training loss 6.229368591448292e-05, (6.2017e-05, 0.0029486732, 0.0010217563, 0.01745034)\n",
      "   validation loss 0.00020960175606887788, (0.00020926823, 0.004581115, 0.0015902456, 0.01745034)\n",
      "decoder loss ratio: 0.000437, decoder SINDy loss  ratio: 0.101627\n",
      "Epoch 479\n",
      "   training loss 0.00010933735029539093, (0.00010906346, 0.00273523, 0.0009924883, 0.017464088)\n",
      "   validation loss 0.000318116566631943, (0.0003177824, 0.0045665135, 0.0015950624, 0.017464088)\n",
      "decoder loss ratio: 0.000663, decoder SINDy loss  ratio: 0.101935\n",
      "Epoch 480\n",
      "   training loss 9.147430682787672e-05, (9.1199e-05, 0.0027783553, 0.0010055108, 0.017475115)\n",
      "   validation loss 0.00023801325005479157, (0.00023767982, 0.0044781626, 0.001586785, 0.017475115)\n",
      "decoder loss ratio: 0.000496, decoder SINDy loss  ratio: 0.101406\n",
      "Epoch 481\n",
      "   training loss 8.064662688411772e-05, (8.037256e-05, 0.002710846, 0.0009984155, 0.017421942)\n",
      "   validation loss 0.00026513010379858315, (0.00026479765, 0.0044346475, 0.0015823722, 0.017421942)\n",
      "decoder loss ratio: 0.000552, decoder SINDy loss  ratio: 0.101124\n",
      "Epoch 482\n",
      "   training loss 0.00014641141751781106, (0.00014613285, 0.0028171323, 0.0010420589, 0.017435651)\n",
      "   validation loss 0.0002522469440009445, (0.00025191304, 0.0044019767, 0.0015954855, 0.017435651)\n",
      "decoder loss ratio: 0.000526, decoder SINDy loss  ratio: 0.101962\n",
      "Epoch 483\n",
      "   training loss 0.00014410822768695652, (0.00014383235, 0.0029623385, 0.0010139492, 0.017448038)\n",
      "   validation loss 0.0002691505942493677, (0.00026881765, 0.0046046833, 0.0015845621, 0.017448038)\n",
      "decoder loss ratio: 0.000561, decoder SINDy loss  ratio: 0.101264\n",
      "Epoch 484\n",
      "   training loss 0.00013189390301704407, (0.00013161908, 0.0028042176, 0.0009994851, 0.017488958)\n",
      "   validation loss 0.00029596645617857575, (0.0002956323, 0.0045934743, 0.0015929815, 0.017488958)\n",
      "decoder loss ratio: 0.000617, decoder SINDy loss  ratio: 0.101802\n",
      "Epoch 485\n",
      "   training loss 0.00010295482206856832, (0.000102680424, 0.0027638155, 0.0010019783, 0.017420365)\n",
      "   validation loss 0.0002478464739397168, (0.00024751356, 0.0044466625, 0.0015870363, 0.017420365)\n",
      "decoder loss ratio: 0.000516, decoder SINDy loss  ratio: 0.101422\n",
      "Epoch 486\n",
      "   training loss 0.00013525568647310138, (0.00013497856, 0.0029160816, 0.0010226029, 0.01748729)\n",
      "   validation loss 0.000278813939075917, (0.00027848122, 0.0044827545, 0.0015784136, 0.01748729)\n",
      "decoder loss ratio: 0.000581, decoder SINDy loss  ratio: 0.100871\n",
      "Epoch 487\n",
      "   training loss 7.382973126368597e-05, (7.355449e-05, 0.0029059388, 0.0010143835, 0.017379964)\n",
      "   validation loss 0.00022910271945875138, (0.00022876979, 0.004635773, 0.0015914167, 0.017379964)\n",
      "decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.101702\n",
      "Epoch 488\n",
      "   training loss 9.630729618947953e-05, (9.603481e-05, 0.0026556135, 0.0009851237, 0.017397745)\n",
      "   validation loss 0.00029579439433291554, (0.0002954619, 0.00447355, 0.0015849334, 0.017397745)\n",
      "decoder loss ratio: 0.000616, decoder SINDy loss  ratio: 0.101288\n",
      "Epoch 489\n",
      "   training loss 0.00010877241584239528, (0.00010849595, 0.0028771088, 0.0010183733, 0.017463122)\n",
      "   validation loss 0.00021708996791858226, (0.00021675725, 0.0045786155, 0.0015807104, 0.017463122)\n",
      "decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.101018\n",
      "Epoch 490\n",
      "   training loss 8.776499453233555e-05, (8.7489876e-05, 0.0027526412, 0.0010095872, 0.017415553)\n",
      "   validation loss 0.00024548909277655184, (0.0002451568, 0.004552457, 0.0015811158, 0.017415553)\n",
      "decoder loss ratio: 0.000511, decoder SINDy loss  ratio: 0.101044\n",
      "Epoch 491\n",
      "   training loss 0.0001138189181801863, (0.00011354409, 0.0027751236, 0.0010067646, 0.017414697)\n",
      "   validation loss 0.00021686307445634156, (0.00021653084, 0.004516141, 0.0015809155, 0.017414697)\n",
      "decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.101031\n",
      "Epoch 492\n",
      "   training loss 0.00020315672736614943, (0.00020287793, 0.0031641528, 0.0010375192, 0.017504107)\n",
      "   validation loss 0.0003378744295332581, (0.0003375408, 0.00467375, 0.001585907, 0.017504107)\n",
      "decoder loss ratio: 0.000704, decoder SINDy loss  ratio: 0.101350\n",
      "Epoch 493\n",
      "   training loss 9.188966214423999e-05, (9.161509e-05, 0.0028597144, 0.000997433, 0.017482571)\n",
      "   validation loss 0.000234119564993307, (0.00023378672, 0.0045661265, 0.0015801532, 0.017482571)\n",
      "decoder loss ratio: 0.000488, decoder SINDy loss  ratio: 0.100982\n",
      "Epoch 494\n",
      "   training loss 7.817761070327833e-05, (7.7902485e-05, 0.0029806786, 0.0010147472, 0.017364942)\n",
      "   validation loss 0.00017678811855148524, (0.00017645647, 0.004534188, 0.0015800424, 0.017364942)\n",
      "decoder loss ratio: 0.000368, decoder SINDy loss  ratio: 0.100975\n",
      "Epoch 495\n",
      "   training loss 0.00023723150661680847, (0.00023695455, 0.0031131909, 0.0010361888, 0.017332507)\n",
      "   validation loss 0.0002965745807159692, (0.0002962417, 0.0047761416, 0.0015958889, 0.017332507)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.101988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496\n",
      "   training loss 4.74034168291837e-05, (4.7129623e-05, 0.00288421, 0.0010014628, 0.01736482)\n",
      "   validation loss 0.00018838678079191595, (0.0001880554, 0.0046408437, 0.0015773549, 0.01736482)\n",
      "decoder loss ratio: 0.000392, decoder SINDy loss  ratio: 0.100803\n",
      "Epoch 497\n",
      "   training loss 9.224746463587508e-05, (9.1972295e-05, 0.002903242, 0.0010124961, 0.017391516)\n",
      "   validation loss 0.00020735690486617386, (0.00020702537, 0.0045240456, 0.0015763297, 0.017391516)\n",
      "decoder loss ratio: 0.000432, decoder SINDy loss  ratio: 0.100738\n",
      "Epoch 498\n",
      "   training loss 0.00019461422925814986, (0.00019433354, 0.0033990566, 0.0010478635, 0.017590683)\n",
      "   validation loss 0.00034023827174678445, (0.00033990253, 0.00481192, 0.001598303, 0.017590683)\n",
      "decoder loss ratio: 0.000709, decoder SINDy loss  ratio: 0.102142\n",
      "Epoch 499\n",
      "   training loss 0.00011613325477810577, (0.00011585871, 0.003071135, 0.000992995, 0.01752433)\n",
      "   validation loss 0.00026836234610527754, (0.00026802855, 0.0047151786, 0.0015854385, 0.01752433)\n",
      "decoder loss ratio: 0.000559, decoder SINDy loss  ratio: 0.101320\n",
      "Epoch 500\n",
      "   training loss 6.299895903794095e-05, (6.2724066e-05, 0.003026163, 0.0010006836, 0.017482342)\n",
      "   validation loss 0.00018654750601854175, (0.00018621511, 0.004632139, 0.0015756368, 0.017482342)\n",
      "decoder loss ratio: 0.000388, decoder SINDy loss  ratio: 0.100693\n",
      "THRESHOLDING: 3 active coefficients\n",
      "Epoch 501\n",
      "   training loss 0.00010065968672279269, (0.00010014148, 0.011856806, 0.003915355, 0.012667683)\n",
      "   validation loss 0.00021308362192939967, (0.00021246649, 0.013290924, 0.0049045845, 0.012667683)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.313435\n",
      "Epoch 502\n",
      "   training loss 0.0001067718694685027, (0.000106249514, 0.011980869, 0.003950976, 0.012725481)\n",
      "   validation loss 0.00019777992565650493, (0.00019716266, 0.01327585, 0.004900009, 0.012725481)\n",
      "decoder loss ratio: 0.000411, decoder SINDy loss  ratio: 0.313142\n",
      "Epoch 503\n",
      "   training loss 0.00011564759915927425, (0.000115130904, 0.011657647, 0.0038957107, 0.012712571)\n",
      "   validation loss 0.00035446291440166533, (0.0003538463, 0.013337803, 0.0048950957, 0.012712571)\n",
      "decoder loss ratio: 0.000738, decoder SINDy loss  ratio: 0.312828\n",
      "Epoch 504\n",
      "   training loss 0.00011212305253138766, (0.00011160452, 0.011728745, 0.0039103343, 0.012750588)\n",
      "   validation loss 0.0002365369291510433, (0.00023592146, 0.013064393, 0.0048796535, 0.012750588)\n",
      "decoder loss ratio: 0.000492, decoder SINDy loss  ratio: 0.311842\n",
      "Epoch 505\n",
      "   training loss 0.00014867869322188199, (0.00014816457, 0.011810034, 0.0038652655, 0.012758849)\n",
      "   validation loss 0.00032692248350940645, (0.0003263104, 0.01334151, 0.0048448225, 0.012758849)\n",
      "decoder loss ratio: 0.000681, decoder SINDy loss  ratio: 0.309616\n",
      "Epoch 506\n",
      "   training loss 7.859684410504997e-05, (7.8080186e-05, 0.011852446, 0.00389105, 0.012755466)\n",
      "   validation loss 0.00025634016492404044, (0.00025572343, 0.0134099, 0.004891863, 0.012755466)\n",
      "decoder loss ratio: 0.000533, decoder SINDy loss  ratio: 0.312622\n",
      "Epoch 507\n",
      "   training loss 6.601893983315676e-05, (6.550282e-05, 0.011647391, 0.0038845926, 0.012766415)\n",
      "   validation loss 0.00020043311815243214, (0.00019981891, 0.01327746, 0.004865415, 0.012766415)\n",
      "decoder loss ratio: 0.000417, decoder SINDy loss  ratio: 0.310932\n",
      "Epoch 508\n",
      "   training loss 8.161890582414344e-05, (8.1104496e-05, 0.011501781, 0.00386716, 0.012769489)\n",
      "   validation loss 0.0002235421707155183, (0.00022292849, 0.013241665, 0.0048599574, 0.012769489)\n",
      "decoder loss ratio: 0.000465, decoder SINDy loss  ratio: 0.310583\n",
      "Epoch 509\n",
      "   training loss 0.00011409682338126004, (0.00011357938, 0.011515033, 0.0038983815, 0.012760512)\n",
      "   validation loss 0.00021301062952261418, (0.00021239887, 0.012992069, 0.004841582, 0.012760512)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.309409\n",
      "Epoch 510\n",
      "   training loss 0.00015469388745259494, (0.00015417462, 0.012192477, 0.0039131395, 0.0127950255)\n",
      "   validation loss 0.00032755083520896733, (0.0003269352, 0.013494693, 0.004876985, 0.0127950255)\n",
      "decoder loss ratio: 0.000682, decoder SINDy loss  ratio: 0.311671\n",
      "Epoch 511\n",
      "   training loss 7.797929720254615e-05, (7.746104e-05, 0.011864719, 0.0039043971, 0.012781949)\n",
      "   validation loss 0.0002001957909669727, (0.00019957924, 0.013435194, 0.0048872423, 0.012781949)\n",
      "decoder loss ratio: 0.000416, decoder SINDy loss  ratio: 0.312327\n",
      "Epoch 512\n",
      "   training loss 9.037942800205201e-05, (8.9862915e-05, 0.011666059, 0.0038856561, 0.012794848)\n",
      "   validation loss 0.00020814720483031124, (0.0002075331, 0.013266071, 0.004861555, 0.012794848)\n",
      "decoder loss ratio: 0.000433, decoder SINDy loss  ratio: 0.310685\n",
      "Epoch 513\n",
      "   training loss 9.615637100068852e-05, (9.564103e-05, 0.011731966, 0.0038754377, 0.012779494)\n",
      "   validation loss 0.00019264372531324625, (0.00019203211, 0.013241279, 0.0048382524, 0.012779494)\n",
      "decoder loss ratio: 0.000401, decoder SINDy loss  ratio: 0.309196\n",
      "Epoch 514\n",
      "   training loss 0.00011549071496119723, (0.00011497464, 0.01175044, 0.0038813003, 0.012794731)\n",
      "   validation loss 0.00022843165788799524, (0.0002278207, 0.013122139, 0.0048302044, 0.012794731)\n",
      "decoder loss ratio: 0.000475, decoder SINDy loss  ratio: 0.308681\n",
      "Epoch 515\n",
      "   training loss 0.00010324810136808082, (0.00010273509, 0.011689744, 0.0038521523, 0.012779674)\n",
      "   validation loss 0.00024650938576087356, (0.00024589768, 0.013278305, 0.004839111, 0.012779674)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.309251\n",
      "Epoch 516\n",
      "   training loss 0.00011686777725117281, (0.0001163554, 0.011628106, 0.00384404, 0.01279786)\n",
      "   validation loss 0.00026573918876238167, (0.00026512824, 0.0131913675, 0.00482987, 0.01279786)\n",
      "decoder loss ratio: 0.000553, decoder SINDy loss  ratio: 0.308660\n",
      "Epoch 517\n",
      "   training loss 0.000211233738809824, (0.00021071394, 0.01232049, 0.0039191106, 0.01278793)\n",
      "   validation loss 0.00030294706812128425, (0.00030233094, 0.013539631, 0.004882538, 0.01278793)\n",
      "decoder loss ratio: 0.000631, decoder SINDy loss  ratio: 0.312026\n",
      "Epoch 518\n",
      "   training loss 0.00011063141573686153, (0.0001101137, 0.012269895, 0.0038967498, 0.012803778)\n",
      "   validation loss 0.0002014220954151824, (0.00020080723, 0.013588877, 0.0048682676, 0.012803778)\n",
      "decoder loss ratio: 0.000419, decoder SINDy loss  ratio: 0.311114\n",
      "Epoch 519\n",
      "   training loss 0.00012366175360511988, (0.00012314605, 0.011855516, 0.003878217, 0.012787567)\n",
      "   validation loss 0.00023335745208896697, (0.00023274602, 0.013348952, 0.0048354366, 0.012787567)\n",
      "decoder loss ratio: 0.000486, decoder SINDy loss  ratio: 0.309016\n",
      "Epoch 520\n",
      "   training loss 0.0002277066232636571, (0.00022717562, 0.012954221, 0.0040263757, 0.012835705)\n",
      "   validation loss 0.00037951988633722067, (0.00037889436, 0.014110633, 0.0049718623, 0.012835705)\n",
      "decoder loss ratio: 0.000790, decoder SINDy loss  ratio: 0.317734\n",
      "Epoch 521\n",
      "   training loss 0.00013831263640895486, (0.00013779567, 0.012314028, 0.0038880394, 0.0128178)\n",
      "   validation loss 0.00032093445770442486, (0.0003203161, 0.014036201, 0.0049019963, 0.0128178)\n",
      "decoder loss ratio: 0.000668, decoder SINDy loss  ratio: 0.313269\n",
      "Epoch 522\n",
      "   training loss 6.333612691378221e-05, (6.282403e-05, 0.012113151, 0.0038394595, 0.012815017)\n",
      "   validation loss 0.00019569862342905253, (0.00019508615, 0.013702564, 0.004843362, 0.012815017)\n",
      "decoder loss ratio: 0.000407, decoder SINDy loss  ratio: 0.309522\n",
      "Epoch 523\n",
      "   training loss 8.770350541453809e-05, (8.7189226e-05, 0.012232762, 0.0038610608, 0.01281701)\n",
      "   validation loss 0.00026268817600794137, (0.00026207362, 0.013797399, 0.004863859, 0.01281701)\n",
      "decoder loss ratio: 0.000547, decoder SINDy loss  ratio: 0.310832\n",
      "Epoch 524\n",
      "   training loss 6.694027979392558e-05, (6.642371e-05, 0.012109101, 0.0038835194, 0.012821658)\n",
      "   validation loss 0.00021142489276826382, (0.0002108099, 0.013772847, 0.004867734, 0.012821658)\n",
      "decoder loss ratio: 0.000440, decoder SINDy loss  ratio: 0.311080\n",
      "Epoch 525\n",
      "   training loss 0.00013000203762203455, (0.000129491, 0.011959497, 0.0038281193, 0.012822418)\n",
      "   validation loss 0.00037027077632956207, (0.00036965814, 0.013813425, 0.0048441165, 0.012822418)\n",
      "decoder loss ratio: 0.000771, decoder SINDy loss  ratio: 0.309571\n",
      "Epoch 526\n",
      "   training loss 0.00010083381494041532, (0.00010031504, 0.012224495, 0.0039020816, 0.012856321)\n",
      "   validation loss 0.00022895798610989004, (0.00022834136, 0.013810884, 0.0048805894, 0.012856321)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.311901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527\n",
      "   training loss 0.0001988889998756349, (0.00019837297, 0.012119014, 0.0038752612, 0.012849719)\n",
      "   validation loss 0.0003117856103926897, (0.0003111695, 0.013848097, 0.0048761754, 0.012849719)\n",
      "decoder loss ratio: 0.000649, decoder SINDy loss  ratio: 0.311619\n",
      "Epoch 528\n",
      "   training loss 5.7604192988947034e-05, (5.709359e-05, 0.01177585, 0.003822135, 0.012838804)\n",
      "   validation loss 0.00015855698438826948, (0.00015794707, 0.013549995, 0.004815166, 0.012838804)\n",
      "decoder loss ratio: 0.000330, decoder SINDy loss  ratio: 0.307720\n",
      "Epoch 529\n",
      "   training loss 7.413489947794005e-05, (7.362364e-05, 0.011814159, 0.003829014, 0.012835417)\n",
      "   validation loss 0.0001630066108191386, (0.00016239772, 0.013458889, 0.0048055053, 0.012835417)\n",
      "decoder loss ratio: 0.000339, decoder SINDy loss  ratio: 0.307103\n",
      "Epoch 530\n",
      "   training loss 0.0003098666784353554, (0.0003093375, 0.013064898, 0.004005583, 0.012859592)\n",
      "   validation loss 0.0004536016786005348, (0.00045298022, 0.0141326925, 0.004928394, 0.012859592)\n",
      "decoder loss ratio: 0.000945, decoder SINDy loss  ratio: 0.314956\n",
      "Epoch 531\n",
      "   training loss 8.298048487631604e-05, (8.246914e-05, 0.01215813, 0.0038297535, 0.012837107)\n",
      "   validation loss 0.00021473621018230915, (0.00021412205, 0.014018617, 0.004857875, 0.012837107)\n",
      "decoder loss ratio: 0.000447, decoder SINDy loss  ratio: 0.310450\n",
      "Epoch 532\n",
      "   training loss 5.702935595763847e-05, (5.6517365e-05, 0.012322473, 0.003834709, 0.012851879)\n",
      "   validation loss 0.00017439182556699961, (0.00017377957, 0.013746849, 0.004837406, 0.012851879)\n",
      "decoder loss ratio: 0.000363, decoder SINDy loss  ratio: 0.309142\n",
      "Epoch 533\n",
      "   training loss 0.00010432896669954062, (0.000103813465, 0.012321093, 0.0038726977, 0.0128232455)\n",
      "   validation loss 0.0001837128511397168, (0.0001831008, 0.013767435, 0.00483817, 0.0128232455)\n",
      "decoder loss ratio: 0.000382, decoder SINDy loss  ratio: 0.309191\n",
      "Epoch 534\n",
      "   training loss 7.851750706322491e-05, (7.800746e-05, 0.0119978, 0.0038173813, 0.01283014)\n",
      "   validation loss 0.00022415751300286502, (0.00022355211, 0.01354577, 0.004770995, 0.01283014)\n",
      "decoder loss ratio: 0.000466, decoder SINDy loss  ratio: 0.304898\n",
      "Epoch 535\n",
      "   training loss 0.0002842024841811508, (0.00028368557, 0.012157218, 0.0038882094, 0.012807733)\n",
      "   validation loss 0.00037667094147764146, (0.00037605778, 0.013758789, 0.004850802, 0.012807733)\n",
      "decoder loss ratio: 0.000785, decoder SINDy loss  ratio: 0.309998\n",
      "Epoch 536\n",
      "   training loss 6.632875738432631e-05, (6.581594e-05, 0.012141518, 0.0038469164, 0.012811962)\n",
      "   validation loss 0.00022087091929279268, (0.00022026002, 0.0137800975, 0.0048278617, 0.012811962)\n",
      "decoder loss ratio: 0.000460, decoder SINDy loss  ratio: 0.308532\n",
      "Epoch 537\n",
      "   training loss 5.17370572197251e-05, (5.122326e-05, 0.012050428, 0.00385643, 0.01281534)\n",
      "   validation loss 0.0001816720177885145, (0.00018106069, 0.013775342, 0.0048316247, 0.01281534)\n",
      "decoder loss ratio: 0.000378, decoder SINDy loss  ratio: 0.308772\n",
      "Epoch 538\n",
      "   training loss 0.00011639242438832298, (0.00011587901, 0.011937212, 0.0038509485, 0.012831941)\n",
      "   validation loss 0.00029801056371070445, (0.00029739825, 0.013790537, 0.004840023, 0.012831941)\n",
      "decoder loss ratio: 0.000620, decoder SINDy loss  ratio: 0.309309\n",
      "Epoch 539\n",
      "   training loss 0.0001255907118320465, (0.0001250805, 0.0118303755, 0.0038193674, 0.012827821)\n",
      "   validation loss 0.00029690677183680236, (0.00029629792, 0.0135948295, 0.0048055253, 0.012827821)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.307104\n",
      "Epoch 540\n",
      "   training loss 8.741852798266336e-05, (8.690858e-05, 0.012079199, 0.0038150956, 0.012844477)\n",
      "   validation loss 0.0002471813349984586, (0.0002465748, 0.013581138, 0.0047809007, 0.012844477)\n",
      "decoder loss ratio: 0.000514, decoder SINDy loss  ratio: 0.305531\n",
      "Epoch 541\n",
      "   training loss 9.153854625765234e-05, (9.102732e-05, 0.011990628, 0.0038284364, 0.012838006)\n",
      "   validation loss 0.0002301566128153354, (0.00022954696, 0.013835059, 0.004812805, 0.012838006)\n",
      "decoder loss ratio: 0.000479, decoder SINDy loss  ratio: 0.307570\n",
      "Epoch 542\n",
      "   training loss 0.000107265317637939, (0.000106752974, 0.011894952, 0.003840594, 0.012828152)\n",
      "   validation loss 0.000267627474386245, (0.00026701533, 0.013735379, 0.0048385356, 0.012828152)\n",
      "decoder loss ratio: 0.000557, decoder SINDy loss  ratio: 0.309214\n",
      "Epoch 543\n",
      "   training loss 0.00010006345110014081, (9.955072e-05, 0.012032822, 0.0038441475, 0.012831328)\n",
      "   validation loss 0.00021445767197292298, (0.00021384975, 0.013578958, 0.0047959695, 0.012831328)\n",
      "decoder loss ratio: 0.000446, decoder SINDy loss  ratio: 0.306494\n",
      "Epoch 544\n",
      "   training loss 0.00019205418357159942, (0.00019154118, 0.012169727, 0.0038471133, 0.012829421)\n",
      "   validation loss 0.00030076660914346576, (0.00030015918, 0.013567879, 0.0047913305, 0.012829421)\n",
      "decoder loss ratio: 0.000626, decoder SINDy loss  ratio: 0.306197\n",
      "Epoch 545\n",
      "   training loss 0.00022181763779371977, (0.00022130692, 0.011543023, 0.0038250736, 0.012820704)\n",
      "   validation loss 0.00042944232700392604, (0.00042882576, 0.014048569, 0.0048836456, 0.012820704)\n",
      "decoder loss ratio: 0.000895, decoder SINDy loss  ratio: 0.312097\n",
      "Epoch 546\n",
      "   training loss 2.913908065238502e-05, (2.8634971e-05, 0.011839438, 0.0037569273, 0.012841682)\n",
      "   validation loss 0.00014386881957761943, (0.0001432638, 0.013619258, 0.0047660186, 0.012841682)\n",
      "decoder loss ratio: 0.000299, decoder SINDy loss  ratio: 0.304580\n",
      "Epoch 547\n",
      "   training loss 0.00015460612485185266, (0.00015409372, 0.012145135, 0.0038402104, 0.012837393)\n",
      "   validation loss 0.00022827521024737507, (0.00022766672, 0.01364507, 0.004801175, 0.012837393)\n",
      "decoder loss ratio: 0.000475, decoder SINDy loss  ratio: 0.306826\n",
      "Epoch 548\n",
      "   training loss 0.00012138616148149595, (0.00012087671, 0.012133318, 0.0038112965, 0.0128321545)\n",
      "   validation loss 0.00023157840769272298, (0.00023097264, 0.013714136, 0.004774526, 0.0128321545)\n",
      "decoder loss ratio: 0.000482, decoder SINDy loss  ratio: 0.305123\n",
      "Epoch 549\n",
      "   training loss 8.799868373898789e-05, (8.749016e-05, 0.011651192, 0.0038038462, 0.012813703)\n",
      "   validation loss 0.00023970534675754607, (0.00023909337, 0.013885835, 0.004838434, 0.012813703)\n",
      "decoder loss ratio: 0.000499, decoder SINDy loss  ratio: 0.309207\n",
      "Epoch 550\n",
      "   training loss 9.202279761666432e-05, (9.151448e-05, 0.012015977, 0.0038001619, 0.012830105)\n",
      "   validation loss 0.00018126530630979687, (0.00018065935, 0.013598777, 0.0047765467, 0.012830105)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.305252\n",
      "Epoch 551\n",
      "   training loss 9.840296843321994e-05, (9.789382e-05, 0.012354653, 0.003810568, 0.012809127)\n",
      "   validation loss 0.00023704968043603003, (0.00023644356, 0.013919074, 0.0047803614, 0.012809127)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.305496\n",
      "Epoch 552\n",
      "   training loss 9.111998951993883e-05, (9.060975e-05, 0.01206214, 0.0038215728, 0.012808321)\n",
      "   validation loss 0.00023306648654397577, (0.00023245884, 0.0139104575, 0.004795541, 0.012808321)\n",
      "decoder loss ratio: 0.000485, decoder SINDy loss  ratio: 0.306466\n",
      "Epoch 553\n",
      "   training loss 0.00019611760217230767, (0.00019561127, 0.011847827, 0.003784366, 0.012789722)\n",
      "   validation loss 0.00039082788862288, (0.0003902225, 0.013638949, 0.0047747684, 0.012789722)\n",
      "decoder loss ratio: 0.000814, decoder SINDy loss  ratio: 0.305139\n",
      "Epoch 554\n",
      "   training loss 0.00012123765191063285, (0.0001207325, 0.012062256, 0.0037682888, 0.012832701)\n",
      "   validation loss 0.00035729698720388114, (0.0003566948, 0.013940093, 0.004738552, 0.012832701)\n",
      "decoder loss ratio: 0.000744, decoder SINDy loss  ratio: 0.302824\n",
      "Epoch 555\n",
      "   training loss 5.4648324294248596e-05, (5.4138276e-05, 0.012198926, 0.0038178707, 0.0128262285)\n",
      "   validation loss 0.00019865082867909223, (0.00019804198, 0.014013143, 0.0048058736, 0.0128262285)\n",
      "decoder loss ratio: 0.000413, decoder SINDy loss  ratio: 0.307127\n",
      "Epoch 556\n",
      "   training loss 6.088432201067917e-05, (6.0375634e-05, 0.011934381, 0.0038029172, 0.01283962)\n",
      "   validation loss 0.00018959883891511708, (0.00018899151, 0.013902385, 0.0047893315, 0.01283962)\n",
      "decoder loss ratio: 0.000394, decoder SINDy loss  ratio: 0.306069\n",
      "Epoch 557\n",
      "   training loss 0.00013191127800382674, (0.00013140708, 0.01172072, 0.0037606733, 0.012813553)\n",
      "   validation loss 0.0003148744872305542, (0.00031427093, 0.0137819955, 0.0047541363, 0.012813553)\n",
      "decoder loss ratio: 0.000656, decoder SINDy loss  ratio: 0.303820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558\n",
      "   training loss 8.752616849960759e-05, (8.702224e-05, 0.012064011, 0.0037547974, 0.012844214)\n",
      "   validation loss 0.0002716042217798531, (0.00027100428, 0.0137641765, 0.0047151675, 0.012844214)\n",
      "decoder loss ratio: 0.000565, decoder SINDy loss  ratio: 0.301330\n",
      "Epoch 559\n",
      "   training loss 0.00014883042604196817, (0.0001483231, 0.012091994, 0.003788285, 0.012849033)\n",
      "   validation loss 0.00024372509506065398, (0.00024312039, 0.013963065, 0.004762172, 0.012849033)\n",
      "decoder loss ratio: 0.000507, decoder SINDy loss  ratio: 0.304334\n",
      "Epoch 560\n",
      "   training loss 0.00011107041063951328, (0.000110564026, 0.011775435, 0.0037791727, 0.012846487)\n",
      "   validation loss 0.00024259938800241798, (0.00024199393, 0.013826886, 0.0047699786, 0.012846487)\n",
      "decoder loss ratio: 0.000505, decoder SINDy loss  ratio: 0.304833\n",
      "Epoch 561\n",
      "   training loss 3.528446177369915e-05, (3.478094e-05, 0.011773334, 0.0037522537, 0.012829766)\n",
      "   validation loss 0.00014489382738247514, (0.00014429308, 0.0136438245, 0.0047243973, 0.012829766)\n",
      "decoder loss ratio: 0.000301, decoder SINDy loss  ratio: 0.301920\n",
      "Epoch 562\n",
      "   training loss 0.00013730629871133715, (0.00013679781, 0.012007963, 0.0038024615, 0.012824852)\n",
      "   validation loss 0.00021818189998157322, (0.00021757955, 0.013598458, 0.004741006, 0.012824852)\n",
      "decoder loss ratio: 0.000454, decoder SINDy loss  ratio: 0.302981\n",
      "Epoch 563\n",
      "   training loss 0.00020067983132321388, (0.00020017443, 0.012221512, 0.003771735, 0.012823818)\n",
      "   validation loss 0.0004261707072146237, (0.00042556762, 0.013617663, 0.004748459, 0.012823818)\n",
      "decoder loss ratio: 0.000888, decoder SINDy loss  ratio: 0.303457\n",
      "Epoch 564\n",
      "   training loss 0.0002116588584613055, (0.0002111518, 0.011718287, 0.003787624, 0.0128298905)\n",
      "   validation loss 0.0004161693505011499, (0.0004155583, 0.014167168, 0.004827879, 0.0128298905)\n",
      "decoder loss ratio: 0.000867, decoder SINDy loss  ratio: 0.308533\n",
      "Epoch 565\n",
      "   training loss 5.9083507949253544e-05, (5.8582744e-05, 0.012038201, 0.003723758, 0.0128386635)\n",
      "   validation loss 0.00016485824016854167, (0.0001642578, 0.013790517, 0.004720471, 0.0128386635)\n",
      "decoder loss ratio: 0.000343, decoder SINDy loss  ratio: 0.301669\n",
      "Epoch 566\n",
      "   training loss 0.00010588666191324592, (0.00010537873, 0.012400438, 0.0037957502, 0.0128359655)\n",
      "   validation loss 0.00021612081036437303, (0.00021551746, 0.014035184, 0.0047498494, 0.0128359655)\n",
      "decoder loss ratio: 0.000450, decoder SINDy loss  ratio: 0.303546\n",
      "Epoch 567\n",
      "   training loss 6.76424679113552e-05, (6.713942e-05, 0.012176347, 0.0037468267, 0.01283591)\n",
      "   validation loss 0.00019661882834043354, (0.00019601913, 0.014022189, 0.004713345, 0.01283591)\n",
      "decoder loss ratio: 0.000409, decoder SINDy loss  ratio: 0.301213\n",
      "Epoch 568\n",
      "   training loss 0.00014082544657867402, (0.00014031534, 0.011984195, 0.0038180389, 0.01283076)\n",
      "   validation loss 0.00021916127298027277, (0.0002185587, 0.013661107, 0.0047426485, 0.01283076)\n",
      "decoder loss ratio: 0.000456, decoder SINDy loss  ratio: 0.303086\n",
      "Epoch 569\n",
      "   training loss 0.00027002027491107583, (0.00026949943, 0.0126485275, 0.003924017, 0.012843615)\n",
      "   validation loss 0.0004805919888895005, (0.0004799736, 0.0147285, 0.0048996815, 0.012843615)\n",
      "decoder loss ratio: 0.001001, decoder SINDy loss  ratio: 0.313122\n",
      "Epoch 570\n",
      "   training loss 8.238660666393116e-05, (8.1878956e-05, 0.012469381, 0.0037921222, 0.012843624)\n",
      "   validation loss 0.00023317582963500172, (0.00023256712, 0.014496128, 0.004802689, 0.012843624)\n",
      "decoder loss ratio: 0.000485, decoder SINDy loss  ratio: 0.306923\n",
      "Epoch 571\n",
      "   training loss 9.062301251105964e-05, (9.011753e-05, 0.0124413585, 0.0037738532, 0.012810004)\n",
      "   validation loss 0.00020981495617888868, (0.0002092124, 0.014177448, 0.00474457, 0.012810004)\n",
      "decoder loss ratio: 0.000436, decoder SINDy loss  ratio: 0.303209\n",
      "Epoch 572\n",
      "   training loss 5.067355959909037e-05, (5.0167262e-05, 0.012383025, 0.0037807582, 0.012822089)\n",
      "   validation loss 0.00018498515419196337, (0.00018438161, 0.014228317, 0.00475331, 0.012822089)\n",
      "decoder loss ratio: 0.000385, decoder SINDy loss  ratio: 0.303767\n",
      "Epoch 573\n",
      "   training loss 0.00010123661922989413, (0.00010073262, 0.012083276, 0.0037585178, 0.012814417)\n",
      "   validation loss 0.0002806341799441725, (0.00028003214, 0.0140933655, 0.004739057, 0.012814417)\n",
      "decoder loss ratio: 0.000584, decoder SINDy loss  ratio: 0.302857\n",
      "Epoch 574\n",
      "   training loss 6.124677020125091e-05, (6.0741495e-05, 0.012197967, 0.0037669525, 0.012857935)\n",
      "   validation loss 0.0002507602621335536, (0.00025015688, 0.014096796, 0.00474806, 0.012857935)\n",
      "decoder loss ratio: 0.000522, decoder SINDy loss  ratio: 0.303432\n",
      "Epoch 575\n",
      "   training loss 0.00015105768397916108, (0.00015054998, 0.012307861, 0.0037908745, 0.012861152)\n",
      "   validation loss 0.0002456193615216762, (0.00024501613, 0.014252254, 0.004746202, 0.012861152)\n",
      "decoder loss ratio: 0.000511, decoder SINDy loss  ratio: 0.303313\n",
      "Epoch 576\n",
      "   training loss 0.00015075394185259938, (0.00015024924, 0.012058278, 0.0037599253, 0.012871304)\n",
      "   validation loss 0.00028910956461913884, (0.00028850458, 0.0143331215, 0.00476259, 0.012871304)\n",
      "decoder loss ratio: 0.000602, decoder SINDy loss  ratio: 0.304360\n",
      "Epoch 577\n",
      "   training loss 5.022348341299221e-05, (4.9722912e-05, 0.0120633105, 0.0037190185, 0.012866865)\n",
      "   validation loss 0.0001720943982945755, (0.0001714947, 0.014066084, 0.004710273, 0.012866865)\n",
      "decoder loss ratio: 0.000358, decoder SINDy loss  ratio: 0.301017\n",
      "Epoch 578\n",
      "   training loss 0.00013998131908010691, (0.00013947907, 0.012064058, 0.003736727, 0.012856517)\n",
      "   validation loss 0.00028019555611535907, (0.00027959386, 0.014115293, 0.0047313212, 0.012856517)\n",
      "decoder loss ratio: 0.000583, decoder SINDy loss  ratio: 0.302362\n",
      "Epoch 579\n",
      "   training loss 0.00010783546167658642, (0.00010733213, 0.012081816, 0.0037486262, 0.012846458)\n",
      "   validation loss 0.00023685468477196991, (0.00023625442, 0.013914307, 0.004718083, 0.012846458)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.301516\n",
      "Epoch 580\n",
      "   training loss 0.00010477287287358195, (0.00010426917, 0.012281522, 0.0037521129, 0.0128485365)\n",
      "   validation loss 0.00034058952587656677, (0.00033999025, 0.014027809, 0.0047078975, 0.0128485365)\n",
      "decoder loss ratio: 0.000709, decoder SINDy loss  ratio: 0.300865\n",
      "Epoch 581\n",
      "   training loss 6.628236587857828e-05, (6.5782544e-05, 0.012156268, 0.0037151366, 0.0128313)\n",
      "   validation loss 0.0001921157818287611, (0.00019151735, 0.014237588, 0.004701176, 0.0128313)\n",
      "decoder loss ratio: 0.000400, decoder SINDy loss  ratio: 0.300436\n",
      "Epoch 582\n",
      "   training loss 9.976061846828088e-05, (9.92569e-05, 0.012060535, 0.0037533883, 0.012838571)\n",
      "   validation loss 0.00022538048506248742, (0.00022477913, 0.0140872905, 0.004729667, 0.012838571)\n",
      "decoder loss ratio: 0.000469, decoder SINDy loss  ratio: 0.302257\n",
      "Epoch 583\n",
      "   training loss 0.00011304300278425217, (0.00011254291, 0.01225713, 0.0037165433, 0.0128436405)\n",
      "   validation loss 0.0002951734932139516, (0.00029457686, 0.014081836, 0.0046819453, 0.0128436405)\n",
      "decoder loss ratio: 0.000615, decoder SINDy loss  ratio: 0.299207\n",
      "Epoch 584\n",
      "   training loss 6.672767631243914e-05, (6.622547e-05, 0.012257487, 0.0037359819, 0.012861006)\n",
      "   validation loss 0.0001849586406024173, (0.00018436104, 0.014218169, 0.004689988, 0.012861006)\n",
      "decoder loss ratio: 0.000385, decoder SINDy loss  ratio: 0.299721\n",
      "Epoch 585\n",
      "   training loss 9.623402002034709e-05, (9.5731346e-05, 0.0120728975, 0.0037420061, 0.012847179)\n",
      "   validation loss 0.00024673392181284726, (0.00024613217, 0.014299384, 0.0047328384, 0.012847179)\n",
      "decoder loss ratio: 0.000513, decoder SINDy loss  ratio: 0.302459\n",
      "Epoch 586\n",
      "   training loss 7.053007720969617e-05, (7.002724e-05, 0.012111251, 0.0037421896, 0.012861524)\n",
      "   validation loss 0.0001783976040314883, (0.000177798, 0.014037518, 0.004709928, 0.012861524)\n",
      "decoder loss ratio: 0.000371, decoder SINDy loss  ratio: 0.300995\n",
      "Epoch 587\n",
      "   training loss 0.0003142435452900827, (0.00031373245, 0.0126348, 0.0038264303, 0.012844813)\n",
      "   validation loss 0.0004639822291210294, (0.00046337757, 0.014110448, 0.0047623445, 0.012844813)\n",
      "decoder loss ratio: 0.000967, decoder SINDy loss  ratio: 0.304345\n",
      "Epoch 588\n",
      "   training loss 0.0002098696568282321, (0.00020937056, 0.011820946, 0.0037057013, 0.01285402)\n",
      "   validation loss 0.00039865198777988553, (0.00039804706, 0.014598871, 0.0047636274, 0.01285402)\n",
      "decoder loss ratio: 0.000830, decoder SINDy loss  ratio: 0.304427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589\n",
      "   training loss 4.1304640035377815e-05, (4.080688e-05, 0.011983476, 0.0036920374, 0.012855659)\n",
      "   validation loss 0.0001621004776097834, (0.00016150223, 0.014059447, 0.004696882, 0.012855659)\n",
      "decoder loss ratio: 0.000337, decoder SINDy loss  ratio: 0.300161\n",
      "Epoch 590\n",
      "   training loss 8.010868623387069e-05, (7.961082e-05, 0.012173217, 0.0036946815, 0.012839722)\n",
      "   validation loss 0.00017839598876889795, (0.00017779895, 0.014151095, 0.0046865027, 0.012839722)\n",
      "decoder loss ratio: 0.000371, decoder SINDy loss  ratio: 0.299498\n",
      "Epoch 591\n",
      "   training loss 0.00013075396418571472, (0.00013024746, 0.012390231, 0.0037798746, 0.012851632)\n",
      "   validation loss 0.0002221080067101866, (0.00022150662, 0.014173685, 0.0047286204, 0.012851632)\n",
      "decoder loss ratio: 0.000462, decoder SINDy loss  ratio: 0.302190\n",
      "Epoch 592\n",
      "   training loss 9.31287941057235e-05, (9.263246e-05, 0.011875431, 0.0036782832, 0.012850652)\n",
      "   validation loss 0.00023101631086319685, (0.00023041856, 0.014334417, 0.00469247, 0.012850652)\n",
      "decoder loss ratio: 0.000481, decoder SINDy loss  ratio: 0.299879\n",
      "Epoch 593\n",
      "   training loss 9.433307423023507e-05, (9.383144e-05, 0.012315448, 0.0037310324, 0.012852798)\n",
      "   validation loss 0.00021218233450781554, (0.00021158085, 0.014158633, 0.0047296397, 0.012852798)\n",
      "decoder loss ratio: 0.000441, decoder SINDy loss  ratio: 0.302255\n",
      "Epoch 594\n",
      "   training loss 3.137225940008648e-05, (3.0872863e-05, 0.012389642, 0.0037079612, 0.012860069)\n",
      "   validation loss 0.00015678376075811684, (0.00015618783, 0.014338636, 0.0046733194, 0.012860069)\n",
      "decoder loss ratio: 0.000326, decoder SINDy loss  ratio: 0.298656\n",
      "Epoch 595\n",
      "   training loss 7.504945097025484e-05, (7.455104e-05, 0.011993938, 0.0036996729, 0.012844471)\n",
      "   validation loss 0.000221462658373639, (0.00022086542, 0.014282915, 0.0046878294, 0.012844471)\n",
      "decoder loss ratio: 0.000461, decoder SINDy loss  ratio: 0.299583\n",
      "Epoch 596\n",
      "   training loss 0.0001900775241665542, (0.0001895771, 0.012030195, 0.0037205373, 0.012837014)\n",
      "   validation loss 0.00030864321161061525, (0.0003080453, 0.013959043, 0.0046954174, 0.012837014)\n",
      "decoder loss ratio: 0.000643, decoder SINDy loss  ratio: 0.300068\n",
      "Epoch 597\n",
      "   training loss 0.00022209054441191256, (0.0002215896, 0.012276329, 0.0037258, 0.012836704)\n",
      "   validation loss 0.0004715940449386835, (0.00047099643, 0.01437207, 0.004692288, 0.012836704)\n",
      "decoder loss ratio: 0.000983, decoder SINDy loss  ratio: 0.299868\n",
      "Epoch 598\n",
      "   training loss 6.416549877030775e-05, (6.3663385e-05, 0.01236017, 0.003736102, 0.012850392)\n",
      "   validation loss 0.00021312104945536703, (0.0002125207, 0.014461081, 0.0047184266, 0.012850392)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.301538\n",
      "Epoch 599\n",
      "   training loss 4.598804662236944e-05, (4.548785e-05, 0.012208539, 0.0037183329, 0.012836139)\n",
      "   validation loss 0.0001675372914178297, (0.00016694021, 0.014287746, 0.0046871975, 0.012836139)\n",
      "decoder loss ratio: 0.000348, decoder SINDy loss  ratio: 0.299542\n",
      "Epoch 600\n",
      "   training loss 8.311704004881904e-05, (8.261565e-05, 0.012158201, 0.0037298673, 0.012840703)\n",
      "   validation loss 0.00021770743478555232, (0.00021710889, 0.014318195, 0.004701482, 0.012840703)\n",
      "decoder loss ratio: 0.000453, decoder SINDy loss  ratio: 0.300455\n",
      "Epoch 601\n",
      "   training loss 0.00012967316433787346, (0.00012917302, 0.0120655475, 0.0037177298, 0.012837529)\n",
      "   validation loss 0.0002654154959600419, (0.00026481866, 0.014201813, 0.004684455, 0.012837529)\n",
      "decoder loss ratio: 0.000552, decoder SINDy loss  ratio: 0.299367\n",
      "Epoch 602\n",
      "   training loss 0.0001316583075094968, (0.00013116037, 0.0121796215, 0.0036936288, 0.01285829)\n",
      "   validation loss 0.00037782255094498396, (0.00037722717, 0.014061552, 0.00466809, 0.01285829)\n",
      "decoder loss ratio: 0.000787, decoder SINDy loss  ratio: 0.298321\n",
      "Epoch 603\n",
      "   training loss 4.6678986109327525e-05, (4.6182267e-05, 0.012239854, 0.0036839782, 0.012832305)\n",
      "   validation loss 0.00022566193365491927, (0.00022506739, 0.0144414585, 0.004662304, 0.012832305)\n",
      "decoder loss ratio: 0.000470, decoder SINDy loss  ratio: 0.297952\n",
      "Epoch 604\n",
      "   training loss 7.26035941625014e-05, (7.2101466e-05, 0.0122917695, 0.0037351334, 0.012861562)\n",
      "   validation loss 0.0001975776831386611, (0.00019697845, 0.014375967, 0.004706271, 0.012861562)\n",
      "decoder loss ratio: 0.000411, decoder SINDy loss  ratio: 0.300761\n",
      "Epoch 605\n",
      "   training loss 7.50304534449242e-05, (7.453069e-05, 0.012240608, 0.003713926, 0.012836907)\n",
      "   validation loss 0.00022789086506236345, (0.00022729364, 0.014467954, 0.0046886867, 0.012836907)\n",
      "decoder loss ratio: 0.000474, decoder SINDy loss  ratio: 0.299638\n",
      "Epoch 606\n",
      "   training loss 0.00010033690341515467, (9.983586e-05, 0.012078968, 0.0037255345, 0.01284947)\n",
      "   validation loss 0.00023632720694877207, (0.00023572976, 0.014198474, 0.004689459, 0.01284947)\n",
      "decoder loss ratio: 0.000492, decoder SINDy loss  ratio: 0.299687\n",
      "Epoch 607\n",
      "   training loss 0.00011729779362212867, (0.00011679878, 0.012476131, 0.0037050345, 0.012851096)\n",
      "   validation loss 0.00042281116475351155, (0.00042221622, 0.014212194, 0.004664076, 0.012851096)\n",
      "decoder loss ratio: 0.000881, decoder SINDy loss  ratio: 0.298065\n",
      "Epoch 608\n",
      "   training loss 7.926562830107287e-05, (7.876984e-05, 0.01232538, 0.0036732461, 0.012846794)\n",
      "   validation loss 0.00020405625400599092, (0.00020346256, 0.01451819, 0.0046521765, 0.012846794)\n",
      "decoder loss ratio: 0.000424, decoder SINDy loss  ratio: 0.297304\n",
      "Epoch 609\n",
      "   training loss 5.194600089453161e-05, (5.1445168e-05, 0.012241037, 0.0037236987, 0.012846389)\n",
      "   validation loss 0.0001779733574949205, (0.0001773765, 0.014378547, 0.0046839314, 0.012846389)\n",
      "decoder loss ratio: 0.000370, decoder SINDy loss  ratio: 0.299334\n",
      "Epoch 610\n",
      "   training loss 7.687347533646971e-05, (7.6374614e-05, 0.012403119, 0.0037031549, 0.012854757)\n",
      "   validation loss 0.00018062035087496042, (0.00018002655, 0.01442682, 0.0046524773, 0.012854757)\n",
      "decoder loss ratio: 0.000376, decoder SINDy loss  ratio: 0.297324\n",
      "Epoch 611\n",
      "   training loss 0.00016449857503175735, (0.00016399019, 0.012752221, 0.0037993647, 0.012845531)\n",
      "   validation loss 0.00037952695856802166, (0.000378925, 0.014256237, 0.00473498, 0.012845531)\n",
      "decoder loss ratio: 0.000791, decoder SINDy loss  ratio: 0.302596\n",
      "Epoch 612\n",
      "   training loss 0.0002515662636142224, (0.00025106984, 0.012227966, 0.0036783125, 0.012856856)\n",
      "   validation loss 0.0004040046769659966, (0.00040340534, 0.014949281, 0.0047076647, 0.012856856)\n",
      "decoder loss ratio: 0.000842, decoder SINDy loss  ratio: 0.300850\n",
      "Epoch 613\n",
      "   training loss 5.826765482197516e-05, (5.7770387e-05, 0.0123053305, 0.0036841496, 0.0128853675)\n",
      "   validation loss 0.00020649824000429362, (0.00020590005, 0.014524153, 0.0046932283, 0.0128853675)\n",
      "decoder loss ratio: 0.000430, decoder SINDy loss  ratio: 0.299928\n",
      "Epoch 614\n",
      "   training loss 5.063923526904546e-05, (5.0144456e-05, 0.012373441, 0.0036629564, 0.012848113)\n",
      "   validation loss 0.00017877182108350098, (0.00017817719, 0.014593151, 0.0046615824, 0.012848113)\n",
      "decoder loss ratio: 0.000372, decoder SINDy loss  ratio: 0.297905\n",
      "Epoch 615\n",
      "   training loss 4.805779826710932e-05, (4.756172e-05, 0.012283222, 0.003676307, 0.012844751)\n",
      "   validation loss 0.00016450653492938727, (0.0001639123, 0.014461709, 0.0046579028, 0.012844751)\n",
      "decoder loss ratio: 0.000342, decoder SINDy loss  ratio: 0.297670\n",
      "Epoch 616\n",
      "   training loss 8.260522008640692e-05, (8.211064e-05, 0.01221244, 0.0036614193, 0.012843983)\n",
      "   validation loss 0.00021666310203727335, (0.00021607241, 0.01431265, 0.004622586, 0.012843983)\n",
      "decoder loss ratio: 0.000451, decoder SINDy loss  ratio: 0.295413\n",
      "Epoch 617\n",
      "   training loss 0.00024024146841838956, (0.00023974058, 0.012448872, 0.0037247494, 0.012842646)\n",
      "   validation loss 0.00036957647535018623, (0.00036897967, 0.014428129, 0.0046837917, 0.012842646)\n",
      "decoder loss ratio: 0.000770, decoder SINDy loss  ratio: 0.299325\n",
      "Epoch 618\n",
      "   training loss 6.804693839512765e-05, (6.7551526e-05, 0.012155153, 0.0036700824, 0.012840824)\n",
      "   validation loss 0.00022464015637524426, (0.00022404782, 0.0144543005, 0.0046392777, 0.012840824)\n",
      "decoder loss ratio: 0.000467, decoder SINDy loss  ratio: 0.296480\n",
      "Epoch 619\n",
      "   training loss 3.789895345107652e-05, (3.740486e-05, 0.012233694, 0.0036570276, 0.012838762)\n",
      "   validation loss 0.00017059696256183088, (0.00017000706, 0.014430337, 0.004615125, 0.012838762)\n",
      "decoder loss ratio: 0.000355, decoder SINDy loss  ratio: 0.294936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620\n",
      "   training loss 6.758810195606202e-05, (6.709179e-05, 0.012219243, 0.0036785554, 0.0128458375)\n",
      "   validation loss 0.0001814420975279063, (0.0001808502, 0.0144409835, 0.004634408, 0.0128458375)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.296169\n",
      "Epoch 621\n",
      "   training loss 0.00016031348786782473, (0.00015981251, 0.012366348, 0.0037248693, 0.012849149)\n",
      "   validation loss 0.0002413467736914754, (0.00024075233, 0.014380483, 0.004659592, 0.012849149)\n",
      "decoder loss ratio: 0.000502, decoder SINDy loss  ratio: 0.297778\n",
      "Epoch 622\n",
      "   training loss 0.00010324381582904607, (0.00010274579, 0.012515399, 0.0036939709, 0.012862378)\n",
      "   validation loss 0.00031973214936442673, (0.00031913814, 0.014340756, 0.004654052, 0.012862378)\n",
      "decoder loss ratio: 0.000666, decoder SINDy loss  ratio: 0.297424\n",
      "Epoch 623\n",
      "   training loss 6.738306547049433e-05, (6.688719e-05, 0.012295312, 0.0036759381, 0.012828574)\n",
      "   validation loss 0.00020177639089524746, (0.00020118193, 0.014693813, 0.0046617403, 0.012828574)\n",
      "decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.297916\n",
      "Epoch 624\n",
      "   training loss 5.9815858548972756e-05, (5.931897e-05, 0.012303486, 0.0036841538, 0.012847628)\n",
      "   validation loss 0.00018128356896340847, (0.00018069, 0.014465058, 0.0046509225, 0.012847628)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.297224\n",
      "Epoch 625\n",
      "   training loss 0.0001735683617880568, (0.00017306782, 0.012867138, 0.0037215657, 0.012838628)\n",
      "   validation loss 0.0003027669445145875, (0.0003021714, 0.014737585, 0.0046716854, 0.012838628)\n",
      "decoder loss ratio: 0.000630, decoder SINDy loss  ratio: 0.298551\n",
      "Epoch 626\n",
      "   training loss 4.31926928285975e-05, (4.2692976e-05, 0.0125121, 0.00371221, 0.012849796)\n",
      "   validation loss 0.00018713250756263733, (0.00018653645, 0.014743578, 0.0046756417, 0.012849796)\n",
      "decoder loss ratio: 0.000389, decoder SINDy loss  ratio: 0.298804\n",
      "Epoch 627\n",
      "   training loss 7.845423533581197e-05, (7.795519e-05, 0.012422599, 0.003706289, 0.012841277)\n",
      "   validation loss 0.0001898319460451603, (0.0001892374, 0.014404967, 0.004661387, 0.012841277)\n",
      "decoder loss ratio: 0.000395, decoder SINDy loss  ratio: 0.297893\n",
      "Epoch 628\n",
      "   training loss 0.0001709030184429139, (0.00017040814, 0.012911711, 0.003663174, 0.012856505)\n",
      "   validation loss 0.0003480451414361596, (0.00034745332, 0.014535483, 0.0046328916, 0.012856505)\n",
      "decoder loss ratio: 0.000725, decoder SINDy loss  ratio: 0.296072\n",
      "Epoch 629\n",
      "   training loss 0.0001652987120905891, (0.00016479948, 0.0121912025, 0.003706176, 0.012860558)\n",
      "   validation loss 0.0003268083091825247, (0.00032620522, 0.0153491115, 0.00474488, 0.012860558)\n",
      "decoder loss ratio: 0.000681, decoder SINDy loss  ratio: 0.303229\n",
      "Epoch 630\n",
      "   training loss 8.019126107683405e-05, (7.969704e-05, 0.012409058, 0.003655627, 0.01286509)\n",
      "   validation loss 0.0002149127540178597, (0.0002143194, 0.01464792, 0.0046470542, 0.01286509)\n",
      "decoder loss ratio: 0.000447, decoder SINDy loss  ratio: 0.296977\n",
      "Epoch 631\n",
      "   training loss 5.392597086029127e-05, (5.3433698e-05, 0.012494086, 0.0036378955, 0.012848107)\n",
      "   validation loss 0.00019405753118917346, (0.00019346635, 0.014684891, 0.004627, 0.012848107)\n",
      "decoder loss ratio: 0.000404, decoder SINDy loss  ratio: 0.295695\n",
      "Epoch 632\n",
      "   training loss 8.799057832220569e-05, (8.749879e-05, 0.012177379, 0.0036340856, 0.012838356)\n",
      "   validation loss 0.0002233217965112999, (0.00022273228, 0.0146449385, 0.004611303, 0.012838356)\n",
      "decoder loss ratio: 0.000465, decoder SINDy loss  ratio: 0.294692\n",
      "Epoch 633\n",
      "   training loss 0.00016592854808550328, (0.00016542725, 0.012549178, 0.0037273313, 0.01285661)\n",
      "   validation loss 0.0002738113689702004, (0.0002732151, 0.014521904, 0.0046771765, 0.01285661)\n",
      "decoder loss ratio: 0.000570, decoder SINDy loss  ratio: 0.298902\n",
      "Epoch 634\n",
      "   training loss 8.616528793936595e-05, (8.567324e-05, 0.012608744, 0.0036355942, 0.012849222)\n",
      "   validation loss 0.00020923353440593928, (0.00020864536, 0.014557461, 0.00459677, 0.012849222)\n",
      "decoder loss ratio: 0.000435, decoder SINDy loss  ratio: 0.293763\n",
      "Epoch 635\n",
      "   training loss 0.00011095656373072416, (0.000110460955, 0.0121200085, 0.0036699278, 0.01286188)\n",
      "   validation loss 0.0002682948252186179, (0.00026769825, 0.015067199, 0.0046797483, 0.01286188)\n",
      "decoder loss ratio: 0.000558, decoder SINDy loss  ratio: 0.299066\n",
      "Epoch 636\n",
      "   training loss 9.540482278680429e-05, (9.490985e-05, 0.012447809, 0.0036633564, 0.012863848)\n",
      "   validation loss 0.00022580500808544457, (0.00022521052, 0.014662009, 0.004658558, 0.012863848)\n",
      "decoder loss ratio: 0.000470, decoder SINDy loss  ratio: 0.297712\n",
      "Epoch 637\n",
      "   training loss 6.582320929737762e-05, (6.533114e-05, 0.012444007, 0.0036345196, 0.012861543)\n",
      "   validation loss 0.0002069900365313515, (0.0002063995, 0.014797129, 0.004619271, 0.012861543)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.295201\n",
      "Epoch 638\n",
      "   training loss 0.00015270060976035893, (0.0001522084, 0.012074574, 0.0036367655, 0.012851663)\n",
      "   validation loss 0.00035481908707879484, (0.0003542279, 0.01477526, 0.004626635, 0.012851663)\n",
      "decoder loss ratio: 0.000739, decoder SINDy loss  ratio: 0.295672\n",
      "Epoch 639\n",
      "   training loss 0.00010375611600466073, (0.00010326013, 0.012414689, 0.0036730932, 0.01286773)\n",
      "   validation loss 0.0002384807012276724, (0.00023788834, 0.014493571, 0.0046368013, 0.01286773)\n",
      "decoder loss ratio: 0.000496, decoder SINDy loss  ratio: 0.296322\n",
      "Epoch 640\n",
      "   training loss 7.359203300438821e-05, (7.310158e-05, 0.01249117, 0.0036159987, 0.012885098)\n",
      "   validation loss 0.0002040975959971547, (0.00020351124, 0.014662623, 0.004575041, 0.012885098)\n",
      "decoder loss ratio: 0.000425, decoder SINDy loss  ratio: 0.292375\n",
      "Epoch 641\n",
      "   training loss 7.323372119572014e-05, (7.2739604e-05, 0.012136809, 0.0036556292, 0.0128548555)\n",
      "   validation loss 0.00021338960505090654, (0.0002127966, 0.014766779, 0.004644576, 0.0128548555)\n",
      "decoder loss ratio: 0.000444, decoder SINDy loss  ratio: 0.296819\n",
      "Epoch 642\n",
      "   training loss 7.397303852485493e-05, (7.347837e-05, 0.012225903, 0.003660324, 0.012864058)\n",
      "   validation loss 0.00019856441940646619, (0.00019797304, 0.014478216, 0.00462736, 0.012864058)\n",
      "decoder loss ratio: 0.000413, decoder SINDy loss  ratio: 0.295718\n",
      "Epoch 643\n",
      "   training loss 0.00022644409909844398, (0.00022594325, 0.013022966, 0.0037216633, 0.012868951)\n",
      "   validation loss 0.0003835354291368276, (0.00038293863, 0.014926182, 0.0046809446, 0.012868951)\n",
      "decoder loss ratio: 0.000799, decoder SINDy loss  ratio: 0.299143\n",
      "Epoch 644\n",
      "   training loss 0.00012485701881814748, (0.00012436674, 0.012215664, 0.0036146499, 0.012881887)\n",
      "   validation loss 0.00026307214284315705, (0.00026247842, 0.015100959, 0.004649098, 0.012881887)\n",
      "decoder loss ratio: 0.000548, decoder SINDy loss  ratio: 0.297108\n",
      "Epoch 645\n",
      "   training loss 9.83081990852952e-05, (9.781365e-05, 0.012376015, 0.0036591436, 0.012863128)\n",
      "   validation loss 0.00023997321841306984, (0.00023937853, 0.014660823, 0.0046606218, 0.012863128)\n",
      "decoder loss ratio: 0.000499, decoder SINDy loss  ratio: 0.297844\n",
      "Epoch 646\n",
      "   training loss 8.945724403019994e-05, (8.896542e-05, 0.012447548, 0.003630957, 0.012873518)\n",
      "   validation loss 0.00020746115478686988, (0.00020687185, 0.014755373, 0.0046056984, 0.012873518)\n",
      "decoder loss ratio: 0.000432, decoder SINDy loss  ratio: 0.294334\n",
      "Epoch 647\n",
      "   training loss 0.00011854455806314945, (0.00011804673, 0.01240928, 0.003692626, 0.012856765)\n",
      "   validation loss 0.0002342701773159206, (0.00023367656, 0.014427207, 0.00465055, 0.012856765)\n",
      "decoder loss ratio: 0.000487, decoder SINDy loss  ratio: 0.297200\n",
      "Epoch 648\n",
      "   training loss 0.00015429688210133463, (0.00015380324, 0.01224286, 0.0036506283, 0.012857511)\n",
      "   validation loss 0.0003183827502653003, (0.0003177866, 0.015138334, 0.0046757013, 0.012857511)\n",
      "decoder loss ratio: 0.000663, decoder SINDy loss  ratio: 0.298808\n",
      "Epoch 649\n",
      "   training loss 8.999159763334319e-05, (8.949293e-05, 0.012867597, 0.0036979783, 0.012886619)\n",
      "   validation loss 0.00024842689163051546, (0.00024782875, 0.014970957, 0.0046926336, 0.012886619)\n",
      "decoder loss ratio: 0.000517, decoder SINDy loss  ratio: 0.299890\n",
      "Epoch 650\n",
      "   training loss 4.375071148388088e-05, (4.3256754e-05, 0.012625185, 0.003652683, 0.012869161)\n",
      "   validation loss 0.00014384496898856014, (0.00014325386, 0.014997213, 0.004624127, 0.012869161)\n",
      "decoder loss ratio: 0.000299, decoder SINDy loss  ratio: 0.295512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651\n",
      "   training loss 5.583591337199323e-05, (5.5342723e-05, 0.012321386, 0.003646909, 0.012850046)\n",
      "   validation loss 0.00017039457452483475, (0.00016980473, 0.014787317, 0.004613475, 0.012850046)\n",
      "decoder loss ratio: 0.000354, decoder SINDy loss  ratio: 0.294831\n",
      "Epoch 652\n",
      "   training loss 0.00015118741430342197, (0.00015068747, 0.01288654, 0.0037116953, 0.012877257)\n",
      "   validation loss 0.0003896245907526463, (0.0003890291, 0.014849349, 0.004667018, 0.012877257)\n",
      "decoder loss ratio: 0.000812, decoder SINDy loss  ratio: 0.298253\n",
      "Epoch 653\n",
      "   training loss 9.138328459812328e-05, (9.089193e-05, 0.012554948, 0.0036273065, 0.012862361)\n",
      "   validation loss 0.00023473183682654053, (0.00023414231, 0.015232552, 0.004608994, 0.012862361)\n",
      "decoder loss ratio: 0.000488, decoder SINDy loss  ratio: 0.294545\n",
      "Epoch 654\n",
      "   training loss 0.00010771119559649378, (0.00010721698, 0.012444578, 0.0036541666, 0.012879998)\n",
      "   validation loss 0.000220402012928389, (0.00021980861, 0.014877709, 0.004646033, 0.012879998)\n",
      "decoder loss ratio: 0.000459, decoder SINDy loss  ratio: 0.296912\n",
      "Epoch 655\n",
      "   training loss 5.558164411922917e-05, (5.508912e-05, 0.012546222, 0.0036365914, 0.01288636)\n",
      "   validation loss 0.00020119466353207827, (0.00020060585, 0.0149225425, 0.0045995098, 0.01288636)\n",
      "decoder loss ratio: 0.000418, decoder SINDy loss  ratio: 0.293939\n",
      "Epoch 656\n",
      "   training loss 6.297096842899919e-05, (6.2479085e-05, 0.012309794, 0.0036310228, 0.012878544)\n",
      "   validation loss 0.000188495556358248, (0.00018790779, 0.014697216, 0.0045897705, 0.012878544)\n",
      "decoder loss ratio: 0.000392, decoder SINDy loss  ratio: 0.293316\n",
      "Epoch 657\n",
      "   training loss 0.00014648902288172394, (0.00014599609, 0.012627453, 0.0036414019, 0.01287879)\n",
      "   validation loss 0.00032262495369650424, (0.0003220357, 0.014769873, 0.004604918, 0.01287879)\n",
      "decoder loss ratio: 0.000672, decoder SINDy loss  ratio: 0.294284\n",
      "Epoch 658\n",
      "   training loss 7.731650839559734e-05, (7.682275e-05, 0.012294322, 0.0036487668, 0.012888804)\n",
      "   validation loss 0.000198037174413912, (0.00019744449, 0.015040089, 0.004637979, 0.012888804)\n",
      "decoder loss ratio: 0.000412, decoder SINDy loss  ratio: 0.296397\n",
      "Epoch 659\n",
      "   training loss 0.00010260447743348777, (0.000102113285, 0.012374163, 0.0036251002, 0.012868192)\n",
      "   validation loss 0.0002448692684993148, (0.0002442806, 0.014697461, 0.004599909, 0.012868192)\n",
      "decoder loss ratio: 0.000510, decoder SINDy loss  ratio: 0.293964\n",
      "Epoch 660\n",
      "   training loss 0.0001508842979092151, (0.00015038892, 0.0128979245, 0.0036648568, 0.012888395)\n",
      "   validation loss 0.0002748079423326999, (0.00027421792, 0.014981793, 0.0046115587, 0.012888395)\n",
      "decoder loss ratio: 0.000572, decoder SINDy loss  ratio: 0.294709\n",
      "Epoch 661\n",
      "   training loss 0.00012137401790823787, (0.000120885365, 0.012346986, 0.0035992204, 0.012872994)\n",
      "   validation loss 0.0002496825472917408, (0.0002490925, 0.015214378, 0.0046132845, 0.012872994)\n",
      "decoder loss ratio: 0.000520, decoder SINDy loss  ratio: 0.294819\n",
      "Epoch 662\n",
      "   training loss 8.925874863052741e-05, (8.876511e-05, 0.012467645, 0.0036479686, 0.0128839305)\n",
      "   validation loss 0.0002198231522925198, (0.00021922974, 0.014839746, 0.004645713, 0.0128839305)\n",
      "decoder loss ratio: 0.000457, decoder SINDy loss  ratio: 0.296891\n",
      "Epoch 663\n",
      "   training loss 6.432628288166597e-05, (6.383688e-05, 0.0125853205, 0.0036073178, 0.012866602)\n",
      "   validation loss 0.0001838264724938199, (0.00018323954, 0.015004545, 0.0045826226, 0.012866602)\n",
      "decoder loss ratio: 0.000382, decoder SINDy loss  ratio: 0.292859\n",
      "Epoch 664\n",
      "   training loss 5.4287538659991696e-05, (5.3795782e-05, 0.012341186, 0.0036304821, 0.012870672)\n",
      "   validation loss 0.0001523448299849406, (0.00015175685, 0.014615055, 0.0045927446, 0.012870672)\n",
      "decoder loss ratio: 0.000317, decoder SINDy loss  ratio: 0.293506\n",
      "Epoch 665\n",
      "   training loss 0.0001172275806311518, (0.000116749754, 0.012341523, 0.00349191, 0.0128637)\n",
      "   validation loss 0.0003041878517251462, (0.0003036132, 0.014846116, 0.004460088, 0.0128637)\n",
      "decoder loss ratio: 0.000633, decoder SINDy loss  ratio: 0.285029\n",
      "Epoch 666\n",
      "   training loss 0.000336064345901832, (0.00033556574, 0.012115882, 0.0036981225, 0.0128777)\n",
      "   validation loss 0.00034735992085188627, (0.0003467677, 0.0146535225, 0.004634586, 0.0128777)\n",
      "decoder loss ratio: 0.000723, decoder SINDy loss  ratio: 0.296180\n",
      "Epoch 667\n",
      "   training loss 5.723140566260554e-05, (5.6744277e-05, 0.01247445, 0.003581798, 0.012894666)\n",
      "   validation loss 0.0002981935685966164, (0.00029760826, 0.0149334865, 0.004563388, 0.012894666)\n",
      "decoder loss ratio: 0.000621, decoder SINDy loss  ratio: 0.291630\n",
      "Epoch 668\n",
      "   training loss 5.162863089935854e-05, (5.1141484e-05, 0.012358977, 0.0035835865, 0.012878921)\n",
      "   validation loss 0.00016084889648482203, (0.0001602634, 0.014999213, 0.0045671016, 0.012878921)\n",
      "decoder loss ratio: 0.000334, decoder SINDy loss  ratio: 0.291868\n",
      "Epoch 669\n",
      "   training loss 0.00012624822556972504, (0.00012575927, 0.012159458, 0.003603352, 0.012862852)\n",
      "   validation loss 0.000250475131906569, (0.0002498888, 0.01491651, 0.004576967, 0.012862852)\n",
      "decoder loss ratio: 0.000521, decoder SINDy loss  ratio: 0.292498\n",
      "Epoch 670\n",
      "   training loss 6.265376578085124e-05, (6.216269e-05, 0.012596615, 0.0036210841, 0.012896731)\n",
      "   validation loss 0.0002158498828066513, (0.00021526508, 0.014932122, 0.0045582317, 0.012896731)\n",
      "decoder loss ratio: 0.000449, decoder SINDy loss  ratio: 0.291301\n",
      "Epoch 671\n",
      "   training loss 0.00010530152212595567, (0.000104817285, 0.0124446675, 0.003553368, 0.012890096)\n",
      "   validation loss 0.00022333586821332574, (0.00022275322, 0.015033981, 0.0045374013, 0.012890096)\n",
      "decoder loss ratio: 0.000465, decoder SINDy loss  ratio: 0.289969\n",
      "Epoch 672\n",
      "   training loss 9.174916340271011e-05, (9.125541e-05, 0.012267518, 0.0036471062, 0.012904485)\n",
      "   validation loss 0.0002129872009390965, (0.00021239505, 0.014952227, 0.0046310425, 0.012904485)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.295954\n",
      "Epoch 673\n",
      "   training loss 4.292360245017335e-05, (4.24349e-05, 0.012272774, 0.003599171, 0.012878745)\n",
      "   validation loss 0.0001372127590002492, (0.00013662793, 0.014816761, 0.004560382, 0.012878745)\n",
      "decoder loss ratio: 0.000285, decoder SINDy loss  ratio: 0.291438\n",
      "Epoch 674\n",
      "   training loss 0.0002462408156134188, (0.00024573843, 0.012857278, 0.0037344766, 0.0128932)\n",
      "   validation loss 0.000377061718609184, (0.00037646474, 0.014931761, 0.0046804384, 0.0128932)\n",
      "decoder loss ratio: 0.000785, decoder SINDy loss  ratio: 0.299110\n",
      "Epoch 675\n",
      "   training loss 0.00013704611046705395, (0.00013656149, 0.012238614, 0.0035574818, 0.012887123)\n",
      "   validation loss 0.000297654012683779, (0.00029706166, 0.015591687, 0.0046348074, 0.012887123)\n",
      "decoder loss ratio: 0.000620, decoder SINDy loss  ratio: 0.296194\n",
      "Epoch 676\n",
      "   training loss 0.0001146381109720096, (0.00011414639, 0.012517773, 0.0036256604, 0.012915345)\n",
      "   validation loss 0.00028380422736518085, (0.00028321086, 0.014942005, 0.0046419394, 0.012915345)\n",
      "decoder loss ratio: 0.000591, decoder SINDy loss  ratio: 0.296650\n",
      "Epoch 677\n",
      "   training loss 3.1990970455808565e-05, (3.1504325e-05, 0.012499294, 0.0035795656, 0.01286901)\n",
      "   validation loss 0.00013123854296281934, (0.00013065284, 0.015034497, 0.004570037, 0.01286901)\n",
      "decoder loss ratio: 0.000273, decoder SINDy loss  ratio: 0.292055\n",
      "Epoch 678\n",
      "   training loss 4.5001703256275505e-05, (4.4514385e-05, 0.012328121, 0.0035869896, 0.0128621105)\n",
      "   validation loss 0.00012689725554082543, (0.00012631211, 0.014869693, 0.004565295, 0.0128621105)\n",
      "decoder loss ratio: 0.000264, decoder SINDy loss  ratio: 0.291752\n",
      "Epoch 679\n",
      "   training loss 0.00031117600155994296, (0.0003106731, 0.012909901, 0.0037411419, 0.012880258)\n",
      "   validation loss 0.000493814644869417, (0.0004932152, 0.015164235, 0.004706136, 0.012880258)\n",
      "decoder loss ratio: 0.001029, decoder SINDy loss  ratio: 0.300753\n",
      "Epoch 680\n",
      "   training loss 0.00010917570034507662, (0.0001086902, 0.012408089, 0.0035664884, 0.012885564)\n",
      "   validation loss 0.00023697219148743898, (0.00023638234, 0.015642693, 0.0046098977, 0.012885564)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.294602\n",
      "Epoch 681\n",
      "   training loss 9.525388304609805e-05, (9.476226e-05, 0.012882262, 0.0036276504, 0.01288604)\n",
      "   validation loss 0.00025706953601911664, (0.00025647707, 0.015190807, 0.004635904, 0.01288604)\n",
      "decoder loss ratio: 0.000535, decoder SINDy loss  ratio: 0.296264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682\n",
      "   training loss 3.7956568121444434e-05, (3.747025e-05, 0.012643541, 0.003574849, 0.012883316)\n",
      "   validation loss 0.00015164467913564295, (0.00015106019, 0.015216172, 0.0045567057, 0.012883316)\n",
      "decoder loss ratio: 0.000315, decoder SINDy loss  ratio: 0.291203\n",
      "Epoch 683\n",
      "   training loss 6.392228533513844e-05, (6.34326e-05, 0.012419111, 0.0036098128, 0.012870617)\n",
      "   validation loss 0.00014478332013823092, (0.00014419763, 0.014974741, 0.0045697656, 0.012870617)\n",
      "decoder loss ratio: 0.000301, decoder SINDy loss  ratio: 0.292038\n",
      "Epoch 684\n",
      "   training loss 0.0001963761606020853, (0.00019587399, 0.01328894, 0.0037303185, 0.012914043)\n",
      "   validation loss 0.00045222914195619524, (0.00045163024, 0.015676778, 0.004697638, 0.012914043)\n",
      "decoder loss ratio: 0.000942, decoder SINDy loss  ratio: 0.300210\n",
      "Epoch 685\n",
      "   training loss 8.888322190614417e-05, (8.839065e-05, 0.012887674, 0.0036358144, 0.012899865)\n",
      "   validation loss 0.0002428096777293831, (0.00024221245, 0.015903288, 0.004682166, 0.012899865)\n",
      "decoder loss ratio: 0.000505, decoder SINDy loss  ratio: 0.299221\n",
      "Epoch 686\n",
      "   training loss 0.0001044794189510867, (0.00010398807, 0.01295089, 0.0036250586, 0.012884261)\n",
      "   validation loss 0.00020697867148555815, (0.00020638874, 0.015479671, 0.0046109413, 0.012884261)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.294669\n",
      "Epoch 687\n",
      "   training loss 6.122989725554362e-05, (6.073923e-05, 0.013004555, 0.003620346, 0.012862914)\n",
      "   validation loss 0.00017142477736342698, (0.00017083802, 0.01549764, 0.0045814444, 0.012862914)\n",
      "decoder loss ratio: 0.000356, decoder SINDy loss  ratio: 0.292784\n",
      "Epoch 688\n",
      "   training loss 3.583350553526543e-05, (3.53436e-05, 0.012858546, 0.0036104699, 0.012885564)\n",
      "   validation loss 0.00014157622354105115, (0.00014099052, 0.015266942, 0.004568379, 0.012885564)\n",
      "decoder loss ratio: 0.000294, decoder SINDy loss  ratio: 0.291949\n",
      "Epoch 689\n",
      "   training loss 0.00011351495777489617, (0.000113031856, 0.012733661, 0.0035447353, 0.0128635)\n",
      "   validation loss 0.0002319598861504346, (0.00023138094, 0.015457337, 0.004503045, 0.0128635)\n",
      "decoder loss ratio: 0.000483, decoder SINDy loss  ratio: 0.287774\n",
      "Epoch 690\n",
      "   training loss 0.0002449540770612657, (0.00024445824, 0.012674014, 0.0036695828, 0.012887056)\n",
      "   validation loss 0.00031942149507813156, (0.00031882786, 0.0153299775, 0.0046474575, 0.012887056)\n",
      "decoder loss ratio: 0.000665, decoder SINDy loss  ratio: 0.297003\n",
      "Epoch 691\n",
      "   training loss 8.29952914500609e-05, (8.2504455e-05, 0.012793336, 0.0036176504, 0.012906545)\n",
      "   validation loss 0.00028855266282334924, (0.00028796613, 0.0154172685, 0.004574546, 0.012906545)\n",
      "decoder loss ratio: 0.000601, decoder SINDy loss  ratio: 0.292343\n",
      "Epoch 692\n",
      "   training loss 3.6727033148054034e-05, (3.6239868e-05, 0.012695105, 0.0035815404, 0.01290093)\n",
      "   validation loss 0.00017015471530612558, (0.00016956973, 0.015401029, 0.004559874, 0.01290093)\n",
      "decoder loss ratio: 0.000354, decoder SINDy loss  ratio: 0.291406\n",
      "Epoch 693\n",
      "   training loss 0.00013092535664327443, (0.00013043385, 0.0125311045, 0.0036281175, 0.012869515)\n",
      "   validation loss 0.00030392216285690665, (0.00030333418, 0.015519883, 0.004593014, 0.012869515)\n",
      "decoder loss ratio: 0.000633, decoder SINDy loss  ratio: 0.293523\n",
      "Epoch 694\n",
      "   training loss 0.00011946194717893377, (0.00011896985, 0.012624617, 0.0036305645, 0.012903793)\n",
      "   validation loss 0.00024297990603372455, (0.00024239207, 0.0151838865, 0.0045881057, 0.012903793)\n",
      "decoder loss ratio: 0.000506, decoder SINDy loss  ratio: 0.293210\n",
      "Epoch 695\n",
      "   training loss 6.486250640591606e-05, (6.4377906e-05, 0.012784488, 0.003557026, 0.0128903575)\n",
      "   validation loss 0.00021168998500797898, (0.00021110807, 0.01529938, 0.004530151, 0.0128903575)\n",
      "decoder loss ratio: 0.000440, decoder SINDy loss  ratio: 0.289506\n",
      "Epoch 696\n",
      "   training loss 9.696069901110604e-05, (9.646918e-05, 0.012538966, 0.0036256367, 0.012896223)\n",
      "   validation loss 0.00025052583077922463, (0.00024993508, 0.015449173, 0.004617976, 0.012896223)\n",
      "decoder loss ratio: 0.000521, decoder SINDy loss  ratio: 0.295119\n",
      "Epoch 697\n",
      "   training loss 0.00010644231224432588, (0.0001059484, 0.012780975, 0.0036506685, 0.012884967)\n",
      "   validation loss 0.00022874325804878026, (0.00022815233, 0.015283838, 0.004620767, 0.012884967)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.295297\n",
      "Epoch 698\n",
      "   training loss 8.044816058827564e-05, (7.995896e-05, 0.013154898, 0.0036023906, 0.012896151)\n",
      "   validation loss 0.00022575544426217675, (0.00022516915, 0.015561126, 0.0045734392, 0.012896151)\n",
      "decoder loss ratio: 0.000470, decoder SINDy loss  ratio: 0.292273\n",
      "Epoch 699\n",
      "   training loss 6.133221177151427e-05, (6.084234e-05, 0.0128217, 0.0036096163, 0.012890478)\n",
      "   validation loss 0.0001810858811950311, (0.00018049793, 0.0155273015, 0.0045904866, 0.012890478)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.293362\n",
      "Epoch 700\n",
      "   training loss 4.485846875468269e-05, (4.4366883e-05, 0.012575419, 0.0036263918, 0.012894776)\n",
      "   validation loss 0.00014219831791706383, (0.00014160982, 0.015279406, 0.0045954753, 0.012894776)\n",
      "decoder loss ratio: 0.000295, decoder SINDy loss  ratio: 0.293681\n",
      "Epoch 701\n",
      "   training loss 0.00017753989959601313, (0.00017704238, 0.012969583, 0.003685793, 0.012893124)\n",
      "   validation loss 0.00037710322067141533, (0.00037651006, 0.015257043, 0.0046424456, 0.012893124)\n",
      "decoder loss ratio: 0.000785, decoder SINDy loss  ratio: 0.296682\n",
      "Epoch 702\n",
      "   training loss 0.00019114774477202445, (0.00019066462, 0.012988758, 0.0035410582, 0.012902356)\n",
      "   validation loss 0.0003217940393369645, (0.00032120518, 0.016202874, 0.0045983964, 0.012902356)\n",
      "decoder loss ratio: 0.000670, decoder SINDy loss  ratio: 0.293867\n",
      "Epoch 703\n",
      "   training loss 0.00013168680015951395, (0.00013119279, 0.013044612, 0.003647217, 0.012929013)\n",
      "   validation loss 0.00029694748809561133, (0.00029635197, 0.015603656, 0.004662471, 0.012929013)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.297962\n",
      "Epoch 704\n",
      "   training loss 4.79813534184359e-05, (4.749289e-05, 0.012949392, 0.003596024, 0.012886195)\n",
      "   validation loss 0.0001405043003614992, (0.00013991805, 0.015633205, 0.00457396, 0.012886195)\n",
      "decoder loss ratio: 0.000292, decoder SINDy loss  ratio: 0.292306\n",
      "Epoch 705\n",
      "   training loss 4.915267345495522e-05, (4.866353e-05, 0.012846175, 0.0036043276, 0.012871178)\n",
      "   validation loss 0.00013776464038528502, (0.00013717904, 0.015372519, 0.0045688404, 0.012871178)\n",
      "decoder loss ratio: 0.000286, decoder SINDy loss  ratio: 0.291979\n",
      "Epoch 706\n",
      "   training loss 0.00010699439735617489, (0.00010650282, 0.012977545, 0.0036267375, 0.012889988)\n",
      "   validation loss 0.0003238398930989206, (0.00032325104, 0.015281188, 0.0045994706, 0.012889988)\n",
      "decoder loss ratio: 0.000674, decoder SINDy loss  ratio: 0.293936\n",
      "Epoch 707\n",
      "   training loss 0.00011332181020407006, (0.0001128363, 0.012627861, 0.00356697, 0.012881212)\n",
      "   validation loss 0.0002292944845976308, (0.00022870375, 0.01613928, 0.004619209, 0.012881212)\n",
      "decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.295198\n",
      "Epoch 708\n",
      "   training loss 0.00010704106534831226, (0.00010654996, 0.013019479, 0.00362083, 0.012902816)\n",
      "   validation loss 0.000265907117864117, (0.0002653153, 0.015552363, 0.0046281577, 0.012902816)\n",
      "decoder loss ratio: 0.000553, decoder SINDy loss  ratio: 0.295769\n",
      "Epoch 709\n",
      "   training loss 4.2304473026888445e-05, (4.181874e-05, 0.012897571, 0.0035693375, 0.012879898)\n",
      "   validation loss 0.00014982068387325853, (0.00014923737, 0.015653506, 0.0045451326, 0.012879898)\n",
      "decoder loss ratio: 0.000311, decoder SINDy loss  ratio: 0.290464\n",
      "Epoch 710\n",
      "   training loss 5.639838127535768e-05, (5.5910226e-05, 0.012685218, 0.0035931037, 0.012884785)\n",
      "   validation loss 0.00013757917622569948, (0.00013699521, 0.015373882, 0.0045512835, 0.012884785)\n",
      "decoder loss ratio: 0.000286, decoder SINDy loss  ratio: 0.290857\n",
      "Epoch 711\n",
      "   training loss 0.00027428922476246953, (0.00027379167, 0.013019216, 0.003684707, 0.012906306)\n",
      "   validation loss 0.0006109887617640197, (0.00061039074, 0.015792815, 0.0046900036, 0.012906306)\n",
      "decoder loss ratio: 0.001273, decoder SINDy loss  ratio: 0.299722\n",
      "Epoch 712\n",
      "   training loss 8.227112994063646e-05, (8.177313e-05, 0.013458743, 0.003688787, 0.012912371)\n",
      "   validation loss 0.0001754768454702571, (0.0001748788, 0.016229277, 0.004689279, 0.012912371)\n",
      "decoder loss ratio: 0.000365, decoder SINDy loss  ratio: 0.299675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713\n",
      "   training loss 4.689637353294529e-05, (4.6402627e-05, 0.01342532, 0.0036502979, 0.012871655)\n",
      "   validation loss 0.00014248861407395452, (0.0001418985, 0.016076298, 0.0046139746, 0.012871655)\n",
      "decoder loss ratio: 0.000296, decoder SINDy loss  ratio: 0.294863\n",
      "Epoch 714\n",
      "   training loss 3.773742719204165e-05, (3.7244085e-05, 0.013416606, 0.003644878, 0.012885323)\n",
      "   validation loss 0.00012136651639593765, (0.00012077767, 0.016003665, 0.0045999587, 0.012885323)\n",
      "decoder loss ratio: 0.000252, decoder SINDy loss  ratio: 0.293967\n",
      "Epoch 715\n",
      "   training loss 2.3002910893410444e-05, (2.2514807e-05, 0.013141132, 0.003594095, 0.012869447)\n",
      "   validation loss 0.00011797368642874062, (0.000117389405, 0.015774889, 0.004555877, 0.012869447)\n",
      "decoder loss ratio: 0.000245, decoder SINDy loss  ratio: 0.291150\n",
      "Epoch 716\n",
      "   training loss 4.6455010306090117e-05, (4.5970573e-05, 0.013028574, 0.0035573246, 0.012870526)\n",
      "   validation loss 0.00014122175343800336, (0.00014064013, 0.015682155, 0.0045291902, 0.012870526)\n",
      "decoder loss ratio: 0.000293, decoder SINDy loss  ratio: 0.289445\n",
      "Epoch 717\n",
      "   training loss 8.784155215835199e-05, (8.734563e-05, 0.013160768, 0.0036713607, 0.012878559)\n",
      "   validation loss 0.00021915380784776062, (0.00021856224, 0.015963253, 0.0046277693, 0.012878559)\n",
      "decoder loss ratio: 0.000456, decoder SINDy loss  ratio: 0.295745\n",
      "Epoch 718\n",
      "   training loss 7.858388562453911e-05, (7.809242e-05, 0.013077948, 0.0036258604, 0.012888734)\n",
      "   validation loss 0.00017952086636796594, (0.00017893346, 0.015747435, 0.0045851306, 0.012888734)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.293020\n",
      "Epoch 719\n",
      "   training loss 0.0001634600484976545, (0.00016296416, 0.013511094, 0.003668076, 0.012907363)\n",
      "   validation loss 0.00028554516029544175, (0.00028495138, 0.015827803, 0.0046468936, 0.012907363)\n",
      "decoder loss ratio: 0.000594, decoder SINDy loss  ratio: 0.296967\n",
      "Epoch 720\n",
      "   training loss 8.737501775613055e-05, (8.6886634e-05, 0.012922395, 0.0035940937, 0.012897204)\n",
      "   validation loss 0.000209648089366965, (0.00020905699, 0.016114736, 0.0046212603, 0.012897204)\n",
      "decoder loss ratio: 0.000436, decoder SINDy loss  ratio: 0.295329\n",
      "Epoch 721\n",
      "   training loss 0.0001901614450616762, (0.00018966802, 0.012958653, 0.0036459411, 0.012883133)\n",
      "   validation loss 0.0003327688609715551, (0.0003321759, 0.015650261, 0.0046412055, 0.012883133)\n",
      "decoder loss ratio: 0.000693, decoder SINDy loss  ratio: 0.296603\n",
      "Epoch 722\n",
      "   training loss 6.674908217974007e-05, (6.626423e-05, 0.0130570205, 0.0035627077, 0.012858853)\n",
      "   validation loss 0.00023127032909542322, (0.00023068761, 0.015905749, 0.0045411745, 0.012858853)\n",
      "decoder loss ratio: 0.000481, decoder SINDy loss  ratio: 0.290211\n",
      "Epoch 723\n",
      "   training loss 0.00010380784806329757, (0.000103318205, 0.012655101, 0.0036105425, 0.012858512)\n",
      "   validation loss 0.00020432677411008626, (0.00020374161, 0.015443102, 0.004565857, 0.012858512)\n",
      "decoder loss ratio: 0.000425, decoder SINDy loss  ratio: 0.291788\n",
      "Epoch 724\n",
      "   training loss 0.00016522564692422748, (0.00016474008, 0.0127889775, 0.0035671205, 0.012885428)\n",
      "   validation loss 0.0005732447025366127, (0.000572661, 0.015588016, 0.0045486363, 0.012885428)\n",
      "decoder loss ratio: 0.001195, decoder SINDy loss  ratio: 0.290687\n",
      "Epoch 725\n",
      "   training loss 9.206659160554409e-05, (9.158172e-05, 0.012906681, 0.0035612755, 0.0128740715)\n",
      "   validation loss 0.00020361490896902978, (0.00020303323, 0.015734568, 0.0045294953, 0.0128740715)\n",
      "decoder loss ratio: 0.000424, decoder SINDy loss  ratio: 0.289464\n",
      "Epoch 726\n",
      "   training loss 0.00010635898797772825, (0.00010587086, 0.012658604, 0.003595782, 0.012855391)\n",
      "   validation loss 0.00020185914763715118, (0.0002012768, 0.0156044075, 0.004538019, 0.012855391)\n",
      "decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.290009\n",
      "Epoch 727\n",
      "   training loss 0.00010463083162903786, (0.00010413896, 0.013139884, 0.0036304055, 0.012882448)\n",
      "   validation loss 0.00024878879776224494, (0.00024820378, 0.015833488, 0.004562027, 0.012882448)\n",
      "decoder loss ratio: 0.000518, decoder SINDy loss  ratio: 0.291543\n",
      "Epoch 728\n",
      "   training loss 6.999112520134076e-05, (6.950557e-05, 0.013369438, 0.0035659694, 0.012896149)\n",
      "   validation loss 0.0001726316986605525, (0.00017204898, 0.016119584, 0.004537637, 0.012896149)\n",
      "decoder loss ratio: 0.000359, decoder SINDy loss  ratio: 0.289985\n",
      "Epoch 729\n",
      "   training loss 0.00012841688294429332, (0.00012792028, 0.012801201, 0.00367794, 0.0128798345)\n",
      "   validation loss 0.000256229133810848, (0.000255636, 0.015792895, 0.0046433765, 0.0128798345)\n",
      "decoder loss ratio: 0.000533, decoder SINDy loss  ratio: 0.296742\n",
      "Epoch 730\n",
      "   training loss 8.043699926929548e-05, (7.9950725e-05, 0.012946022, 0.0035726833, 0.012900431)\n",
      "   validation loss 0.0002291466371389106, (0.00022856466, 0.015894148, 0.004529695, 0.012900431)\n",
      "decoder loss ratio: 0.000477, decoder SINDy loss  ratio: 0.289477\n",
      "Epoch 731\n",
      "   training loss 0.00010222885612165555, (0.00010173892, 0.012794956, 0.0036115926, 0.01287803)\n",
      "   validation loss 0.00017955205112230033, (0.00017896698, 0.015481218, 0.004562906, 0.01287803)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.291599\n",
      "Epoch 732\n",
      "   training loss 6.052581738913432e-05, (6.004664e-05, 0.012991183, 0.0035025158, 0.012892607)\n",
      "   validation loss 0.00022416948922909796, (0.00022359079, 0.015759235, 0.004497671, 0.012892607)\n",
      "decoder loss ratio: 0.000466, decoder SINDy loss  ratio: 0.287430\n",
      "Epoch 733\n",
      "   training loss 0.00014822141383774579, (0.00014772365, 0.013127885, 0.0036889275, 0.012886929)\n",
      "   validation loss 0.00023223536845762283, (0.00023163605, 0.016313672, 0.004704481, 0.012886929)\n",
      "decoder loss ratio: 0.000483, decoder SINDy loss  ratio: 0.300647\n",
      "Epoch 734\n",
      "   training loss 7.498081686208025e-05, (7.449047e-05, 0.013383963, 0.0036147977, 0.012887301)\n",
      "   validation loss 0.00018184137297794223, (0.00018125406, 0.016140347, 0.0045844247, 0.012887301)\n",
      "decoder loss ratio: 0.000378, decoder SINDy loss  ratio: 0.292975\n",
      "Epoch 735\n",
      "   training loss 5.7487970479996875e-05, (5.699951e-05, 0.0133395, 0.003597472, 0.012871345)\n",
      "   validation loss 0.0001842885831138119, (0.00018370323, 0.01598816, 0.004566441, 0.012871345)\n",
      "decoder loss ratio: 0.000383, decoder SINDy loss  ratio: 0.291825\n",
      "Epoch 736\n",
      "   training loss 6.098107041907497e-05, (6.049461e-05, 0.013165548, 0.003576396, 0.01288208)\n",
      "   validation loss 0.00020031697931699455, (0.0001997378, 0.015852844, 0.004503657, 0.01288208)\n",
      "decoder loss ratio: 0.000417, decoder SINDy loss  ratio: 0.287813\n",
      "Epoch 737\n",
      "   training loss 0.00011348308908054605, (0.00011299318, 0.0133268, 0.0036100452, 0.012890713)\n",
      "   validation loss 0.0003100854519288987, (0.0003094979, 0.015839977, 0.0045864237, 0.012890713)\n",
      "decoder loss ratio: 0.000646, decoder SINDy loss  ratio: 0.293102\n",
      "Epoch 738\n",
      "   training loss 0.0001050438077072613, (0.00010455536, 0.013151246, 0.0035943221, 0.012902029)\n",
      "   validation loss 0.00024112396931741387, (0.00024052967, 0.016857138, 0.004652844, 0.012902029)\n",
      "decoder loss ratio: 0.000502, decoder SINDy loss  ratio: 0.297347\n",
      "Epoch 739\n",
      "   training loss 0.00016638882516417652, (0.00016589984, 0.012966891, 0.0036006074, 0.012893721)\n",
      "   validation loss 0.00033284854725934565, (0.00033226085, 0.015820622, 0.0045875, 0.012893721)\n",
      "decoder loss ratio: 0.000693, decoder SINDy loss  ratio: 0.293171\n",
      "Epoch 740\n",
      "   training loss 4.8986985348165035e-05, (4.8504287e-05, 0.013090901, 0.0035404027, 0.012865887)\n",
      "   validation loss 0.0001616671943338588, (0.00016108718, 0.015939789, 0.0045135487, 0.012865887)\n",
      "decoder loss ratio: 0.000336, decoder SINDy loss  ratio: 0.288445\n",
      "Epoch 741\n",
      "   training loss 6.372370989993215e-05, (6.3237334e-05, 0.012934116, 0.0035772657, 0.0128648905)\n",
      "   validation loss 0.0001527531712781638, (0.00015217194, 0.015825339, 0.0045258156, 0.0128648905)\n",
      "decoder loss ratio: 0.000317, decoder SINDy loss  ratio: 0.289229\n",
      "Epoch 742\n",
      "   training loss 0.0001582944387337193, (0.00015780408, 0.012980121, 0.0036142613, 0.012892554)\n",
      "   validation loss 0.000431311025749892, (0.0004307221, 0.015726, 0.0045997193, 0.012892554)\n",
      "decoder loss ratio: 0.000899, decoder SINDy loss  ratio: 0.293952\n",
      "Epoch 743\n",
      "   training loss 0.00013567304995376617, (0.00013519119, 0.013424207, 0.0035297675, 0.012888519)\n",
      "   validation loss 0.000257909472566098, (0.00025732827, 0.01650396, 0.00452326, 0.012888519)\n",
      "decoder loss ratio: 0.000537, decoder SINDy loss  ratio: 0.289066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 744\n",
      "   training loss 0.000165665551321581, (0.00016517448, 0.013393571, 0.003620525, 0.0129021285)\n",
      "   validation loss 0.0003035951522178948, (0.00030300493, 0.016106868, 0.0046120835, 0.0129021285)\n",
      "decoder loss ratio: 0.000632, decoder SINDy loss  ratio: 0.294742\n",
      "Epoch 745\n",
      "   training loss 7.863126666052267e-05, (7.814726e-05, 0.013318658, 0.0035506336, 0.0128940465)\n",
      "   validation loss 0.00021315488265827298, (0.00021257586, 0.01626775, 0.0045008343, 0.0128940465)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.287633\n",
      "Epoch 746\n",
      "   training loss 8.888784941518679e-05, (8.839846e-05, 0.013149702, 0.0036042538, 0.012896879)\n",
      "   validation loss 0.0001713824603939429, (0.00017079701, 0.015853098, 0.0045648525, 0.012896879)\n",
      "decoder loss ratio: 0.000356, decoder SINDy loss  ratio: 0.291724\n",
      "Epoch 747\n",
      "   training loss 5.781674190075137e-05, (5.7337762e-05, 0.0131963985, 0.0035002232, 0.012895825)\n",
      "   validation loss 0.0003142104542348534, (0.00031363245, 0.016034238, 0.004490303, 0.012895825)\n",
      "decoder loss ratio: 0.000654, decoder SINDy loss  ratio: 0.286960\n",
      "Epoch 748\n",
      "   training loss 6.505348574137315e-05, (6.456518e-05, 0.013102323, 0.0035922318, 0.012908423)\n",
      "   validation loss 0.00016765232430770993, (0.00016706709, 0.016064942, 0.0045614, 0.012908423)\n",
      "decoder loss ratio: 0.000349, decoder SINDy loss  ratio: 0.291503\n",
      "Epoch 749\n",
      "   training loss 0.00015670500579290092, (0.00015621458, 0.013302844, 0.003616, 0.01288245)\n",
      "   validation loss 0.0002899429528042674, (0.00028935753, 0.01612297, 0.0045661153, 0.01288245)\n",
      "decoder loss ratio: 0.000604, decoder SINDy loss  ratio: 0.291804\n",
      "Epoch 750\n",
      "   training loss 6.54754985589534e-05, (6.498971e-05, 0.01393535, 0.0035658875, 0.012919939)\n",
      "   validation loss 0.00017932947957888246, (0.00017874752, 0.016666917, 0.0045275413, 0.012919939)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.289339\n",
      "Epoch 751\n",
      "   training loss 0.00013712546206079423, (0.00013663134, 0.013127036, 0.003652599, 0.012886889)\n",
      "   validation loss 0.00023506043362431228, (0.00023447008, 0.016082011, 0.0046148873, 0.012886889)\n",
      "decoder loss ratio: 0.000489, decoder SINDy loss  ratio: 0.294921\n",
      "Epoch 752\n",
      "   training loss 0.0001380783214699477, (0.0001375954, 0.013037361, 0.0035397313, 0.012893872)\n",
      "   validation loss 0.0003076294087804854, (0.00030705013, 0.016167324, 0.004503625, 0.012893872)\n",
      "decoder loss ratio: 0.000641, decoder SINDy loss  ratio: 0.287811\n",
      "Epoch 753\n",
      "   training loss 0.00012039571447530761, (0.00011990742, 0.0129452795, 0.003592926, 0.012900016)\n",
      "   validation loss 0.0002122346340911463, (0.00021165209, 0.015771331, 0.00453537, 0.012900016)\n",
      "decoder loss ratio: 0.000442, decoder SINDy loss  ratio: 0.289840\n",
      "Epoch 754\n",
      "   training loss 7.374634151346982e-05, (7.326758e-05, 0.012935166, 0.0034936634, 0.01293873)\n",
      "   validation loss 0.00035495066549628973, (0.00035437266, 0.01590397, 0.0044861413, 0.01293873)\n",
      "decoder loss ratio: 0.000739, decoder SINDy loss  ratio: 0.286694\n",
      "Epoch 755\n",
      "   training loss 0.0001002350909402594, (9.975239e-05, 0.012864165, 0.0035358528, 0.012911904)\n",
      "   validation loss 0.0002012386394198984, (0.00020066032, 0.01596278, 0.0044920533, 0.012911904)\n",
      "decoder loss ratio: 0.000419, decoder SINDy loss  ratio: 0.287071\n",
      "Epoch 756\n",
      "   training loss 0.00017301266780123115, (0.00017252284, 0.012994454, 0.0036078282, 0.012904642)\n",
      "   validation loss 0.0002791760489344597, (0.00027859295, 0.016008645, 0.0045403834, 0.012904642)\n",
      "decoder loss ratio: 0.000581, decoder SINDy loss  ratio: 0.290160\n",
      "Epoch 757\n",
      "   training loss 7.613618072355166e-05, (7.5653654e-05, 0.01360552, 0.0035337303, 0.012915724)\n",
      "   validation loss 0.0002165682817576453, (0.0002159901, 0.016394565, 0.0044901664, 0.012915724)\n",
      "decoder loss ratio: 0.000451, decoder SINDy loss  ratio: 0.286951\n",
      "Epoch 758\n",
      "   training loss 7.360635936493054e-05, (7.3116054e-05, 0.013136354, 0.003612196, 0.012908449)\n",
      "   validation loss 0.00018521460879128426, (0.00018462866, 0.016043263, 0.0045685894, 0.012908449)\n",
      "decoder loss ratio: 0.000385, decoder SINDy loss  ratio: 0.291963\n",
      "Epoch 759\n",
      "   training loss 0.00016994813631754369, (0.00016946811, 0.012820003, 0.0035110197, 0.012890961)\n",
      "   validation loss 0.0003128148673567921, (0.00031223876, 0.016063385, 0.004471976, 0.012890961)\n",
      "decoder loss ratio: 0.000651, decoder SINDy loss  ratio: 0.285788\n",
      "Epoch 760\n",
      "   training loss 0.000203769639483653, (0.00020328077, 0.012898826, 0.003597296, 0.012915454)\n",
      "   validation loss 0.0002990508801303804, (0.00029846843, 0.015884114, 0.00453296, 0.012915454)\n",
      "decoder loss ratio: 0.000623, decoder SINDy loss  ratio: 0.289686\n",
      "Epoch 761\n",
      "   training loss 4.5695378503296524e-05, (4.5219487e-05, 0.013160259, 0.0034668571, 0.0129206395)\n",
      "   validation loss 0.00020438735373318195, (0.0002038135, 0.01606068, 0.0044464283, 0.0129206395)\n",
      "decoder loss ratio: 0.000425, decoder SINDy loss  ratio: 0.284156\n",
      "Epoch 762\n",
      "   training loss 0.00012362233246676624, (0.00012312928, 0.013197914, 0.0036384389, 0.012921293)\n",
      "   validation loss 0.00022439152235165238, (0.0002237999, 0.016199678, 0.004624213, 0.012921293)\n",
      "decoder loss ratio: 0.000467, decoder SINDy loss  ratio: 0.295517\n",
      "Epoch 763\n",
      "   training loss 7.799001468811184e-05, (7.750566e-05, 0.013225186, 0.003551731, 0.012917508)\n",
      "   validation loss 0.00018408428877592087, (0.00018350515, 0.01616098, 0.004499602, 0.012917508)\n",
      "decoder loss ratio: 0.000383, decoder SINDy loss  ratio: 0.287554\n",
      "Epoch 764\n",
      "   training loss 0.00015203192015178502, (0.00015154487, 0.013489585, 0.0035777115, 0.01292756)\n",
      "   validation loss 0.00032044228282757103, (0.0003198592, 0.016172776, 0.0045380965, 0.01292756)\n",
      "decoder loss ratio: 0.000667, decoder SINDy loss  ratio: 0.290014\n",
      "Epoch 765\n",
      "   training loss 7.680393173359334e-05, (7.632279e-05, 0.013801378, 0.0035199805, 0.012914876)\n",
      "   validation loss 0.00017143916920758784, (0.00017086147, 0.01654812, 0.004485552, 0.012914876)\n",
      "decoder loss ratio: 0.000356, decoder SINDy loss  ratio: 0.286656\n",
      "Epoch 766\n",
      "   training loss 0.00012973482080269605, (0.00012924228, 0.013430218, 0.003632826, 0.01292435)\n",
      "   validation loss 0.00019772525411099195, (0.00019713593, 0.016198138, 0.0046007102, 0.01292435)\n",
      "decoder loss ratio: 0.000411, decoder SINDy loss  ratio: 0.294015\n",
      "Epoch 767\n",
      "   training loss 4.6608522097812966e-05, (4.612639e-05, 0.01356206, 0.0035314471, 0.012898469)\n",
      "   validation loss 0.00016056629829108715, (0.00015998827, 0.01651216, 0.004490466, 0.012898469)\n",
      "decoder loss ratio: 0.000334, decoder SINDy loss  ratio: 0.286970\n",
      "Epoch 768\n",
      "   training loss 9.533293632557616e-05, (9.484269e-05, 0.013149596, 0.0036117998, 0.012907114)\n",
      "   validation loss 0.0001947506971191615, (0.0001941673, 0.015788699, 0.0045433, 0.012907114)\n",
      "decoder loss ratio: 0.000405, decoder SINDy loss  ratio: 0.290346\n",
      "Epoch 769\n",
      "   training loss 0.0001636040979065001, (0.00016312287, 0.0130826635, 0.003519572, 0.012927647)\n",
      "   validation loss 0.0005566424806602299, (0.00055606, 0.01615128, 0.004532029, 0.012927647)\n",
      "decoder loss ratio: 0.001160, decoder SINDy loss  ratio: 0.289626\n",
      "Epoch 770\n",
      "   training loss 0.00013506684626918286, (0.00013458221, 0.01317474, 0.0035528112, 0.0129351355)\n",
      "   validation loss 0.00024070919607765973, (0.00024012894, 0.016163148, 0.004509041, 0.0129351355)\n",
      "decoder loss ratio: 0.000501, decoder SINDy loss  ratio: 0.288157\n",
      "Epoch 771\n",
      "   training loss 7.359111623372883e-05, (7.310716e-05, 0.013365219, 0.0035501872, 0.012894039)\n",
      "   validation loss 0.000171381383552216, (0.0001708042, 0.01626907, 0.0044823936, 0.012894039)\n",
      "decoder loss ratio: 0.000356, decoder SINDy loss  ratio: 0.286454\n",
      "Epoch 772\n",
      "   training loss 6.766159640392289e-05, (6.7176785e-05, 0.0135347, 0.0035562152, 0.012918862)\n",
      "   validation loss 0.00016279642295558006, (0.00016221961, 0.016462078, 0.004476194, 0.012918862)\n",
      "decoder loss ratio: 0.000338, decoder SINDy loss  ratio: 0.286058\n",
      "Epoch 773\n",
      "   training loss 0.0001459892519051209, (0.00014550521, 0.012921244, 0.003550962, 0.012894177)\n",
      "   validation loss 0.00026569722103886306, (0.00026511867, 0.016233874, 0.004496371, 0.012894177)\n",
      "decoder loss ratio: 0.000553, decoder SINDy loss  ratio: 0.287347\n",
      "Epoch 774\n",
      "   training loss 0.00032818614272400737, (0.00032768826, 0.013934893, 0.0036835023, 0.012955043)\n",
      "   validation loss 0.0005979963461868465, (0.00059740274, 0.016702559, 0.0046404735, 0.012955043)\n",
      "decoder loss ratio: 0.001246, decoder SINDy loss  ratio: 0.296556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775\n",
      "   training loss 7.357038703048602e-05, (7.307763e-05, 0.014085677, 0.0036306377, 0.012969479)\n",
      "   validation loss 0.0001939526409842074, (0.0001933606, 0.017192079, 0.0046234713, 0.012969479)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.295470\n",
      "Epoch 776\n",
      "   training loss 2.8800874133594334e-05, (2.8311735e-05, 0.0141060045, 0.0035967112, 0.012946904)\n",
      "   validation loss 0.0001423783105565235, (0.0001417935, 0.016876008, 0.0045534293, 0.012946904)\n",
      "decoder loss ratio: 0.000296, decoder SINDy loss  ratio: 0.290994\n",
      "Epoch 777\n",
      "   training loss 3.051112980756443e-05, (3.0021725e-05, 0.0142439855, 0.0036013182, 0.012927167)\n",
      "   validation loss 0.00010815179848577827, (0.00010756744, 0.016861206, 0.004550916, 0.012927167)\n",
      "decoder loss ratio: 0.000224, decoder SINDy loss  ratio: 0.290833\n",
      "Epoch 778\n",
      "   training loss 2.4240842321887612e-05, (2.3753502e-05, 0.013797525, 0.0035808305, 0.012925723)\n",
      "   validation loss 0.0001270995708182454, (0.00012651685, 0.01653437, 0.00453466, 0.012925723)\n",
      "decoder loss ratio: 0.000264, decoder SINDy loss  ratio: 0.289794\n",
      "Epoch 779\n",
      "   training loss 3.313118213554844e-05, (3.26473e-05, 0.013523494, 0.003547734, 0.012911066)\n",
      "   validation loss 0.0001621443370822817, (0.000161562, 0.01637259, 0.004532353, 0.012911066)\n",
      "decoder loss ratio: 0.000337, decoder SINDy loss  ratio: 0.289647\n",
      "Epoch 780\n",
      "   training loss 7.432464190060273e-05, (7.3833144e-05, 0.013792182, 0.0036227223, 0.012922484)\n",
      "   validation loss 0.00029806222300976515, (0.0002974727, 0.016959067, 0.0046029966, 0.012922484)\n",
      "decoder loss ratio: 0.000621, decoder SINDy loss  ratio: 0.294161\n",
      "Epoch 781\n",
      "   training loss 0.00014208414359018207, (0.00014159418, 0.013902523, 0.0036058307, 0.012938716)\n",
      "   validation loss 0.00022824273037258536, (0.00022765783, 0.016842825, 0.004555188, 0.012938716)\n",
      "decoder loss ratio: 0.000475, decoder SINDy loss  ratio: 0.291106\n",
      "Epoch 782\n",
      "   training loss 3.9179361920105293e-05, (3.8695645e-05, 0.013778623, 0.0035435576, 0.012935867)\n",
      "   validation loss 0.00014119231491349638, (0.0001406124, 0.016722187, 0.0045055733, 0.012935867)\n",
      "decoder loss ratio: 0.000293, decoder SINDy loss  ratio: 0.287935\n",
      "Epoch 783\n",
      "   training loss 4.9158385081682354e-05, (4.8672697e-05, 0.013599527, 0.0035658074, 0.012910829)\n",
      "   validation loss 0.00012575082655530423, (0.00012516945, 0.016395738, 0.0045227082, 0.012910829)\n",
      "decoder loss ratio: 0.000261, decoder SINDy loss  ratio: 0.289030\n",
      "Epoch 784\n",
      "   training loss 5.642046744469553e-05, (5.59424e-05, 0.013778816, 0.0034893262, 0.012913423)\n",
      "   validation loss 0.00015715454355813563, (0.00015657906, 0.016762767, 0.0044635246, 0.012913423)\n",
      "decoder loss ratio: 0.000327, decoder SINDy loss  ratio: 0.285248\n",
      "Epoch 785\n",
      "   training loss 0.00024283253878820688, (0.00024233574, 0.013376893, 0.003678221, 0.012897189)\n",
      "   validation loss 0.0002655282150954008, (0.0002649373, 0.01638303, 0.004619671, 0.012897189)\n",
      "decoder loss ratio: 0.000553, decoder SINDy loss  ratio: 0.295227\n",
      "Epoch 786\n",
      "   training loss 9.88388856058009e-05, (9.835488e-05, 0.013459212, 0.0035466799, 0.012933972)\n",
      "   validation loss 0.0002384413528488949, (0.00023786233, 0.016664395, 0.004496853, 0.012933972)\n",
      "decoder loss ratio: 0.000496, decoder SINDy loss  ratio: 0.287378\n",
      "Epoch 787\n",
      "   training loss 0.0001313134707743302, (0.0001308267, 0.013683297, 0.0035759197, 0.012917907)\n",
      "   validation loss 0.0002814994368236512, (0.00028091634, 0.016445857, 0.0045390246, 0.012917907)\n",
      "decoder loss ratio: 0.000586, decoder SINDy loss  ratio: 0.290073\n",
      "Epoch 788\n",
      "   training loss 9.723064431454986e-05, (9.675007e-05, 0.014078601, 0.0035141867, 0.012915673)\n",
      "   validation loss 0.00023127264284994453, (0.00023069409, 0.016898993, 0.004493905, 0.012915673)\n",
      "decoder loss ratio: 0.000481, decoder SINDy loss  ratio: 0.287190\n",
      "Epoch 789\n",
      "   training loss 0.00014553630899172276, (0.00014504432, 0.013836466, 0.0036279317, 0.0129192965)\n",
      "   validation loss 0.0002497457026038319, (0.00024915586, 0.016664065, 0.004606607, 0.0129192965)\n",
      "decoder loss ratio: 0.000520, decoder SINDy loss  ratio: 0.294392\n",
      "Epoch 790\n",
      "   training loss 4.468951010494493e-05, (4.420586e-05, 0.013995424, 0.0035431501, 0.012933827)\n",
      "   validation loss 0.00015576148871332407, (0.00015518312, 0.01693098, 0.00449034, 0.012933827)\n",
      "decoder loss ratio: 0.000324, decoder SINDy loss  ratio: 0.286962\n",
      "Epoch 791\n",
      "   training loss 0.00014479897799901664, (0.00014430688, 0.013946866, 0.003629038, 0.012919123)\n",
      "   validation loss 0.00021020964777562767, (0.00020962395, 0.016496772, 0.00456509, 0.012919123)\n",
      "decoder loss ratio: 0.000437, decoder SINDy loss  ratio: 0.291739\n",
      "Epoch 792\n",
      "   training loss 8.750693086767569e-05, (8.702815e-05, 0.014061987, 0.0034945903, 0.012931941)\n",
      "   validation loss 0.00024566848878748715, (0.00024508862, 0.017258264, 0.0045055705, 0.012931941)\n",
      "decoder loss ratio: 0.000511, decoder SINDy loss  ratio: 0.287935\n",
      "Epoch 793\n",
      "   training loss 8.82373788044788e-05, (8.7747656e-05, 0.014101674, 0.0036025927, 0.012946195)\n",
      "   validation loss 0.00019872542179655284, (0.00019813843, 0.016840842, 0.004575231, 0.012946195)\n",
      "decoder loss ratio: 0.000413, decoder SINDy loss  ratio: 0.292387\n",
      "Epoch 794\n",
      "   training loss 8.500967669533566e-05, (8.452375e-05, 0.01421284, 0.0035676537, 0.012916516)\n",
      "   validation loss 0.00020457948266994208, (0.00020400067, 0.017129015, 0.004496478, 0.012916516)\n",
      "decoder loss ratio: 0.000426, decoder SINDy loss  ratio: 0.287354\n",
      "Epoch 795\n",
      "   training loss 0.00010718663543229923, (0.00010669895, 0.013939403, 0.003584714, 0.012921293)\n",
      "   validation loss 0.00022887412342242897, (0.00022828991, 0.016736904, 0.0045500905, 0.012921293)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.290780\n",
      "Epoch 796\n",
      "   training loss 5.7351375289727e-05, (5.6871042e-05, 0.014150773, 0.0035117297, 0.0129160695)\n",
      "   validation loss 0.00017519955872558057, (0.0001746235, 0.017006408, 0.00446891, 0.0129160695)\n",
      "decoder loss ratio: 0.000364, decoder SINDy loss  ratio: 0.285592\n",
      "Epoch 797\n",
      "   training loss 0.00010141760867554694, (0.00010092492, 0.01390132, 0.0036361185, 0.012908581)\n",
      "   validation loss 0.00017091773042920977, (0.00017032992, 0.016585588, 0.0045872396, 0.012908581)\n",
      "decoder loss ratio: 0.000355, decoder SINDy loss  ratio: 0.293154\n",
      "Epoch 798\n",
      "   training loss 4.874872320215218e-05, (4.8266917e-05, 0.013960074, 0.0035248145, 0.012932663)\n",
      "   validation loss 0.00021720446238759905, (0.00021662525, 0.01686988, 0.0044988706, 0.012932663)\n",
      "decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.287507\n",
      "Epoch 799\n",
      "   training loss 7.946733239805326e-05, (7.8976984e-05, 0.014204805, 0.0036097416, 0.012937398)\n",
      "   validation loss 0.00016264882287941873, (0.00016206516, 0.016743774, 0.004542815, 0.012937398)\n",
      "decoder loss ratio: 0.000338, decoder SINDy loss  ratio: 0.290315\n",
      "Epoch 800\n",
      "   training loss 7.915584137663245e-05, (7.8675934e-05, 0.014267232, 0.0035053748, 0.012936948)\n",
      "   validation loss 0.000211006699828431, (0.00021042586, 0.017380185, 0.0045148, 0.012936948)\n",
      "decoder loss ratio: 0.000439, decoder SINDy loss  ratio: 0.288525\n",
      "Epoch 801\n",
      "   training loss 0.0001317555143032223, (0.0001312602, 0.014257543, 0.0036595245, 0.012936465)\n",
      "   validation loss 0.00021715117327403277, (0.00021655955, 0.017078593, 0.0046225702, 0.012936465)\n",
      "decoder loss ratio: 0.000452, decoder SINDy loss  ratio: 0.295412\n",
      "Epoch 802\n",
      "   training loss 9.496557322563604e-05, (9.447872e-05, 0.014335766, 0.0035744566, 0.012940726)\n",
      "   validation loss 0.00022604445985052735, (0.0002254636, 0.017408378, 0.004514432, 0.012940726)\n",
      "decoder loss ratio: 0.000470, decoder SINDy loss  ratio: 0.288502\n",
      "Epoch 803\n",
      "   training loss 0.00011808409180957824, (0.00011759742, 0.014103447, 0.0035748193, 0.012919345)\n",
      "   validation loss 0.00026473813340999186, (0.00026415492, 0.016933594, 0.0045400793, 0.012919345)\n",
      "decoder loss ratio: 0.000551, decoder SINDy loss  ratio: 0.290141\n",
      "Epoch 804\n",
      "   training loss 3.435809048824012e-05, (3.3875327e-05, 0.014417064, 0.003534833, 0.012927809)\n",
      "   validation loss 0.00013370388478506356, (0.00013312722, 0.017137932, 0.0044737905, 0.012927809)\n",
      "decoder loss ratio: 0.000278, decoder SINDy loss  ratio: 0.285904\n",
      "Epoch 805\n",
      "   training loss 4.349501250544563e-05, (4.3006556e-05, 0.013980567, 0.0035942714, 0.012902827)\n",
      "   validation loss 0.00017558035324327648, (0.00017499845, 0.016580192, 0.004528711, 0.012902827)\n",
      "decoder loss ratio: 0.000365, decoder SINDy loss  ratio: 0.289414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 806\n",
      "   training loss 0.00011723110947059467, (0.00011674886, 0.013671284, 0.0035275365, 0.01294941)\n",
      "   validation loss 0.00047028952394612134, (0.00046970742, 0.016754046, 0.0045262147, 0.01294941)\n",
      "decoder loss ratio: 0.000980, decoder SINDy loss  ratio: 0.289255\n",
      "Epoch 807\n",
      "   training loss 7.155994535423815e-05, (7.108008e-05, 0.013772742, 0.0035033007, 0.0129530765)\n",
      "   validation loss 0.0001814310671761632, (0.00018085435, 0.016797341, 0.004471973, 0.0129530765)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.285788\n",
      "Epoch 808\n",
      "   training loss 0.00017257842409890145, (0.00017208965, 0.013833706, 0.0035931491, 0.012944915)\n",
      "   validation loss 0.000299064937280491, (0.00029848336, 0.01683817, 0.0045213234, 0.012944915)\n",
      "decoder loss ratio: 0.000623, decoder SINDy loss  ratio: 0.288942\n",
      "Epoch 809\n",
      "   training loss 0.0001081355512724258, (0.0001076546, 0.014763667, 0.0035147197, 0.01294792)\n",
      "   validation loss 0.0002957989927381277, (0.00029522256, 0.017604668, 0.0044694417, 0.01294792)\n",
      "decoder loss ratio: 0.000616, decoder SINDy loss  ratio: 0.285626\n",
      "Epoch 810\n",
      "   training loss 0.00014733885473106056, (0.00014684738, 0.014095261, 0.003619486, 0.012952585)\n",
      "   validation loss 0.00026102818083018064, (0.0002604415, 0.01701983, 0.004571764, 0.012952585)\n",
      "decoder loss ratio: 0.000543, decoder SINDy loss  ratio: 0.292165\n",
      "Epoch 811\n",
      "   training loss 0.0001358198351226747, (0.00013533703, 0.014188599, 0.0035340781, 0.012939806)\n",
      "   validation loss 0.0002631519455462694, (0.0002625775, 0.017094962, 0.004450449, 0.012939806)\n",
      "decoder loss ratio: 0.000548, decoder SINDy loss  ratio: 0.284413\n",
      "Epoch 812\n",
      "   training loss 0.0001836629380704835, (0.00018317546, 0.014014318, 0.0035811535, 0.012937246)\n",
      "   validation loss 0.0003322323609609157, (0.00033165002, 0.016921729, 0.004529706, 0.012937246)\n",
      "decoder loss ratio: 0.000692, decoder SINDy loss  ratio: 0.289478\n",
      "Epoch 813\n",
      "   training loss 6.946521898498759e-05, (6.898612e-05, 0.014678185, 0.003496538, 0.012944868)\n",
      "   validation loss 0.00021591392578557134, (0.00021533997, 0.0173767, 0.004445011, 0.012944868)\n",
      "decoder loss ratio: 0.000449, decoder SINDy loss  ratio: 0.284065\n",
      "Epoch 814\n",
      "   training loss 0.0001413314021192491, (0.00014084013, 0.014272631, 0.003618, 0.012947183)\n",
      "   validation loss 0.00021633824508171529, (0.00021575206, 0.01697116, 0.004567084, 0.012947183)\n",
      "decoder loss ratio: 0.000450, decoder SINDy loss  ratio: 0.291866\n",
      "Epoch 815\n",
      "   training loss 4.940020517096855e-05, (4.892028e-05, 0.014680709, 0.0035046437, 0.012945947)\n",
      "   validation loss 0.00017265178030356765, (0.00017207702, 0.017432796, 0.0044530733, 0.012945947)\n",
      "decoder loss ratio: 0.000359, decoder SINDy loss  ratio: 0.284580\n",
      "Epoch 816\n",
      "   training loss 0.0001473808370064944, (0.00014688568, 0.014133881, 0.0036576292, 0.012939623)\n",
      "   validation loss 0.00022584342514164746, (0.00022525668, 0.0168112, 0.0045735855, 0.012939623)\n",
      "decoder loss ratio: 0.000470, decoder SINDy loss  ratio: 0.292282\n",
      "Epoch 817\n",
      "   training loss 7.337972783716395e-05, (7.28991e-05, 0.014097146, 0.00350928, 0.01297042)\n",
      "   validation loss 0.0003158800827804953, (0.00031530295, 0.017027315, 0.0044741994, 0.01297042)\n",
      "decoder loss ratio: 0.000658, decoder SINDy loss  ratio: 0.285930\n",
      "Epoch 818\n",
      "   training loss 4.529927173280157e-05, (4.4815817e-05, 0.014114487, 0.0035385094, 0.012960457)\n",
      "   validation loss 0.00016180408420041203, (0.00016122639, 0.016887669, 0.0044809505, 0.012960457)\n",
      "decoder loss ratio: 0.000336, decoder SINDy loss  ratio: 0.286362\n",
      "Epoch 819\n",
      "   training loss 8.238766167778522e-05, (8.190588e-05, 0.014715388, 0.003524621, 0.012931948)\n",
      "   validation loss 0.00014250630920287222, (0.00014193315, 0.017284673, 0.0044383085, 0.012931948)\n",
      "decoder loss ratio: 0.000296, decoder SINDy loss  ratio: 0.283637\n",
      "Epoch 820\n",
      "   training loss 0.0002029544994002208, (0.00020246356, 0.014501032, 0.0036152245, 0.012940364)\n",
      "   validation loss 0.00045763180241920054, (0.00045704894, 0.017483866, 0.0045347554, 0.012940364)\n",
      "decoder loss ratio: 0.000953, decoder SINDy loss  ratio: 0.289800\n",
      "Epoch 821\n",
      "   training loss 0.00011976194946328178, (0.00011927007, 0.014452626, 0.003623922, 0.012948468)\n",
      "   validation loss 0.00019190902821719646, (0.00019132282, 0.017467927, 0.0045672953, 0.012948468)\n",
      "decoder loss ratio: 0.000399, decoder SINDy loss  ratio: 0.291880\n",
      "Epoch 822\n",
      "   training loss 4.7258392442017794e-05, (4.6771915e-05, 0.014240296, 0.0035694323, 0.012953539)\n",
      "   validation loss 0.0001570334570715204, (0.00015645084, 0.01712029, 0.004530749, 0.012953539)\n",
      "decoder loss ratio: 0.000326, decoder SINDy loss  ratio: 0.289544\n",
      "Epoch 823\n",
      "   training loss 5.6955610489239916e-05, (5.6471672e-05, 0.014318087, 0.0035457145, 0.012936499)\n",
      "   validation loss 0.00016369478544220328, (0.00016311543, 0.017107721, 0.0044998843, 0.012936499)\n",
      "decoder loss ratio: 0.000340, decoder SINDy loss  ratio: 0.287572\n",
      "Epoch 824\n",
      "   training loss 3.8212700019357726e-05, (3.7729595e-05, 0.01413905, 0.0035368425, 0.01294223)\n",
      "   validation loss 0.00014147641195449978, (0.00014089693, 0.01699074, 0.00450062, 0.01294223)\n",
      "decoder loss ratio: 0.000294, decoder SINDy loss  ratio: 0.287619\n",
      "Epoch 825\n",
      "   training loss 9.9852608400397e-05, (9.937024e-05, 0.014216698, 0.003531442, 0.01292242)\n",
      "   validation loss 0.0002636455756146461, (0.00026306877, 0.017209997, 0.0044759344, 0.01292242)\n",
      "decoder loss ratio: 0.000549, decoder SINDy loss  ratio: 0.286041\n",
      "Epoch 826\n",
      "   training loss 0.0003092355909757316, (0.00030874624, 0.014184102, 0.0035970486, 0.01296523)\n",
      "   validation loss 0.0004516144108492881, (0.00045102937, 0.017262135, 0.004553826, 0.01296523)\n",
      "decoder loss ratio: 0.000941, decoder SINDy loss  ratio: 0.291019\n",
      "Epoch 827\n",
      "   training loss 7.646608719369397e-05, (7.5983815e-05, 0.015094977, 0.003525885, 0.012968645)\n",
      "   validation loss 0.0002351708390051499, (0.00023459326, 0.017796876, 0.0044788653, 0.012968645)\n",
      "decoder loss ratio: 0.000489, decoder SINDy loss  ratio: 0.286229\n",
      "Epoch 828\n",
      "   training loss 0.00011189493670826778, (0.000111408044, 0.0145809995, 0.0035729273, 0.012960102)\n",
      "   validation loss 0.000249797070864588, (0.00024921438, 0.017289944, 0.0045309467, 0.012960102)\n",
      "decoder loss ratio: 0.000520, decoder SINDy loss  ratio: 0.289557\n",
      "Epoch 829\n",
      "   training loss 8.521568815922365e-05, (8.473221e-05, 0.014811977, 0.0035402835, 0.012945152)\n",
      "   validation loss 0.00019434146815910935, (0.00019376622, 0.017489046, 0.0044579348, 0.012945152)\n",
      "decoder loss ratio: 0.000404, decoder SINDy loss  ratio: 0.284891\n",
      "Epoch 830\n",
      "   training loss 0.00013889142428524792, (0.00013840073, 0.014109775, 0.0036141505, 0.012927757)\n",
      "   validation loss 0.00019203191914130002, (0.00019144811, 0.01692712, 0.004545345, 0.012927757)\n",
      "decoder loss ratio: 0.000399, decoder SINDy loss  ratio: 0.290477\n",
      "Epoch 831\n",
      "   training loss 0.00010514581663301215, (0.00010466644, 0.014130087, 0.0034977472, 0.012959977)\n",
      "   validation loss 0.00038312317337840796, (0.00038254788, 0.017215732, 0.004457011, 0.012959977)\n",
      "decoder loss ratio: 0.000798, decoder SINDy loss  ratio: 0.284832\n",
      "Epoch 832\n",
      "   training loss 8.625452755950391e-05, (8.577173e-05, 0.014094035, 0.0035333203, 0.012946179)\n",
      "   validation loss 0.0002377893979428336, (0.00023721183, 0.016961057, 0.004481023, 0.012946179)\n",
      "decoder loss ratio: 0.000495, decoder SINDy loss  ratio: 0.286367\n",
      "Epoch 833\n",
      "   training loss 5.188435170566663e-05, (5.140499e-05, 0.014637033, 0.0034996383, 0.01293989)\n",
      "   validation loss 0.0001615903020137921, (0.00016101546, 0.017196005, 0.004454479, 0.01293989)\n",
      "decoder loss ratio: 0.000336, decoder SINDy loss  ratio: 0.284670\n",
      "Epoch 834\n",
      "   training loss 7.121208182070404e-05, (7.07248e-05, 0.014499396, 0.003578371, 0.012944458)\n",
      "   validation loss 0.00020730840333271772, (0.00020672761, 0.01736832, 0.0045135585, 0.012944458)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.288446\n",
      "Epoch 835\n",
      "   training loss 0.00022947385150473565, (0.00022898437, 0.014057607, 0.0035991676, 0.012956777)\n",
      "   validation loss 0.00033418857492506504, (0.000333608, 0.01739669, 0.004509934, 0.012956777)\n",
      "decoder loss ratio: 0.000696, decoder SINDy loss  ratio: 0.288214\n",
      "Epoch 836\n",
      "   training loss 0.00010293872037436813, (0.00010245718, 0.0153140575, 0.003517606, 0.012977064)\n",
      "   validation loss 0.00025557572371326387, (0.00025500005, 0.017938925, 0.004458961, 0.012977064)\n",
      "decoder loss ratio: 0.000532, decoder SINDy loss  ratio: 0.284957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837\n",
      "   training loss 5.437925938167609e-05, (5.389185e-05, 0.014721747, 0.0035765143, 0.012975995)\n",
      "   validation loss 0.00014504291175398976, (0.00014446068, 0.017403008, 0.004524748, 0.012975995)\n",
      "decoder loss ratio: 0.000301, decoder SINDy loss  ratio: 0.289161\n",
      "Epoch 838\n",
      "   training loss 0.00014301961346063763, (0.00014253522, 0.01477464, 0.0035468237, 0.01296957)\n",
      "   validation loss 0.00028593343449756503, (0.0002853592, 0.017548475, 0.0044457293, 0.01296957)\n",
      "decoder loss ratio: 0.000595, decoder SINDy loss  ratio: 0.284111\n",
      "Epoch 839\n",
      "   training loss 0.00013827926886733621, (0.00013779117, 0.014254249, 0.003587239, 0.012938064)\n",
      "   validation loss 0.00020603020675480366, (0.00020545005, 0.017312044, 0.0045078043, 0.012938064)\n",
      "decoder loss ratio: 0.000429, decoder SINDy loss  ratio: 0.288078\n",
      "Epoch 840\n",
      "   training loss 8.600536966696382e-05, (8.55243e-05, 0.014248003, 0.003513224, 0.01297489)\n",
      "   validation loss 0.0002372523449594155, (0.0002366774, 0.017226849, 0.004452053, 0.01297489)\n",
      "decoder loss ratio: 0.000494, decoder SINDy loss  ratio: 0.284515\n",
      "Epoch 841\n",
      "   training loss 4.2471667256904766e-05, (4.199042e-05, 0.014515246, 0.0035173967, 0.012950937)\n",
      "   validation loss 0.00016441848129034042, (0.00016384303, 0.017227989, 0.004459391, 0.012950937)\n",
      "decoder loss ratio: 0.000342, decoder SINDy loss  ratio: 0.284984\n",
      "Epoch 842\n",
      "   training loss 9.793167555471882e-05, (9.744707e-05, 0.014928978, 0.0035499875, 0.012960486)\n",
      "   validation loss 0.0002738421899266541, (0.00027326337, 0.017794974, 0.0044921264, 0.012960486)\n",
      "decoder loss ratio: 0.000570, decoder SINDy loss  ratio: 0.287076\n",
      "Epoch 843\n",
      "   training loss 0.0003378514666110277, (0.00033735984, 0.014231674, 0.0036202515, 0.0129601555)\n",
      "   validation loss 0.0004497221962083131, (0.000449137, 0.01755414, 0.0045559746, 0.0129601555)\n",
      "decoder loss ratio: 0.000937, decoder SINDy loss  ratio: 0.291156\n",
      "Epoch 844\n",
      "   training loss 8.584408351453021e-05, (8.536148e-05, 0.015015983, 0.0035262727, 0.012997661)\n",
      "   validation loss 0.00023657798010390252, (0.00023600107, 0.01784057, 0.0044693407, 0.012997661)\n",
      "decoder loss ratio: 0.000492, decoder SINDy loss  ratio: 0.285620\n",
      "Epoch 845\n",
      "   training loss 9.162717469735071e-05, (9.114426e-05, 0.014580344, 0.0035318388, 0.01297335)\n",
      "   validation loss 0.000263940601143986, (0.00026336097, 0.017449925, 0.004498737, 0.01297335)\n",
      "decoder loss ratio: 0.000549, decoder SINDy loss  ratio: 0.287499\n",
      "Epoch 846\n",
      "   training loss 5.299057738739066e-05, (5.2507905e-05, 0.014684447, 0.0035290972, 0.01297635)\n",
      "   validation loss 0.0001452983997296542, (0.00014472062, 0.017519236, 0.0044801864, 0.01297635)\n",
      "decoder loss ratio: 0.000302, decoder SINDy loss  ratio: 0.286313\n",
      "Epoch 847\n",
      "   training loss 8.719612378627062e-05, (8.671323e-05, 0.014813515, 0.0035326122, 0.012962863)\n",
      "   validation loss 0.0002922101120930165, (0.00029163464, 0.017684687, 0.0044585112, 0.012962863)\n",
      "decoder loss ratio: 0.000608, decoder SINDy loss  ratio: 0.284928\n",
      "Epoch 848\n",
      "   training loss 0.0003784906002692878, (0.0003779984, 0.014247266, 0.003625491, 0.012966964)\n",
      "   validation loss 0.0005112446960993111, (0.00051065907, 0.017543998, 0.004559582, 0.012966964)\n",
      "decoder loss ratio: 0.001065, decoder SINDy loss  ratio: 0.291387\n",
      "Epoch 849\n",
      "   training loss 6.204288365552202e-05, (6.155898e-05, 0.015277974, 0.003541262, 0.012977722)\n",
      "   validation loss 0.00019862766203004867, (0.0001980489, 0.017984364, 0.00448986, 0.012977722)\n",
      "decoder loss ratio: 0.000413, decoder SINDy loss  ratio: 0.286931\n",
      "Epoch 850\n",
      "   training loss 0.00010686623863875866, (0.00010638201, 0.014835856, 0.0035455516, 0.012967553)\n",
      "   validation loss 0.00028057530289515853, (0.00027999512, 0.017554928, 0.004504888, 0.012967553)\n",
      "decoder loss ratio: 0.000584, decoder SINDy loss  ratio: 0.287892\n",
      "Epoch 851\n",
      "   training loss 4.205845471005887e-05, (4.1575913e-05, 0.015190343, 0.003528621, 0.012967853)\n",
      "   validation loss 0.00012930955563206226, (0.00012873307, 0.01777865, 0.0044681123, 0.012967853)\n",
      "decoder loss ratio: 0.000269, decoder SINDy loss  ratio: 0.285541\n",
      "Epoch 852\n",
      "   training loss 9.623543155612424e-05, (9.5750205e-05, 0.014788733, 0.0035563866, 0.0129582)\n",
      "   validation loss 0.0003135545994155109, (0.00031297814, 0.017577657, 0.004468762, 0.0129582)\n",
      "decoder loss ratio: 0.000653, decoder SINDy loss  ratio: 0.285583\n",
      "Epoch 853\n",
      "   training loss 0.00029950597672723234, (0.00029901526, 0.014517363, 0.0036082002, 0.0129896905)\n",
      "   validation loss 0.0004835021391045302, (0.00048291858, 0.017640416, 0.00453677, 0.0129896905)\n",
      "decoder loss ratio: 0.001007, decoder SINDy loss  ratio: 0.289929\n",
      "Epoch 854\n",
      "   training loss 6.226650293683633e-05, (6.178344e-05, 0.015430276, 0.0035304707, 0.013001775)\n",
      "   validation loss 0.00019317389524076134, (0.00019259567, 0.018168103, 0.004482041, 0.013001775)\n",
      "decoder loss ratio: 0.000402, decoder SINDy loss  ratio: 0.286432\n",
      "Epoch 855\n",
      "   training loss 0.00013734614185523242, (0.00013686088, 0.014727809, 0.0035544564, 0.012982073)\n",
      "   validation loss 0.00031106206006370485, (0.00031048147, 0.017511321, 0.0045076986, 0.012982073)\n",
      "decoder loss ratio: 0.000648, decoder SINDy loss  ratio: 0.288071\n",
      "Epoch 856\n",
      "   training loss 7.568794535472989e-05, (7.5205484e-05, 0.01544065, 0.0035263011, 0.012982857)\n",
      "   validation loss 0.0001648828329052776, (0.00016430882, 0.017964639, 0.004441845, 0.012982857)\n",
      "decoder loss ratio: 0.000343, decoder SINDy loss  ratio: 0.283863\n",
      "Epoch 857\n",
      "   training loss 0.00011809637362603098, (0.00011760571, 0.0147391, 0.0036113139, 0.012952997)\n",
      "   validation loss 0.00019342976156622171, (0.00019284688, 0.01748249, 0.004533541, 0.012952997)\n",
      "decoder loss ratio: 0.000402, decoder SINDy loss  ratio: 0.289723\n",
      "Epoch 858\n",
      "   training loss 8.333570440299809e-05, (8.285648e-05, 0.0144907385, 0.0034946008, 0.012977033)\n",
      "   validation loss 0.00025779654970392585, (0.0002572221, 0.017531175, 0.0044466695, 0.012977033)\n",
      "decoder loss ratio: 0.000537, decoder SINDy loss  ratio: 0.284171\n",
      "Epoch 859\n",
      "   training loss 0.00010783778998302296, (0.00010735192, 0.014614117, 0.003561921, 0.012967524)\n",
      "   validation loss 0.00026227973285131156, (0.00026170083, 0.017445404, 0.0044921683, 0.012967524)\n",
      "decoder loss ratio: 0.000546, decoder SINDy loss  ratio: 0.287079\n",
      "Epoch 860\n",
      "   training loss 0.00016657946980558336, (0.00016610192, 0.015772922, 0.0034769352, 0.012985963)\n",
      "   validation loss 0.0002943652798421681, (0.00029379097, 0.018441133, 0.004444382, 0.012985963)\n",
      "decoder loss ratio: 0.000613, decoder SINDy loss  ratio: 0.284025\n",
      "Epoch 861\n",
      "   training loss 9.76802475634031e-05, (9.719191e-05, 0.015235179, 0.0035835067, 0.012999255)\n",
      "   validation loss 0.00019170778978150338, (0.00019112609, 0.017854454, 0.004517093, 0.012999255)\n",
      "decoder loss ratio: 0.000399, decoder SINDy loss  ratio: 0.288672\n",
      "Epoch 862\n",
      "   training loss 0.0001180399558506906, (0.00011755307, 0.015838226, 0.0035675855, 0.0130124455)\n",
      "   validation loss 0.00025266315788030624, (0.00025208632, 0.018391155, 0.004467069, 0.0130124455)\n",
      "decoder loss ratio: 0.000526, decoder SINDy loss  ratio: 0.285475\n",
      "Epoch 863\n",
      "   training loss 5.0257000111741945e-05, (4.977208e-05, 0.015208569, 0.0035500608, 0.012991762)\n",
      "   validation loss 0.00013912034046370536, (0.000138542, 0.017924307, 0.004484233, 0.012991762)\n",
      "decoder loss ratio: 0.000289, decoder SINDy loss  ratio: 0.286572\n",
      "Epoch 864\n",
      "   training loss 3.953288614866324e-05, (3.904947e-05, 0.014933895, 0.0035342984, 0.012998374)\n",
      "   validation loss 0.00013525239774025977, (0.00013467422, 0.017755216, 0.0044819177, 0.012998374)\n",
      "decoder loss ratio: 0.000281, decoder SINDy loss  ratio: 0.286424\n",
      "Epoch 865\n",
      "   training loss 0.00012726165005005896, (0.00012677818, 0.015001257, 0.0035365499, 0.012981375)\n",
      "   validation loss 0.00037750505725853145, (0.00037692869, 0.017954277, 0.0044656536, 0.012981375)\n",
      "decoder loss ratio: 0.000786, decoder SINDy loss  ratio: 0.285384\n",
      "Epoch 866\n",
      "   training loss 0.00021052907686680555, (0.0002100407, 0.014847835, 0.0035851914, 0.012986379)\n",
      "   validation loss 0.00032832889701239765, (0.00032774612, 0.017859649, 0.004529034, 0.012986379)\n",
      "decoder loss ratio: 0.000684, decoder SINDy loss  ratio: 0.289435\n",
      "Epoch 867\n",
      "   training loss 5.5457709095207974e-05, (5.497678e-05, 0.015696984, 0.003510613, 0.012986775)\n",
      "   validation loss 0.00017901229148264974, (0.00017843736, 0.01828638, 0.0044507263, 0.012986775)\n",
      "decoder loss ratio: 0.000372, decoder SINDy loss  ratio: 0.284430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868\n",
      "   training loss 8.546361641492695e-05, (8.497544e-05, 0.015268774, 0.0035825893, 0.012990902)\n",
      "   validation loss 0.0001829064858611673, (0.00018232373, 0.017901469, 0.0045285975, 0.012990902)\n",
      "decoder loss ratio: 0.000380, decoder SINDy loss  ratio: 0.289407\n",
      "Epoch 869\n",
      "   training loss 9.273387695429847e-05, (9.225192e-05, 0.014963376, 0.0035222473, 0.012974076)\n",
      "   validation loss 0.00019797601271420717, (0.00019739998, 0.01801418, 0.0044629415, 0.012974076)\n",
      "decoder loss ratio: 0.000412, decoder SINDy loss  ratio: 0.285211\n",
      "Epoch 870\n",
      "   training loss 0.00018932287639472634, (0.00018883735, 0.0150471805, 0.0035566394, 0.012986355)\n",
      "   validation loss 0.00036112696398049593, (0.00036054634, 0.01793556, 0.0045075277, 0.012986355)\n",
      "decoder loss ratio: 0.000752, decoder SINDy loss  ratio: 0.288060\n",
      "Epoch 871\n",
      "   training loss 0.00011489769531181082, (0.00011441621, 0.016124925, 0.0035153427, 0.012995889)\n",
      "   validation loss 0.0002533250954002142, (0.00025275018, 0.018620048, 0.0044497615, 0.012995889)\n",
      "decoder loss ratio: 0.000527, decoder SINDy loss  ratio: 0.284369\n",
      "Epoch 872\n",
      "   training loss 0.00012762696132995188, (0.00012713792, 0.015358485, 0.0035910218, 0.0129947085)\n",
      "   validation loss 0.0002220101741841063, (0.0002214259, 0.01803513, 0.004543256, 0.0129947085)\n",
      "decoder loss ratio: 0.000462, decoder SINDy loss  ratio: 0.290344\n",
      "Epoch 873\n",
      "   training loss 0.00014932380872778594, (0.00014883924, 0.015524176, 0.00354759, 0.01297997)\n",
      "   validation loss 0.00031252691405825317, (0.00031195066, 0.018284924, 0.0044644545, 0.01297997)\n",
      "decoder loss ratio: 0.000651, decoder SINDy loss  ratio: 0.285308\n",
      "Epoch 874\n",
      "   training loss 0.00013259181287139654, (0.00013210447, 0.015055005, 0.0035733972, 0.0130000515)\n",
      "   validation loss 0.00022538118355441839, (0.00022479943, 0.01805337, 0.0045175683, 0.0130000515)\n",
      "decoder loss ratio: 0.000469, decoder SINDy loss  ratio: 0.288702\n",
      "Epoch 875\n",
      "   training loss 2.2143714886624366e-05, (2.1662729e-05, 0.015377077, 0.0035116961, 0.012981649)\n",
      "   validation loss 0.00012402617721818388, (0.00012344995, 0.01819321, 0.0044641388, 0.012981649)\n",
      "decoder loss ratio: 0.000258, decoder SINDy loss  ratio: 0.285288\n",
      "Epoch 876\n",
      "   training loss 9.178580512525514e-05, (9.1295595e-05, 0.015211299, 0.0036044242, 0.01297692)\n",
      "   validation loss 0.0001794612326193601, (0.00017887812, 0.017688705, 0.0045333127, 0.01297692)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.289708\n",
      "Epoch 877\n",
      "   training loss 9.113743726629764e-05, (9.065564e-05, 0.015875392, 0.00351864, 0.012993121)\n",
      "   validation loss 0.00021949515212327242, (0.00021891536, 0.018500503, 0.004498626, 0.012993121)\n",
      "decoder loss ratio: 0.000457, decoder SINDy loss  ratio: 0.287491\n",
      "Epoch 878\n",
      "   training loss 4.8210451495833695e-05, (4.7724265e-05, 0.015592352, 0.0035607358, 0.013011089)\n",
      "   validation loss 0.00015409983461722732, (0.00015351968, 0.017950013, 0.00450042, 0.013011089)\n",
      "decoder loss ratio: 0.000320, decoder SINDy loss  ratio: 0.287606\n",
      "Epoch 879\n",
      "   training loss 8.630195952719077e-05, (8.581629e-05, 0.016041793, 0.0035577784, 0.0129890945)\n",
      "   validation loss 0.00015851865464355797, (0.00015794014, 0.01852798, 0.0044862702, 0.0129890945)\n",
      "decoder loss ratio: 0.000329, decoder SINDy loss  ratio: 0.286702\n",
      "Epoch 880\n",
      "   training loss 6.575812585651875e-05, (6.5272725e-05, 0.015301774, 0.0035539041, 0.013001523)\n",
      "   validation loss 0.00017344526713714004, (0.00017286361, 0.0182318, 0.0045164037, 0.013001523)\n",
      "decoder loss ratio: 0.000361, decoder SINDy loss  ratio: 0.288628\n",
      "Epoch 881\n",
      "   training loss 4.305730908527039e-05, (4.2572654e-05, 0.0151583515, 0.0035483614, 0.012981822)\n",
      "   validation loss 0.00012005453027086332, (0.000119475495, 0.018137038, 0.0044921935, 0.012981822)\n",
      "decoder loss ratio: 0.000249, decoder SINDy loss  ratio: 0.287080\n",
      "Epoch 882\n",
      "   training loss 0.00012112429976696149, (0.00012064079, 0.014850673, 0.0035368234, 0.012982264)\n",
      "   validation loss 0.00027220018091611564, (0.00027162093, 0.017867234, 0.004494167, 0.012982264)\n",
      "decoder loss ratio: 0.000567, decoder SINDy loss  ratio: 0.287207\n",
      "Epoch 883\n",
      "   training loss 5.832582974107936e-05, (5.7844765e-05, 0.015652811, 0.0035116589, 0.012989738)\n",
      "   validation loss 0.00020560486882459372, (0.00020502968, 0.018458033, 0.004453058, 0.012989738)\n",
      "decoder loss ratio: 0.000428, decoder SINDy loss  ratio: 0.284579\n",
      "Epoch 884\n",
      "   training loss 0.00016381080786231905, (0.00016331952, 0.015122559, 0.0036142208, 0.012985427)\n",
      "   validation loss 0.00026451816665939987, (0.00026393347, 0.018142477, 0.004548302, 0.012985427)\n",
      "decoder loss ratio: 0.000551, decoder SINDy loss  ratio: 0.290666\n",
      "Epoch 885\n",
      "   training loss 0.00010979047510772943, (0.00010930553, 0.01559801, 0.0035509055, 0.012985408)\n",
      "   validation loss 0.00021654684678651392, (0.000215968, 0.018579561, 0.0044898083, 0.012985408)\n",
      "decoder loss ratio: 0.000451, decoder SINDy loss  ratio: 0.286928\n",
      "Epoch 886\n",
      "   training loss 0.0001339844020549208, (0.00013349962, 0.015082016, 0.0035497344, 0.012980778)\n",
      "   validation loss 0.0002832894679158926, (0.0002827095, 0.0181566, 0.0045017973, 0.012980778)\n",
      "decoder loss ratio: 0.000590, decoder SINDy loss  ratio: 0.287694\n",
      "Epoch 887\n",
      "   training loss 3.564888902474195e-05, (3.5167497e-05, 0.015814811, 0.003516894, 0.012970298)\n",
      "   validation loss 0.00014545458543580025, (0.00014487919, 0.018457534, 0.0044569555, 0.012970298)\n",
      "decoder loss ratio: 0.000302, decoder SINDy loss  ratio: 0.284828\n",
      "Epoch 888\n",
      "   training loss 0.00011416229244787246, (0.00011367446, 0.0148915695, 0.003581128, 0.012971721)\n",
      "   validation loss 0.00020236811542417854, (0.00020178495, 0.017655192, 0.0045344546, 0.012971721)\n",
      "decoder loss ratio: 0.000421, decoder SINDy loss  ratio: 0.289781\n",
      "Epoch 889\n",
      "   training loss 0.00010689106420613825, (0.000106410684, 0.016191276, 0.0035033757, 0.013004467)\n",
      "   validation loss 0.00024448716430924833, (0.00024391057, 0.018769154, 0.004465672, 0.013004467)\n",
      "decoder loss ratio: 0.000509, decoder SINDy loss  ratio: 0.285386\n",
      "Epoch 890\n",
      "   training loss 7.428271055687219e-05, (7.379333e-05, 0.016567172, 0.0035908977, 0.013028953)\n",
      "   validation loss 0.00017468702571932226, (0.00017410498, 0.018681882, 0.004517647, 0.013028953)\n",
      "decoder loss ratio: 0.000363, decoder SINDy loss  ratio: 0.288707\n",
      "Epoch 891\n",
      "   training loss 7.007081876508892e-05, (6.958318e-05, 0.016375987, 0.0035754805, 0.013009588)\n",
      "   validation loss 0.00018601847114041448, (0.00018543845, 0.018731588, 0.0044992757, 0.013009588)\n",
      "decoder loss ratio: 0.000387, decoder SINDy loss  ratio: 0.287533\n",
      "Epoch 892\n",
      "   training loss 4.280486609786749e-05, (4.2319225e-05, 0.015981354, 0.0035549803, 0.013014274)\n",
      "   validation loss 0.00012417120160534978, (0.00012359132, 0.018613942, 0.004497355, 0.013014274)\n",
      "decoder loss ratio: 0.000258, decoder SINDy loss  ratio: 0.287410\n",
      "Epoch 893\n",
      "   training loss 4.9777117965277284e-05, (4.9292732e-05, 0.01550094, 0.0035448154, 0.012990635)\n",
      "   validation loss 0.00013505620881915092, (0.00013447575, 0.018444343, 0.004505616, 0.012990635)\n",
      "decoder loss ratio: 0.000281, decoder SINDy loss  ratio: 0.287938\n",
      "Epoch 894\n",
      "   training loss 6.255167681956664e-05, (6.206636e-05, 0.015070208, 0.003555033, 0.012980762)\n",
      "   validation loss 0.00015279592480510473, (0.00015221605, 0.018181067, 0.00450082, 0.012980762)\n",
      "decoder loss ratio: 0.000318, decoder SINDy loss  ratio: 0.287632\n",
      "Epoch 895\n",
      "   training loss 0.00018208597612101585, (0.00018160336, 0.014819175, 0.0035285163, 0.01297663)\n",
      "   validation loss 0.0003610036801546812, (0.00036042434, 0.01796018, 0.004495623, 0.01297663)\n",
      "decoder loss ratio: 0.000752, decoder SINDy loss  ratio: 0.287300\n",
      "Epoch 896\n",
      "   training loss 0.00010857678717002273, (0.000108093685, 0.015840372, 0.003532121, 0.012989273)\n",
      "   validation loss 0.00019624635751824826, (0.0001956686, 0.018661771, 0.0044786725, 0.012989273)\n",
      "decoder loss ratio: 0.000408, decoder SINDy loss  ratio: 0.286216\n",
      "Epoch 897\n",
      "   training loss 9.258617501473054e-05, (9.2100585e-05, 0.0152423745, 0.0035577025, 0.012981693)\n",
      "   validation loss 0.00019763059390243143, (0.00019704853, 0.018267777, 0.0045224675, 0.012981693)\n",
      "decoder loss ratio: 0.000411, decoder SINDy loss  ratio: 0.289015\n",
      "Epoch 898\n",
      "   training loss 6.185648089740425e-05, (6.1372375e-05, 0.016003093, 0.0035419185, 0.012991381)\n",
      "   validation loss 0.00016305076132994145, (0.00016247116, 0.01892372, 0.0044968314, 0.012991381)\n",
      "decoder loss ratio: 0.000339, decoder SINDy loss  ratio: 0.287377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899\n",
      "   training loss 0.00012165439693490043, (0.000121169316, 0.0153256925, 0.0035527903, 0.012980301)\n",
      "   validation loss 0.00021890350035391748, (0.00021832269, 0.018408181, 0.0045100055, 0.012980301)\n",
      "decoder loss ratio: 0.000455, decoder SINDy loss  ratio: 0.288219\n",
      "Epoch 900\n",
      "   training loss 8.043251727940515e-05, (7.995067e-05, 0.016183326, 0.0035210731, 0.012974815)\n",
      "   validation loss 0.00024207909882534295, (0.00024150257, 0.01892318, 0.00446788, 0.012974815)\n",
      "decoder loss ratio: 0.000504, decoder SINDy loss  ratio: 0.285527\n",
      "Epoch 901\n",
      "   training loss 0.00020551355555653572, (0.00020502694, 0.014837955, 0.0035688211, 0.012972992)\n",
      "   validation loss 0.0002507797908037901, (0.00025019704, 0.018117452, 0.0045303376, 0.012972992)\n",
      "decoder loss ratio: 0.000522, decoder SINDy loss  ratio: 0.289518\n",
      "Epoch 902\n",
      "   training loss 6.201746145961806e-05, (6.153455e-05, 0.016338727, 0.0035302506, 0.012988794)\n",
      "   validation loss 0.00024951330851763487, (0.00024893513, 0.018955756, 0.004482787, 0.012988794)\n",
      "decoder loss ratio: 0.000519, decoder SINDy loss  ratio: 0.286479\n",
      "Epoch 903\n",
      "   training loss 7.824108615750447e-05, (7.775331e-05, 0.016415454, 0.0035782824, 0.012994158)\n",
      "   validation loss 0.0001605561119504273, (0.00015997246, 0.018861555, 0.0045370166, 0.012994158)\n",
      "decoder loss ratio: 0.000334, decoder SINDy loss  ratio: 0.289945\n",
      "Epoch 904\n",
      "   training loss 8.046382572501898e-05, (7.9977515e-05, 0.016246099, 0.0035645629, 0.012985402)\n",
      "   validation loss 0.0001951393496710807, (0.00019455774, 0.019139571, 0.004517428, 0.012985402)\n",
      "decoder loss ratio: 0.000406, decoder SINDy loss  ratio: 0.288693\n",
      "Epoch 905\n",
      "   training loss 3.827597538474947e-05, (3.778968e-05, 0.016133895, 0.0035652695, 0.012976942)\n",
      "   validation loss 0.00012899120338261127, (0.000128411, 0.018834922, 0.004504287, 0.012976942)\n",
      "decoder loss ratio: 0.000268, decoder SINDy loss  ratio: 0.287853\n",
      "Epoch 906\n",
      "   training loss 3.1420833693118766e-05, (3.0935847e-05, 0.015877733, 0.0035520485, 0.012978005)\n",
      "   validation loss 0.0001214048606925644, (0.00012082404, 0.018757734, 0.0045103854, 0.012978005)\n",
      "decoder loss ratio: 0.000252, decoder SINDy loss  ratio: 0.288243\n",
      "Epoch 907\n",
      "   training loss 3.773086427827366e-05, (3.724747e-05, 0.0156056015, 0.003536589, 0.012973252)\n",
      "   validation loss 0.00013299682177603245, (0.0001324176, 0.018549755, 0.0044948766, 0.012973252)\n",
      "decoder loss ratio: 0.000276, decoder SINDy loss  ratio: 0.287252\n",
      "Epoch 908\n",
      "   training loss 0.00012683877139352262, (0.00012635923, 0.014976186, 0.0034964164, 0.012991049)\n",
      "   validation loss 0.0003522181650623679, (0.0003516405, 0.018299853, 0.0044772993, 0.012991049)\n",
      "decoder loss ratio: 0.000734, decoder SINDy loss  ratio: 0.286129\n",
      "Epoch 909\n",
      "   training loss 8.677200094098225e-05, (8.6291184e-05, 0.01621017, 0.0035100996, 0.01298088)\n",
      "   validation loss 0.00020883594697806984, (0.0002082612, 0.018870896, 0.0044494374, 0.01298088)\n",
      "decoder loss ratio: 0.000434, decoder SINDy loss  ratio: 0.284348\n",
      "Epoch 910\n",
      "   training loss 7.326950435526669e-05, (7.2783434e-05, 0.015875755, 0.0035605843, 0.013001583)\n",
      "   validation loss 0.00019035716832149774, (0.00018977321, 0.018923935, 0.004539271, 0.013001583)\n",
      "decoder loss ratio: 0.000396, decoder SINDy loss  ratio: 0.290089\n",
      "Epoch 911\n",
      "   training loss 6.250971637200564e-05, (6.2024876e-05, 0.01604643, 0.0035505681, 0.012978224)\n",
      "   validation loss 0.00016051315469667315, (0.0001599333, 0.019031174, 0.004500664, 0.012978224)\n",
      "decoder loss ratio: 0.000334, decoder SINDy loss  ratio: 0.287622\n",
      "Epoch 912\n",
      "   training loss 3.963943163398653e-05, (3.9155297e-05, 0.0163308, 0.0035421504, 0.012992125)\n",
      "   validation loss 0.00013027177192270756, (0.00012969154, 0.01899487, 0.0045031034, 0.012992125)\n",
      "decoder loss ratio: 0.000271, decoder SINDy loss  ratio: 0.287778\n",
      "Epoch 913\n",
      "   training loss 3.58192810381297e-05, (3.5336503e-05, 0.01613148, 0.0035308865, 0.012969101)\n",
      "   validation loss 0.0001299113646382466, (0.00012933153, 0.019031962, 0.0045014373, 0.012969101)\n",
      "decoder loss ratio: 0.000270, decoder SINDy loss  ratio: 0.287671\n",
      "Epoch 914\n",
      "   training loss 9.155881707556546e-05, (9.107588e-05, 0.015702225, 0.0035326604, 0.012966268)\n",
      "   validation loss 0.00023571700148750097, (0.00023513853, 0.018769477, 0.004488114, 0.012966268)\n",
      "decoder loss ratio: 0.000491, decoder SINDy loss  ratio: 0.286820\n",
      "Epoch 915\n",
      "   training loss 6.353516801027581e-05, (6.305202e-05, 0.01572757, 0.0035342977, 0.012971446)\n",
      "   validation loss 0.00015878277190495282, (0.00015820294, 0.018657807, 0.004501133, 0.012971446)\n",
      "decoder loss ratio: 0.000330, decoder SINDy loss  ratio: 0.287652\n",
      "Epoch 916\n",
      "   training loss 4.024210647912696e-05, (3.9761264e-05, 0.016258031, 0.0035098926, 0.012985256)\n",
      "   validation loss 0.00013836202560923994, (0.00013778439, 0.01900123, 0.0044779344, 0.012985256)\n",
      "decoder loss ratio: 0.000287, decoder SINDy loss  ratio: 0.286169\n",
      "Epoch 917\n",
      "   training loss 5.336745016393252e-05, (5.2885425e-05, 0.01631118, 0.0035233041, 0.012969318)\n",
      "   validation loss 0.0001384195638820529, (0.00013783993, 0.019213257, 0.004499477, 0.012969318)\n",
      "decoder loss ratio: 0.000288, decoder SINDy loss  ratio: 0.287546\n",
      "Epoch 918\n",
      "   training loss 0.00013024704821873456, (0.00012976174, 0.015067603, 0.0035569586, 0.012961781)\n",
      "   validation loss 0.00020137045066803694, (0.00020078859, 0.018532125, 0.004522394, 0.012961781)\n",
      "decoder loss ratio: 0.000419, decoder SINDy loss  ratio: 0.289010\n",
      "Epoch 919\n",
      "   training loss 5.3477273468161e-05, (5.2994168e-05, 0.016010722, 0.0035325314, 0.012985434)\n",
      "   validation loss 0.00017328502144664526, (0.0001727048, 0.018932419, 0.004503713, 0.012985434)\n",
      "decoder loss ratio: 0.000360, decoder SINDy loss  ratio: 0.287817\n",
      "Epoch 920\n",
      "   training loss 0.0001132959223468788, (0.000112811584, 0.01637956, 0.00354655, 0.012968878)\n",
      "   validation loss 0.00022464701032731682, (0.0002240654, 0.019157784, 0.004519289, 0.012968878)\n",
      "decoder loss ratio: 0.000467, decoder SINDy loss  ratio: 0.288812\n",
      "Epoch 921\n",
      "   training loss 7.737685518804938e-05, (7.689302e-05, 0.015989365, 0.0035408223, 0.012975103)\n",
      "   validation loss 0.00019154978508595377, (0.0001909685, 0.019064918, 0.0045153997, 0.012975103)\n",
      "decoder loss ratio: 0.000398, decoder SINDy loss  ratio: 0.288563\n",
      "Epoch 922\n",
      "   training loss 6.718286749674007e-05, (6.670019e-05, 0.015984666, 0.0035302637, 0.012965309)\n",
      "   validation loss 0.00016485172091051936, (0.00016427401, 0.018981712, 0.004480574, 0.012965309)\n",
      "decoder loss ratio: 0.000343, decoder SINDy loss  ratio: 0.286338\n",
      "Epoch 923\n",
      "   training loss 5.293160938890651e-05, (5.2449563e-05, 0.01594062, 0.0035251516, 0.01295293)\n",
      "   validation loss 0.00014698348240926862, (0.00014640517, 0.019037483, 0.0044877552, 0.01295293)\n",
      "decoder loss ratio: 0.000305, decoder SINDy loss  ratio: 0.286797\n",
      "Epoch 924\n",
      "   training loss 6.941783067304641e-05, (6.8935886e-05, 0.015819147, 0.0035239917, 0.012954909)\n",
      "   validation loss 0.00016621043323539197, (0.00016563307, 0.01892342, 0.004478038, 0.012954909)\n",
      "decoder loss ratio: 0.000346, decoder SINDy loss  ratio: 0.286176\n",
      "Epoch 925\n",
      "   training loss 0.00015705538680776954, (0.00015657622, 0.0148978485, 0.0034950615, 0.012965691)\n",
      "   validation loss 0.00031348210177384317, (0.00031290538, 0.018461892, 0.004470688, 0.012965691)\n",
      "decoder loss ratio: 0.000653, decoder SINDy loss  ratio: 0.285706\n",
      "Epoch 926\n",
      "   training loss 7.315659604500979e-05, (7.267658e-05, 0.016279861, 0.0035020271, 0.012981681)\n",
      "   validation loss 0.00018747647118289024, (0.00018690072, 0.019110046, 0.00445936, 0.012981681)\n",
      "decoder loss ratio: 0.000390, decoder SINDy loss  ratio: 0.284982\n",
      "Epoch 927\n",
      "   training loss 8.375404286198318e-05, (8.32705e-05, 0.01592755, 0.003538651, 0.012967643)\n",
      "   validation loss 0.00021307726274244487, (0.00021249463, 0.019137934, 0.0045295767, 0.012967643)\n",
      "decoder loss ratio: 0.000443, decoder SINDy loss  ratio: 0.289469\n",
      "Epoch 928\n",
      "   training loss 5.433315163827501e-05, (5.3848038e-05, 0.016257627, 0.00355268, 0.0129847955)\n",
      "   validation loss 0.00015344397979788482, (0.00015286368, 0.019192874, 0.0045044827, 0.0129847955)\n",
      "decoder loss ratio: 0.000319, decoder SINDy loss  ratio: 0.287866\n",
      "Epoch 929\n",
      "   training loss 3.774013021029532e-05, (3.7254707e-05, 0.016638095, 0.0035579884, 0.0129625015)\n",
      "   validation loss 0.00014214494149200618, (0.00014156329, 0.019336672, 0.0045202537, 0.0129625015)\n",
      "decoder loss ratio: 0.000295, decoder SINDy loss  ratio: 0.288874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930\n",
      "   training loss 4.379143865662627e-05, (4.3306736e-05, 0.01653073, 0.003550062, 0.012969792)\n",
      "   validation loss 0.00015066731430124491, (0.00015008613, 0.019369863, 0.004514807, 0.012969792)\n",
      "decoder loss ratio: 0.000313, decoder SINDy loss  ratio: 0.288526\n",
      "Epoch 931\n",
      "   training loss 5.4053045460022986e-05, (5.3568743e-05, 0.01630876, 0.0035489658, 0.012940511)\n",
      "   validation loss 0.00015857959806453437, (0.00015799882, 0.019292543, 0.0045136646, 0.012940511)\n",
      "decoder loss ratio: 0.000330, decoder SINDy loss  ratio: 0.288453\n",
      "Epoch 932\n",
      "   training loss 5.876323120901361e-05, (5.8279293e-05, 0.01619018, 0.0035440056, 0.012953828)\n",
      "   validation loss 0.00015794977662153542, (0.00015736895, 0.019228645, 0.0045128344, 0.012953828)\n",
      "decoder loss ratio: 0.000328, decoder SINDy loss  ratio: 0.288399\n",
      "Epoch 933\n",
      "   training loss 5.3105301049072295e-05, (5.262229e-05, 0.016133653, 0.0035354844, 0.012946091)\n",
      "   validation loss 0.00015427664038725197, (0.00015369646, 0.019194882, 0.0045073694, 0.012946091)\n",
      "decoder loss ratio: 0.000321, decoder SINDy loss  ratio: 0.288050\n",
      "Epoch 934\n",
      "   training loss 4.910810821456835e-05, (4.862585e-05, 0.016103147, 0.0035273072, 0.012952505)\n",
      "   validation loss 0.0001633158972254023, (0.00016273696, 0.019129578, 0.004494108, 0.012952505)\n",
      "decoder loss ratio: 0.000339, decoder SINDy loss  ratio: 0.287203\n",
      "Epoch 935\n",
      "   training loss 5.553745722863823e-05, (5.5056433e-05, 0.01574714, 0.0035155243, 0.012947147)\n",
      "   validation loss 0.00015660615463275462, (0.00015602756, 0.018957917, 0.004491285, 0.012947147)\n",
      "decoder loss ratio: 0.000326, decoder SINDy loss  ratio: 0.287022\n",
      "Epoch 936\n",
      "   training loss 4.572087709675543e-05, (4.524111e-05, 0.015828205, 0.003502488, 0.012951706)\n",
      "   validation loss 0.00014971874770708382, (0.0001491416, 0.01901414, 0.004476365, 0.012951706)\n",
      "decoder loss ratio: 0.000311, decoder SINDy loss  ratio: 0.286069\n",
      "Epoch 937\n",
      "   training loss 8.32956939120777e-05, (8.281531e-05, 0.015766947, 0.0035092726, 0.012945455)\n",
      "   validation loss 0.0002196714049205184, (0.00021909397, 0.018917693, 0.0044798004, 0.012945455)\n",
      "decoder loss ratio: 0.000457, decoder SINDy loss  ratio: 0.286288\n",
      "Epoch 938\n",
      "   training loss 9.938955190591514e-05, (9.89079e-05, 0.016131414, 0.0035210417, 0.012954757)\n",
      "   validation loss 0.0003054737171623856, (0.00030489365, 0.019548882, 0.004505203, 0.012954757)\n",
      "decoder loss ratio: 0.000636, decoder SINDy loss  ratio: 0.287912\n",
      "Epoch 939\n",
      "   training loss 0.00020154680532868952, (0.00020105945, 0.017547637, 0.0035768282, 0.012967541)\n",
      "   validation loss 0.0002990666835103184, (0.0002984841, 0.020189457, 0.0045288466, 0.012967541)\n",
      "decoder loss ratio: 0.000623, decoder SINDy loss  ratio: 0.289423\n",
      "Epoch 940\n",
      "   training loss 0.0001245565654244274, (0.0001240702, 0.015725737, 0.0035645792, 0.012990788)\n",
      "   validation loss 0.0002901496773120016, (0.00028956527, 0.019087074, 0.0045447764, 0.012990788)\n",
      "decoder loss ratio: 0.000604, decoder SINDy loss  ratio: 0.290441\n",
      "Epoch 941\n",
      "   training loss 7.048642873996869e-05, (6.999891e-05, 0.016444387, 0.0035775776, 0.012975822)\n",
      "   validation loss 0.00016416616563219577, (0.00016358502, 0.019382037, 0.0045138197, 0.012975822)\n",
      "decoder loss ratio: 0.000341, decoder SINDy loss  ratio: 0.288462\n",
      "Epoch 942\n",
      "   training loss 4.31902808486484e-05, (4.2701515e-05, 0.01699803, 0.003589838, 0.012978165)\n",
      "   validation loss 0.0001461635110899806, (0.00014558012, 0.019605905, 0.004535911, 0.012978165)\n",
      "decoder loss ratio: 0.000304, decoder SINDy loss  ratio: 0.289874\n",
      "Epoch 943\n",
      "   training loss 4.18617892137263e-05, (4.137503e-05, 0.01681239, 0.0035705224, 0.0129704075)\n",
      "   validation loss 0.00014591428043786436, (0.00014533242, 0.0195414, 0.0045215334, 0.0129704075)\n",
      "decoder loss ratio: 0.000303, decoder SINDy loss  ratio: 0.288955\n",
      "Epoch 944\n",
      "   training loss 5.430445526144467e-05, (5.3818283e-05, 0.016812151, 0.0035658497, 0.012958903)\n",
      "   validation loss 0.00018138575251214206, (0.00018080488, 0.01966947, 0.0045128013, 0.012958903)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.288397\n",
      "Epoch 945\n",
      "   training loss 6.130875408416614e-05, (6.082269e-05, 0.016572542, 0.0035655727, 0.012950451)\n",
      "   validation loss 0.00016991299344226718, (0.00016933163, 0.019598788, 0.0045186607, 0.012950451)\n",
      "decoder loss ratio: 0.000353, decoder SINDy loss  ratio: 0.288772\n",
      "Epoch 946\n",
      "   training loss 0.00010808378283400089, (0.000107598906, 0.01628658, 0.003551599, 0.0129716825)\n",
      "   validation loss 0.00022419133165385574, (0.00022360988, 0.019390719, 0.0045174174, 0.0129716825)\n",
      "decoder loss ratio: 0.000466, decoder SINDy loss  ratio: 0.288692\n",
      "Epoch 947\n",
      "   training loss 6.742739788023755e-05, (6.694114e-05, 0.016987128, 0.003568819, 0.012937825)\n",
      "   validation loss 0.00016810472880024463, (0.00016752417, 0.01971438, 0.0045117494, 0.012937825)\n",
      "decoder loss ratio: 0.000349, decoder SINDy loss  ratio: 0.288330\n",
      "Epoch 948\n",
      "   training loss 7.436847226927057e-05, (7.3883304e-05, 0.016517429, 0.0035565998, 0.012950823)\n",
      "   validation loss 0.0001976228813873604, (0.0001970418, 0.019741215, 0.004515791, 0.012950823)\n",
      "decoder loss ratio: 0.000411, decoder SINDy loss  ratio: 0.288588\n",
      "Epoch 949\n",
      "   training loss 0.0001103488975786604, (0.00010986664, 0.016072353, 0.0035282234, 0.012943535)\n",
      "   validation loss 0.0002430130261927843, (0.00024243412, 0.01946216, 0.004494717, 0.012943535)\n",
      "decoder loss ratio: 0.000506, decoder SINDy loss  ratio: 0.287242\n",
      "Epoch 950\n",
      "   training loss 0.0002106995671056211, (0.00021021342, 0.016198732, 0.0035661396, 0.0129546765)\n",
      "   validation loss 0.00040630585863254964, (0.0004057231, 0.019324645, 0.0045319316, 0.0129546765)\n",
      "decoder loss ratio: 0.000846, decoder SINDy loss  ratio: 0.289620\n",
      "Epoch 951\n",
      "   training loss 7.288029883056879e-05, (7.239345e-05, 0.017200863, 0.0035727136, 0.012957422)\n",
      "   validation loss 0.00017327428213320673, (0.00017269337, 0.019892715, 0.0045134863, 0.012957422)\n",
      "decoder loss ratio: 0.000360, decoder SINDy loss  ratio: 0.288441\n",
      "Epoch 952\n",
      "   training loss 6.67979329591617e-05, (6.631127e-05, 0.01694752, 0.0035694132, 0.01297168)\n",
      "   validation loss 0.00019901973428204656, (0.00019843849, 0.01990686, 0.004515381, 0.01297168)\n",
      "decoder loss ratio: 0.000414, decoder SINDy loss  ratio: 0.288562\n",
      "Epoch 953\n",
      "   training loss 0.00012701698869932443, (0.00012653225, 0.01619473, 0.0035514105, 0.012959428)\n",
      "   validation loss 0.0002880367392208427, (0.00028745586, 0.019389339, 0.0045128786, 0.012959428)\n",
      "decoder loss ratio: 0.000600, decoder SINDy loss  ratio: 0.288402\n",
      "Epoch 954\n",
      "   training loss 0.0001128676813095808, (0.00011238017, 0.016520625, 0.0035779902, 0.012970924)\n",
      "   validation loss 0.00025557944900356233, (0.0002549965, 0.019351676, 0.0045323055, 0.012970924)\n",
      "decoder loss ratio: 0.000532, decoder SINDy loss  ratio: 0.289644\n",
      "Epoch 955\n",
      "   training loss 7.126911077648401e-05, (7.078129e-05, 0.0173862, 0.0035817986, 0.012964282)\n",
      "   validation loss 0.000207103556022048, (0.00020652261, 0.0199912, 0.004513028, 0.012964282)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.288412\n",
      "Epoch 956\n",
      "   training loss 5.689488898497075e-05, (5.640897e-05, 0.016660767, 0.0035640947, 0.012950704)\n",
      "   validation loss 0.00018800038378685713, (0.00018741933, 0.019791435, 0.0045154695, 0.012950704)\n",
      "decoder loss ratio: 0.000391, decoder SINDy loss  ratio: 0.288568\n",
      "Epoch 957\n",
      "   training loss 0.00015940154844429344, (0.00015891698, 0.016081812, 0.0035494913, 0.012961135)\n",
      "   validation loss 0.00034109302214346826, (0.00034051182, 0.019315286, 0.0045159883, 0.012961135)\n",
      "decoder loss ratio: 0.000710, decoder SINDy loss  ratio: 0.288601\n",
      "Epoch 958\n",
      "   training loss 5.7777564506977797e-05, (5.729011e-05, 0.016895654, 0.0035782591, 0.012962966)\n",
      "   validation loss 0.00017207596101798117, (0.00017149406, 0.019484239, 0.0045227525, 0.012962966)\n",
      "decoder loss ratio: 0.000358, decoder SINDy loss  ratio: 0.289033\n",
      "Epoch 959\n",
      "   training loss 7.580400415463373e-05, (7.531918e-05, 0.01709687, 0.0035531337, 0.012950888)\n",
      "   validation loss 0.00020689988741651177, (0.00020632046, 0.020081144, 0.0044991677, 0.012950888)\n",
      "decoder loss ratio: 0.000430, decoder SINDy loss  ratio: 0.287526\n",
      "Epoch 960\n",
      "   training loss 0.00010457121970830485, (0.000104087085, 0.016213715, 0.003545504, 0.012958618)\n",
      "   validation loss 0.0002288965624757111, (0.00022831687, 0.019560037, 0.0045010145, 0.012958618)\n",
      "decoder loss ratio: 0.000476, decoder SINDy loss  ratio: 0.287644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961\n",
      "   training loss 7.077118789311498e-05, (7.028488e-05, 0.016856615, 0.0035676647, 0.012954316)\n",
      "   validation loss 0.00020144674635957927, (0.00020086562, 0.019541439, 0.0045159324, 0.012954316)\n",
      "decoder loss ratio: 0.000419, decoder SINDy loss  ratio: 0.288597\n",
      "Epoch 962\n",
      "   training loss 4.952888411935419e-05, (4.9043963e-05, 0.016927524, 0.0035520617, 0.012971573)\n",
      "   validation loss 0.0001814115239540115, (0.00018083068, 0.019902848, 0.0045112004, 0.012971573)\n",
      "decoder loss ratio: 0.000377, decoder SINDy loss  ratio: 0.288295\n",
      "Epoch 963\n",
      "   training loss 0.00010958638449665159, (0.00010910274, 0.016502991, 0.0035407643, 0.012956977)\n",
      "   validation loss 0.0002478067472111434, (0.00024722918, 0.019862771, 0.0044799224, 0.012956977)\n",
      "decoder loss ratio: 0.000516, decoder SINDy loss  ratio: 0.286296\n",
      "Epoch 964\n",
      "   training loss 0.0001289688516408205, (0.00012848427, 0.01607914, 0.003548788, 0.012970628)\n",
      "   validation loss 0.0002676667645573616, (0.00026708594, 0.019397719, 0.0045109917, 0.012970628)\n",
      "decoder loss ratio: 0.000557, decoder SINDy loss  ratio: 0.288282\n",
      "Epoch 965\n",
      "   training loss 7.10515450919047e-05, (7.056631e-05, 0.017223326, 0.0035559628, 0.012963677)\n",
      "   validation loss 0.00020345093798823655, (0.00020287099, 0.019715698, 0.0045031384, 0.012963677)\n",
      "decoder loss ratio: 0.000423, decoder SINDy loss  ratio: 0.287780\n",
      "Epoch 966\n",
      "   training loss 6.879425200168043e-05, (6.8309535e-05, 0.016834056, 0.0035489183, 0.012982387)\n",
      "   validation loss 0.00019494775915518403, (0.00019436672, 0.019851474, 0.0045123305, 0.012982387)\n",
      "decoder loss ratio: 0.000405, decoder SINDy loss  ratio: 0.288367\n",
      "Epoch 967\n",
      "   training loss 7.888094114605337e-05, (7.839511e-05, 0.016464802, 0.003563, 0.012953283)\n",
      "   validation loss 0.00017917004879564047, (0.00017859032, 0.019590436, 0.004502058, 0.012953283)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.287711\n",
      "Epoch 968\n",
      "   training loss 6.510991079267114e-05, (6.462289e-05, 0.017116664, 0.0035748289, 0.012954137)\n",
      "   validation loss 0.00018642249051481485, (0.00018584207, 0.019896647, 0.0045087617, 0.012954137)\n",
      "decoder loss ratio: 0.000388, decoder SINDy loss  ratio: 0.288139\n",
      "Epoch 969\n",
      "   training loss 7.88211909821257e-05, (7.833761e-05, 0.016364545, 0.0035404102, 0.01295438)\n",
      "   validation loss 0.00019949530542362481, (0.00019891527, 0.019734517, 0.0045049204, 0.01295438)\n",
      "decoder loss ratio: 0.000415, decoder SINDy loss  ratio: 0.287894\n",
      "Epoch 970\n",
      "   training loss 9.926401253324002e-05, (9.8780656e-05, 0.016413784, 0.0035362504, 0.0129729705)\n",
      "   validation loss 0.0002411690220469609, (0.00024058895, 0.019719109, 0.0045033237, 0.0129729705)\n",
      "decoder loss ratio: 0.000502, decoder SINDy loss  ratio: 0.287792\n",
      "Epoch 971\n",
      "   training loss 6.111508992034942e-05, (6.062977e-05, 0.017316798, 0.0035579237, 0.012953159)\n",
      "   validation loss 0.000178888178197667, (0.00017830811, 0.020074096, 0.0045053526, 0.012953159)\n",
      "decoder loss ratio: 0.000372, decoder SINDy loss  ratio: 0.287921\n",
      "Epoch 972\n",
      "   training loss 6.88943182467483e-05, (6.840916e-05, 0.017015789, 0.0035553928, 0.012961793)\n",
      "   validation loss 0.00020695729472208768, (0.00020637437, 0.02035286, 0.0045330175, 0.012961793)\n",
      "decoder loss ratio: 0.000431, decoder SINDy loss  ratio: 0.289689\n",
      "Epoch 973\n",
      "   training loss 0.00013747565390076488, (0.00013698917, 0.017612582, 0.0035687983, 0.012960344)\n",
      "   validation loss 0.00040466361679136753, (0.00040408454, 0.020679068, 0.0044946806, 0.012960344)\n",
      "decoder loss ratio: 0.000843, decoder SINDy loss  ratio: 0.287239\n",
      "Epoch 974\n",
      "   training loss 0.0001200430269818753, (0.00011955208, 0.017304502, 0.003609621, 0.012998311)\n",
      "   validation loss 0.00022626918507739902, (0.00022568382, 0.019669654, 0.004553921, 0.012998311)\n",
      "decoder loss ratio: 0.000471, decoder SINDy loss  ratio: 0.291025\n",
      "Epoch 975\n",
      "   training loss 0.00017596416000742465, (0.00017547412, 0.015955342, 0.0036033564, 0.012969828)\n",
      "   validation loss 0.00022732779325451702, (0.00022674484, 0.01922122, 0.0045325262, 0.012969828)\n",
      "decoder loss ratio: 0.000473, decoder SINDy loss  ratio: 0.289658\n",
      "Epoch 976\n",
      "   training loss 0.00011779477790696546, (0.00011729975, 0.0178957, 0.0036525927, 0.012976547)\n",
      "   validation loss 0.0001883683435153216, (0.00018778234, 0.02021517, 0.004562416, 0.012976547)\n",
      "decoder loss ratio: 0.000392, decoder SINDy loss  ratio: 0.291568\n",
      "Epoch 977\n",
      "   training loss 0.00017098769603762776, (0.00017049446, 0.016521547, 0.0036373015, 0.012951854)\n",
      "   validation loss 0.00022966662072576582, (0.00022908274, 0.019573053, 0.0045437207, 0.012951854)\n",
      "decoder loss ratio: 0.000478, decoder SINDy loss  ratio: 0.290373\n",
      "Epoch 978\n",
      "   training loss 8.587422780692577e-05, (8.537939e-05, 0.01797525, 0.0036519293, 0.012964582)\n",
      "   validation loss 0.00015995788271538913, (0.00015937204, 0.020279102, 0.0045620734, 0.012964582)\n",
      "decoder loss ratio: 0.000332, decoder SINDy loss  ratio: 0.291546\n",
      "Epoch 979\n",
      "   training loss 0.00017903091793414205, (0.00017853754, 0.016724998, 0.0036397371, 0.012941013)\n",
      "   validation loss 0.000267101131612435, (0.00026651702, 0.019747237, 0.0045472756, 0.012941013)\n",
      "decoder loss ratio: 0.000556, decoder SINDy loss  ratio: 0.290600\n",
      "Epoch 980\n",
      "   training loss 6.40263024251908e-05, (6.353071e-05, 0.017909812, 0.0036604067, 0.012955846)\n",
      "   validation loss 0.00014651445962954313, (0.00014592781, 0.020256406, 0.0045708665, 0.012955846)\n",
      "decoder loss ratio: 0.000304, decoder SINDy loss  ratio: 0.292108\n",
      "Epoch 981\n",
      "   training loss 0.00010995005868608132, (0.00010945769, 0.016860778, 0.0036312453, 0.0129252365)\n",
      "   validation loss 0.00021369406022131443, (0.00021310995, 0.019821608, 0.0045486903, 0.0129252365)\n",
      "decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.290691\n",
      "Epoch 982\n",
      "   training loss 5.077260357211344e-05, (5.0278857e-05, 0.017719138, 0.003642527, 0.0129493)\n",
      "   validation loss 0.00014321932394523174, (0.00014263387, 0.020250663, 0.0045595304, 0.0129493)\n",
      "decoder loss ratio: 0.000298, decoder SINDy loss  ratio: 0.291384\n",
      "Epoch 983\n",
      "   training loss 0.00012579969188664109, (0.00012530817, 0.016565638, 0.003622966, 0.01292262)\n",
      "   validation loss 0.00022956376778893173, (0.00022897989, 0.019705376, 0.004546591, 0.01292262)\n",
      "decoder loss ratio: 0.000478, decoder SINDy loss  ratio: 0.290557\n",
      "Epoch 984\n",
      "   training loss 5.511504059541039e-05, (5.4620166e-05, 0.018051172, 0.0036543019, 0.012944326)\n",
      "   validation loss 0.0001502781524322927, (0.00014969235, 0.020438155, 0.004563617, 0.012944326)\n",
      "decoder loss ratio: 0.000312, decoder SINDy loss  ratio: 0.291645\n",
      "Epoch 985\n",
      "   training loss 0.0001269747590413317, (0.000126483, 0.016782133, 0.0036247221, 0.012927804)\n",
      "   validation loss 0.00023676837736275047, (0.00023618413, 0.01987416, 0.004549616, 0.012927804)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.290750\n",
      "Epoch 986\n",
      "   training loss 5.4316224122885615e-05, (5.382239e-05, 0.018070469, 0.0036447654, 0.012935493)\n",
      "   validation loss 0.0001514496689196676, (0.00015086427, 0.020511057, 0.004560412, 0.012935493)\n",
      "decoder loss ratio: 0.000315, decoder SINDy loss  ratio: 0.291440\n",
      "Epoch 987\n",
      "   training loss 0.00013806599599774927, (0.00013757459, 0.016767146, 0.0036212625, 0.012927645)\n",
      "   validation loss 0.00024913609377108514, (0.00024855172, 0.019950036, 0.0045509813, 0.012927645)\n",
      "decoder loss ratio: 0.000519, decoder SINDy loss  ratio: 0.290837\n",
      "Epoch 988\n",
      "   training loss 5.2274652261985466e-05, (5.178037e-05, 0.018139344, 0.00364841, 0.012943835)\n",
      "   validation loss 0.00014867537538520992, (0.00014808933, 0.020612031, 0.004566076, 0.012943835)\n",
      "decoder loss ratio: 0.000309, decoder SINDy loss  ratio: 0.291802\n",
      "Epoch 989\n",
      "   training loss 0.00012423211592249572, (0.00012374064, 0.016890883, 0.003621913, 0.012928241)\n",
      "   validation loss 0.00023396109463647008, (0.00023337641, 0.020094523, 0.0045539993, 0.012928241)\n",
      "decoder loss ratio: 0.000487, decoder SINDy loss  ratio: 0.291030\n",
      "Epoch 990\n",
      "   training loss 5.304884325596504e-05, (5.255524e-05, 0.018109523, 0.0036420217, 0.012940438)\n",
      "   validation loss 0.00015124342462513596, (0.00015065742, 0.020710249, 0.004565994, 0.012940438)\n",
      "decoder loss ratio: 0.000314, decoder SINDy loss  ratio: 0.291797\n",
      "Epoch 991\n",
      "   training loss 0.00014479845413006842, (0.00014430685, 0.016815243, 0.003621994, 0.01294169)\n",
      "   validation loss 0.0002548423071857542, (0.00025425717, 0.020147257, 0.004557065, 0.01294169)\n",
      "decoder loss ratio: 0.000530, decoder SINDy loss  ratio: 0.291226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 992\n",
      "   training loss 5.362470983527601e-05, (5.313055e-05, 0.01824542, 0.003648533, 0.012930961)\n",
      "   validation loss 0.00015115426504053175, (0.00015056762, 0.02084017, 0.0045733107, 0.012930961)\n",
      "decoder loss ratio: 0.000314, decoder SINDy loss  ratio: 0.292264\n",
      "Epoch 993\n",
      "   training loss 0.00013625595602206886, (0.00013576451, 0.016986804, 0.0036220793, 0.0129239485)\n",
      "   validation loss 0.0002505746961105615, (0.00024998933, 0.020325983, 0.0045610387, 0.0129239485)\n",
      "decoder loss ratio: 0.000522, decoder SINDy loss  ratio: 0.291480\n",
      "Epoch 994\n",
      "   training loss 5.381904702517204e-05, (5.3325846e-05, 0.018120186, 0.003638529, 0.012934969)\n",
      "   validation loss 0.00015239068306982517, (0.00015180402, 0.020890595, 0.0045731496, 0.012934969)\n",
      "decoder loss ratio: 0.000317, decoder SINDy loss  ratio: 0.292254\n",
      "Epoch 995\n",
      "   training loss 0.0001536383351776749, (0.00015314693, 0.016867, 0.0036224648, 0.012915807)\n",
      "   validation loss 0.00026438714121468365, (0.00026380143, 0.020347528, 0.0045655267, 0.012915807)\n",
      "decoder loss ratio: 0.000550, decoder SINDy loss  ratio: 0.291767\n",
      "Epoch 996\n",
      "   training loss 5.3340685553848743e-05, (5.2846408e-05, 0.01828321, 0.0036486536, 0.012941527)\n",
      "   validation loss 0.00015133351553231478, (0.0001507459, 0.021025384, 0.0045821657, 0.012941527)\n",
      "decoder loss ratio: 0.000314, decoder SINDy loss  ratio: 0.292830\n",
      "Epoch 997\n",
      "   training loss 0.00013836573634762317, (0.00013787406, 0.017061787, 0.003623844, 0.01292876)\n",
      "   validation loss 0.00025219976669177413, (0.0002516135, 0.020528164, 0.0045699957, 0.01292876)\n",
      "decoder loss ratio: 0.000525, decoder SINDy loss  ratio: 0.292052\n",
      "Epoch 998\n",
      "   training loss 5.689851241186261e-05, (5.6405544e-05, 0.018137602, 0.003636282, 0.012934061)\n",
      "   validation loss 0.00015640557103324682, (0.00015581815, 0.021071894, 0.0045808027, 0.012934061)\n",
      "decoder loss ratio: 0.000325, decoder SINDy loss  ratio: 0.292743\n",
      "Epoch 999\n",
      "   training loss 0.0001677456748438999, (0.0001672539, 0.016889604, 0.0036258008, 0.012920935)\n",
      "   validation loss 0.00027719198260456324, (0.0002766052, 0.020517848, 0.004575777, 0.012920935)\n",
      "decoder loss ratio: 0.000577, decoder SINDy loss  ratio: 0.292422\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 5.8271598391002044e-05, (5.7921432e-05, 0.01891615, 0.0035016676, 0.013943195)\n",
      "   validation loss 0.00019288997282274067, (0.0001924469, 0.021623444, 0.0044307555, 0.013943195)\n",
      "decoder loss ratio: 0.000401, decoder SINDy loss  ratio: 0.283154\n",
      "Epoch 1\n",
      "   training loss 5.1247177907498553e-05, (5.0898627e-05, 0.018923419, 0.0034854952, 0.0139484145)\n",
      "   validation loss 0.00017473170009907335, (0.00017428889, 0.022077218, 0.0044280784, 0.0139484145)\n",
      "decoder loss ratio: 0.000364, decoder SINDy loss  ratio: 0.282983\n",
      "Epoch 2\n",
      "   training loss 0.00010295767424395308, (0.000102607446, 0.018839223, 0.00350226, 0.013948615)\n",
      "   validation loss 0.00021846313029527664, (0.00021801758, 0.022182694, 0.004455467, 0.013948615)\n",
      "decoder loss ratio: 0.000455, decoder SINDy loss  ratio: 0.284733\n",
      "Epoch 3\n",
      "   training loss 0.00010893295984715223, (0.00010858536, 0.017773682, 0.003476023, 0.013961289)\n",
      "   validation loss 0.00020183154265396297, (0.00020138914, 0.021462804, 0.0044241077, 0.013961289)\n",
      "decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.282729\n",
      "Epoch 4\n",
      "   training loss 3.445298716542311e-05, (3.410438e-05, 0.019040497, 0.00348606, 0.013960415)\n",
      "   validation loss 0.00014084480062592775, (0.00014040084, 0.022045434, 0.0044396557, 0.013960415)\n",
      "decoder loss ratio: 0.000293, decoder SINDy loss  ratio: 0.283723\n",
      "Epoch 5\n",
      "   training loss 6.153082358650863e-05, (6.1181454e-05, 0.018763185, 0.003493676, 0.013954652)\n",
      "   validation loss 0.0001829850662034005, (0.00018254126, 0.022124069, 0.004438021, 0.013954652)\n",
      "decoder loss ratio: 0.000381, decoder SINDy loss  ratio: 0.283618\n",
      "Epoch 6\n",
      "   training loss 0.00010514893074287102, (0.000104801205, 0.018071271, 0.0034772183, 0.013967197)\n",
      "   validation loss 0.00020895584020763636, (0.00020851307, 0.021715373, 0.004427783, 0.013967197)\n",
      "decoder loss ratio: 0.000435, decoder SINDy loss  ratio: 0.282964\n",
      "Epoch 7\n",
      "   training loss 4.421110133989714e-05, (4.386274e-05, 0.019070437, 0.003483621, 0.013961613)\n",
      "   validation loss 0.00016200586105696857, (0.00016156345, 0.022074716, 0.0044241115, 0.013961613)\n",
      "decoder loss ratio: 0.000337, decoder SINDy loss  ratio: 0.282730\n",
      "Epoch 8\n",
      "   training loss 7.091912993928418e-05, (7.057105e-05, 0.018630309, 0.0034807858, 0.013955481)\n",
      "   validation loss 0.000195316577446647, (0.00019487439, 0.022152634, 0.004421943, 0.013955481)\n",
      "decoder loss ratio: 0.000407, decoder SINDy loss  ratio: 0.282591\n",
      "Epoch 9\n",
      "   training loss 0.0001404143258696422, (0.00014006623, 0.018073188, 0.0034810323, 0.013966312)\n",
      "   validation loss 0.0002593389363028109, (0.0002588957, 0.021789376, 0.004432182, 0.013966312)\n",
      "decoder loss ratio: 0.000540, decoder SINDy loss  ratio: 0.283245\n",
      "Epoch 10\n",
      "   training loss 5.037008668296039e-05, (5.0021412e-05, 0.019319395, 0.0034867323, 0.013965638)\n",
      "   validation loss 0.00017155312525574118, (0.00017111069, 0.022265973, 0.004424389, 0.013965638)\n",
      "decoder loss ratio: 0.000357, decoder SINDy loss  ratio: 0.282747\n",
      "Epoch 11\n",
      "   training loss 6.889123324071988e-05, (6.854274e-05, 0.01878934, 0.0034849977, 0.013963297)\n",
      "   validation loss 0.00019514450104907155, (0.00019470157, 0.022277467, 0.00442929, 0.013963297)\n",
      "decoder loss ratio: 0.000406, decoder SINDy loss  ratio: 0.283060\n",
      "Epoch 12\n",
      "   training loss 0.00012546432844828814, (0.00012511699, 0.018192602, 0.0034734407, 0.01396903)\n",
      "   validation loss 0.00026149326004087925, (0.0002610501, 0.022029081, 0.004431693, 0.01396903)\n",
      "decoder loss ratio: 0.000545, decoder SINDy loss  ratio: 0.283214\n",
      "Epoch 13\n",
      "   training loss 5.3485237003769726e-05, (5.3138123e-05, 0.01901996, 0.0034711312, 0.0139634395)\n",
      "   validation loss 0.0001723487803246826, (0.00017190777, 0.022231918, 0.004410136, 0.0139634395)\n",
      "decoder loss ratio: 0.000359, decoder SINDy loss  ratio: 0.281836\n",
      "Epoch 14\n",
      "   training loss 7.332800305448472e-05, (7.2982e-05, 0.018486539, 0.0034600194, 0.013963871)\n",
      "   validation loss 0.00021502090385183692, (0.00021458005, 0.02224145, 0.0044084527, 0.013963871)\n",
      "decoder loss ratio: 0.000448, decoder SINDy loss  ratio: 0.281729\n",
      "Epoch 15\n",
      "   training loss 0.0001486439723521471, (0.0001482965, 0.018326106, 0.0034746644, 0.013985849)\n",
      "   validation loss 0.00028653666959144175, (0.0002860937, 0.021915441, 0.0044297334, 0.013985849)\n",
      "decoder loss ratio: 0.000597, decoder SINDy loss  ratio: 0.283089\n",
      "Epoch 16\n",
      "   training loss 4.100231672055088e-05, (4.065585e-05, 0.019571736, 0.0034646555, 0.013983111)\n",
      "   validation loss 0.00017261321772821248, (0.00017217208, 0.022389928, 0.0044114683, 0.013983111)\n",
      "decoder loss ratio: 0.000359, decoder SINDy loss  ratio: 0.281922\n",
      "Epoch 17\n",
      "   training loss 5.715366205549799e-05, (5.6805897e-05, 0.0190672, 0.0034776607, 0.013977089)\n",
      "   validation loss 0.00017749132530298084, (0.00017704882, 0.022458194, 0.0044250805, 0.013977089)\n",
      "decoder loss ratio: 0.000369, decoder SINDy loss  ratio: 0.282791\n",
      "Epoch 18\n",
      "   training loss 8.707481902092695e-05, (8.672688e-05, 0.018622639, 0.0034793804, 0.013966294)\n",
      "   validation loss 0.0001977122446987778, (0.00019727016, 0.022191696, 0.0044208313, 0.013966294)\n",
      "decoder loss ratio: 0.000412, decoder SINDy loss  ratio: 0.282520\n",
      "Epoch 19\n",
      "   training loss 6.257935456233099e-05, (6.223315e-05, 0.018624518, 0.003462044, 0.013973451)\n",
      "   validation loss 0.00020104690338484943, (0.00020060438, 0.022187468, 0.004425257, 0.013973451)\n",
      "decoder loss ratio: 0.000418, decoder SINDy loss  ratio: 0.282803\n",
      "Epoch 20\n",
      "   training loss 0.00012988409434910864, (0.0001295365, 0.018744744, 0.0034759482, 0.013986563)\n",
      "   validation loss 0.000285743415588513, (0.00028529894, 0.022231078, 0.004444734, 0.013986563)\n",
      "decoder loss ratio: 0.000595, decoder SINDy loss  ratio: 0.284047\n",
      "Epoch 21\n",
      "   training loss 4.465824531507678e-05, (4.4307286e-05, 0.019786814, 0.0035095932, 0.013982894)\n",
      "   validation loss 0.0001706277544144541, (0.00017018303, 0.022542061, 0.0044471677, 0.013982894)\n",
      "decoder loss ratio: 0.000355, decoder SINDy loss  ratio: 0.284203\n",
      "Epoch 22\n",
      "   training loss 8.519348921254277e-05, (8.484361e-05, 0.019772701, 0.0034988108, 0.013977196)\n",
      "   validation loss 0.00027932561351917684, (0.00027888254, 0.022693254, 0.00443091, 0.013977196)\n",
      "decoder loss ratio: 0.000582, decoder SINDy loss  ratio: 0.283164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "   training loss 0.00012722449901048094, (0.00012687413, 0.019493781, 0.003503655, 0.0140099935)\n",
      "   validation loss 0.00024971223319880664, (0.00024926683, 0.022251332, 0.004454082, 0.0140099935)\n",
      "decoder loss ratio: 0.000520, decoder SINDy loss  ratio: 0.284645\n",
      "Epoch 24\n",
      "   training loss 6.472035602200776e-05, (6.437367e-05, 0.018194681, 0.0034668325, 0.014003969)\n",
      "   validation loss 0.00016672993660904467, (0.00016628794, 0.021519452, 0.004419954, 0.014003969)\n",
      "decoder loss ratio: 0.000347, decoder SINDy loss  ratio: 0.282464\n",
      "Epoch 25\n",
      "   training loss 3.757966260309331e-05, (3.7233207e-05, 0.018912062, 0.0034645717, 0.013986602)\n",
      "   validation loss 0.00014077327796258032, (0.00014033279, 0.021986887, 0.004404853, 0.013986602)\n",
      "decoder loss ratio: 0.000293, decoder SINDy loss  ratio: 0.281499\n",
      "Epoch 26\n",
      "   training loss 7.541706872871146e-05, (7.506898e-05, 0.018720757, 0.0034808842, 0.013973369)\n",
      "   validation loss 0.00017577459220774472, (0.00017533134, 0.022181489, 0.0044325152, 0.013973369)\n",
      "decoder loss ratio: 0.000366, decoder SINDy loss  ratio: 0.283267\n",
      "Epoch 27\n",
      "   training loss 6.061741805751808e-05, (6.026964e-05, 0.01888307, 0.003477806, 0.013967955)\n",
      "   validation loss 0.00017236292478628457, (0.0001719198, 0.022341717, 0.004431195, 0.013967955)\n",
      "decoder loss ratio: 0.000359, decoder SINDy loss  ratio: 0.283182\n",
      "Epoch 28\n",
      "   training loss 0.00011668348452076316, (0.00011633553, 0.018691042, 0.0034795855, 0.013976076)\n",
      "   validation loss 0.0002617167483549565, (0.00026127178, 0.022412807, 0.004449583, 0.013976076)\n",
      "decoder loss ratio: 0.000545, decoder SINDy loss  ratio: 0.284357\n",
      "Epoch 29\n",
      "   training loss 0.00016843530465848744, (0.00016808446, 0.018944552, 0.0035084542, 0.013986857)\n",
      "   validation loss 0.00032384091173298657, (0.00032339344, 0.022601876, 0.0044745845, 0.013986857)\n",
      "decoder loss ratio: 0.000675, decoder SINDy loss  ratio: 0.285955\n",
      "Epoch 30\n",
      "   training loss 6.099040911067277e-05, (6.0634804e-05, 0.020617662, 0.0035560513, 0.013994419)\n",
      "   validation loss 0.00021370222384575754, (0.00021325343, 0.023140019, 0.0044879094, 0.013994419)\n",
      "decoder loss ratio: 0.000445, decoder SINDy loss  ratio: 0.286807\n",
      "Epoch 31\n",
      "   training loss 0.00010075135651277378, (0.000100397956, 0.02040573, 0.0035339752, 0.014026549)\n",
      "   validation loss 0.00026193089433945715, (0.00026148383, 0.023037411, 0.004470589, 0.014026549)\n",
      "decoder loss ratio: 0.000546, decoder SINDy loss  ratio: 0.285700\n",
      "Epoch 32\n",
      "   training loss 0.00022992426238488406, (0.0002295737, 0.018107032, 0.0035056286, 0.014025793)\n",
      "   validation loss 0.00029664189787581563, (0.0002961997, 0.021741036, 0.0044220844, 0.014025793)\n",
      "decoder loss ratio: 0.000618, decoder SINDy loss  ratio: 0.282600\n",
      "Epoch 33\n",
      "   training loss 0.00011516303493408486, (0.00011480837, 0.020068267, 0.0035466792, 0.01402736)\n",
      "   validation loss 0.0002191276871599257, (0.00021868212, 0.022874227, 0.004455671, 0.01402736)\n",
      "decoder loss ratio: 0.000456, decoder SINDy loss  ratio: 0.284746\n",
      "Epoch 34\n",
      "   training loss 0.00019087400869466364, (0.00019051883, 0.019471029, 0.0035518669, 0.013986571)\n",
      "   validation loss 0.00027587247313931584, (0.00027542745, 0.022541652, 0.004450171, 0.013986571)\n",
      "decoder loss ratio: 0.000575, decoder SINDy loss  ratio: 0.284395\n",
      "Epoch 35\n",
      "   training loss 6.005966497468762e-05, (5.9705384e-05, 0.019813301, 0.0035428242, 0.013981347)\n",
      "   validation loss 0.00015493387763854116, (0.0001544882, 0.0227357, 0.0044567934, 0.013981347)\n",
      "decoder loss ratio: 0.000322, decoder SINDy loss  ratio: 0.284818\n",
      "Epoch 36\n",
      "   training loss 0.0001533277827547863, (0.00015297477, 0.018992787, 0.0035301717, 0.013960602)\n",
      "   validation loss 0.0002508654724806547, (0.0002504211, 0.02227724, 0.004443773, 0.013960602)\n",
      "decoder loss ratio: 0.000522, decoder SINDy loss  ratio: 0.283986\n",
      "Epoch 37\n",
      "   training loss 6.051171658327803e-05, (6.0158258e-05, 0.019732306, 0.0035345722, 0.013964563)\n",
      "   validation loss 0.0001625563600100577, (0.00016211063, 0.022719622, 0.0044572167, 0.013964563)\n",
      "decoder loss ratio: 0.000338, decoder SINDy loss  ratio: 0.284845\n",
      "Epoch 38\n",
      "   training loss 0.00018624274525791407, (0.00018589084, 0.018740553, 0.003519117, 0.013954884)\n",
      "   validation loss 0.00029258077847771347, (0.00029213648, 0.022193545, 0.004443009, 0.013954884)\n",
      "decoder loss ratio: 0.000609, decoder SINDy loss  ratio: 0.283937\n",
      "Epoch 39\n",
      "   training loss 5.8572502894094214e-05, (5.821811e-05, 0.019793473, 0.0035439446, 0.013967152)\n",
      "   validation loss 0.00015850868658162653, (0.00015806232, 0.022735938, 0.0044635967, 0.013967152)\n",
      "decoder loss ratio: 0.000330, decoder SINDy loss  ratio: 0.285253\n",
      "Epoch 40\n",
      "   training loss 0.00012766268628183752, (0.0001273116, 0.018919656, 0.003510844, 0.013948326)\n",
      "   validation loss 0.00023513889755122364, (0.00023469457, 0.022269333, 0.0044432147, 0.013948326)\n",
      "decoder loss ratio: 0.000490, decoder SINDy loss  ratio: 0.283950\n",
      "Epoch 41\n",
      "   training loss 5.7469107559882104e-05, (5.7118057e-05, 0.019548317, 0.0035105136, 0.013949217)\n",
      "   validation loss 0.000160811425303109, (0.00016036665, 0.022670042, 0.0044478644, 0.013949217)\n",
      "decoder loss ratio: 0.000335, decoder SINDy loss  ratio: 0.284247\n",
      "Epoch 42\n",
      "   training loss 0.00017857729108072817, (0.0001782267, 0.018541807, 0.003505778, 0.013947485)\n",
      "   validation loss 0.0002803634852170944, (0.00027991887, 0.022107359, 0.004446195, 0.013947485)\n",
      "decoder loss ratio: 0.000584, decoder SINDy loss  ratio: 0.284141\n",
      "Epoch 43\n",
      "   training loss 6.76364652463235e-05, (6.728273e-05, 0.020050144, 0.0035373596, 0.013969951)\n",
      "   validation loss 0.00016727361071389169, (0.00016682777, 0.0229247, 0.004458395, 0.013969951)\n",
      "decoder loss ratio: 0.000348, decoder SINDy loss  ratio: 0.284920\n",
      "Epoch 44\n",
      "   training loss 0.0001221384882228449, (0.000121788034, 0.019180218, 0.0035045668, 0.013949845)\n",
      "   validation loss 0.0002380754885962233, (0.0002376312, 0.022504479, 0.004442789, 0.013949845)\n",
      "decoder loss ratio: 0.000496, decoder SINDy loss  ratio: 0.283923\n",
      "Epoch 45\n",
      "   training loss 6.020056389388628e-05, (5.9851936e-05, 0.019507391, 0.0034862584, 0.013944311)\n",
      "   validation loss 0.00016078838962130249, (0.00016034467, 0.022790844, 0.004437128, 0.013944311)\n",
      "decoder loss ratio: 0.000335, decoder SINDy loss  ratio: 0.283561\n",
      "Epoch 46\n",
      "   training loss 0.00019284049631096423, (0.0001924906, 0.018468102, 0.0034990269, 0.013947308)\n",
      "   validation loss 0.0002947514585684985, (0.00029430646, 0.022164298, 0.0044498886, 0.013947308)\n",
      "decoder loss ratio: 0.000614, decoder SINDy loss  ratio: 0.284377\n",
      "Epoch 47\n",
      "   training loss 6.946821667952463e-05, (6.9115e-05, 0.020171816, 0.003532153, 0.013970752)\n",
      "   validation loss 0.00016488345863763243, (0.00016443762, 0.023101348, 0.004458383, 0.013970752)\n",
      "decoder loss ratio: 0.000343, decoder SINDy loss  ratio: 0.284920\n",
      "Epoch 48\n",
      "   training loss 0.0001105962073779665, (0.000110245965, 0.019384885, 0.0035024593, 0.0139502855)\n",
      "   validation loss 0.00023021850211080164, (0.00022977387, 0.022747906, 0.0044463626, 0.0139502855)\n",
      "decoder loss ratio: 0.000479, decoder SINDy loss  ratio: 0.284151\n",
      "Epoch 49\n",
      "   training loss 5.333971785148606e-05, (5.2992094e-05, 0.019484667, 0.0034762318, 0.013941429)\n",
      "   validation loss 0.00015155455912463367, (0.00015111094, 0.022914771, 0.004436132, 0.013941429)\n",
      "decoder loss ratio: 0.000315, decoder SINDy loss  ratio: 0.283498\n",
      "Epoch 50\n",
      "   training loss 0.00017580614075995982, (0.00017545649, 0.018431742, 0.0034965533, 0.013946603)\n",
      "   validation loss 0.000277280923910439, (0.0002768353, 0.022235705, 0.0044564195, 0.013946603)\n",
      "decoder loss ratio: 0.000578, decoder SINDy loss  ratio: 0.284794\n",
      "Epoch 51\n",
      "   training loss 6.973428389756009e-05, (6.938167e-05, 0.020262014, 0.0035261805, 0.013969355)\n",
      "   validation loss 0.00016923630028031766, (0.00016879043, 0.023263015, 0.0044586626, 0.013969355)\n",
      "decoder loss ratio: 0.000352, decoder SINDy loss  ratio: 0.284938\n",
      "Epoch 52\n",
      "   training loss 0.00011485905997687951, (0.00011450873, 0.01945298, 0.0035032963, 0.013951306)\n",
      "   validation loss 0.00023571049678139389, (0.00023526522, 0.022906361, 0.004452784, 0.013951306)\n",
      "decoder loss ratio: 0.000491, decoder SINDy loss  ratio: 0.284562\n",
      "Epoch 53\n",
      "   training loss 5.41731424164027e-05, (5.3825504e-05, 0.019586826, 0.0034763764, 0.01394182)\n",
      "   validation loss 0.00015550745592918247, (0.00015506338, 0.02307372, 0.0044408008, 0.01394182)\n",
      "decoder loss ratio: 0.000323, decoder SINDy loss  ratio: 0.283796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54\n",
      "   training loss 0.00017662844038568437, (0.00017627845, 0.018549202, 0.0034998353, 0.013945859)\n",
      "   validation loss 0.0002749658888205886, (0.00027451935, 0.022388533, 0.0044654314, 0.013945859)\n",
      "decoder loss ratio: 0.000573, decoder SINDy loss  ratio: 0.285370\n",
      "Epoch 55\n",
      "   training loss 7.092544547049329e-05, (7.057334e-05, 0.02025237, 0.003521026, 0.01396301)\n",
      "   validation loss 0.00017864047549664974, (0.00017819421, 0.023351964, 0.00446267, 0.01396301)\n",
      "decoder loss ratio: 0.000372, decoder SINDy loss  ratio: 0.285194\n",
      "Epoch 56\n",
      "   training loss 0.00012340852117631584, (0.00012305788, 0.019421773, 0.003506431, 0.013948353)\n",
      "   validation loss 0.00023382359358947724, (0.00023337768, 0.022973314, 0.004459184, 0.013948353)\n",
      "decoder loss ratio: 0.000487, decoder SINDy loss  ratio: 0.284971\n",
      "Epoch 57\n",
      "   training loss 5.962340219411999e-05, (5.927505e-05, 0.019737776, 0.0034835138, 0.013939993)\n",
      "   validation loss 0.00016524949751328677, (0.00016480456, 0.0232226, 0.00444943, 0.013939993)\n",
      "decoder loss ratio: 0.000344, decoder SINDy loss  ratio: 0.284348\n",
      "Epoch 58\n",
      "   training loss 0.00016892023268155754, (0.00016856965, 0.018738898, 0.00350589, 0.013941669)\n",
      "   validation loss 0.00026011490263044834, (0.00025966763, 0.022576708, 0.004472586, 0.013941669)\n",
      "decoder loss ratio: 0.000542, decoder SINDy loss  ratio: 0.285827\n",
      "Epoch 59\n",
      "   training loss 7.253189687617123e-05, (7.2180206e-05, 0.020230094, 0.0035168915, 0.013951737)\n",
      "   validation loss 0.00018925838230643421, (0.00018881157, 0.023420673, 0.004468101, 0.013951737)\n",
      "decoder loss ratio: 0.000394, decoder SINDy loss  ratio: 0.285541\n",
      "Epoch 60\n",
      "   training loss 0.00013022882922086865, (0.00012987769, 0.019356461, 0.0035113501, 0.013941562)\n",
      "   validation loss 0.0002297642786288634, (0.00022931761, 0.022997683, 0.004466713, 0.013941562)\n",
      "decoder loss ratio: 0.000478, decoder SINDy loss  ratio: 0.285452\n",
      "Epoch 61\n",
      "   training loss 6.733933696523309e-05, (6.6990055e-05, 0.01992453, 0.0034928569, 0.013936045)\n",
      "   validation loss 0.00017926443251781166, (0.00017881858, 0.023366217, 0.0044585243, 0.013936045)\n",
      "decoder loss ratio: 0.000373, decoder SINDy loss  ratio: 0.284929\n",
      "Epoch 62\n",
      "   training loss 0.00015178286412265152, (0.00015143154, 0.01899317, 0.0035133176, 0.013935147)\n",
      "   validation loss 0.0002368935674894601, (0.0002364459, 0.022788137, 0.0044765775, 0.013935147)\n",
      "decoder loss ratio: 0.000493, decoder SINDy loss  ratio: 0.286082\n",
      "Epoch 63\n",
      "   training loss 7.403897325275466e-05, (7.3687996e-05, 0.02021153, 0.003509752, 0.013937635)\n",
      "   validation loss 0.00019347708439454436, (0.00019303005, 0.02347713, 0.0044704103, 0.013937635)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.285688\n",
      "Epoch 64\n",
      "   training loss 0.00013567082351073623, (0.00013531891, 0.019311396, 0.0035191225, 0.013932703)\n",
      "   validation loss 0.0002248950768262148, (0.00022444747, 0.023016265, 0.004476057, 0.013932703)\n",
      "decoder loss ratio: 0.000468, decoder SINDy loss  ratio: 0.286049\n",
      "Epoch 65\n",
      "   training loss 7.441174238920212e-05, (7.406141e-05, 0.020155188, 0.0035033012, 0.013931033)\n",
      "   validation loss 0.00019339090795256197, (0.00019294424, 0.023503311, 0.0044667562, 0.013931033)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.285455\n",
      "Epoch 66\n",
      "   training loss 0.00013007441884838045, (0.00012972215, 0.019330073, 0.003522695, 0.013928697)\n",
      "   validation loss 0.00021597759041469544, (0.00021552964, 0.02303518, 0.0044795508, 0.013928697)\n",
      "decoder loss ratio: 0.000450, decoder SINDy loss  ratio: 0.286272\n",
      "Epoch 67\n",
      "   training loss 7.107044075382873e-05, (7.07201e-05, 0.020200195, 0.0035033622, 0.013924834)\n",
      "   validation loss 0.00018789747264236212, (0.00018745066, 0.02352637, 0.00446818, 0.013924834)\n",
      "decoder loss ratio: 0.000391, decoder SINDy loss  ratio: 0.285546\n",
      "Epoch 68\n",
      "   training loss 0.00013223913265392184, (0.00013188634, 0.0193284, 0.003527959, 0.013923371)\n",
      "   validation loss 0.00021510603255592287, (0.00021465767, 0.023045024, 0.004483639, 0.013923371)\n",
      "decoder loss ratio: 0.000448, decoder SINDy loss  ratio: 0.286534\n",
      "Epoch 69\n",
      "   training loss 7.709076453465968e-05, (7.6739896e-05, 0.020345496, 0.0035087126, 0.0139230015)\n",
      "   validation loss 0.00019787919882219285, (0.00019743206, 0.023609025, 0.0044713668, 0.0139230015)\n",
      "decoder loss ratio: 0.000412, decoder SINDy loss  ratio: 0.285749\n",
      "Epoch 70\n",
      "   training loss 0.00011881044338224456, (0.00011845721, 0.01956776, 0.00353231, 0.013922277)\n",
      "   validation loss 0.00020802968356292695, (0.0002075812, 0.023210559, 0.004484859, 0.013922277)\n",
      "decoder loss ratio: 0.000433, decoder SINDy loss  ratio: 0.286612\n",
      "Epoch 71\n",
      "   training loss 6.951808609301224e-05, (6.916756e-05, 0.02029266, 0.0035052863, 0.013916852)\n",
      "   validation loss 0.00018759373051580042, (0.00018714691, 0.023604851, 0.004468233, 0.013916852)\n",
      "decoder loss ratio: 0.000390, decoder SINDy loss  ratio: 0.285549\n",
      "Epoch 72\n",
      "   training loss 0.00011646653729258105, (0.00011611315, 0.019473398, 0.0035338928, 0.0139164515)\n",
      "   validation loss 0.0002016459038713947, (0.00020119722, 0.023142267, 0.0044868006, 0.0139164515)\n",
      "decoder loss ratio: 0.000420, decoder SINDy loss  ratio: 0.286736\n",
      "Epoch 73\n",
      "   training loss 7.412786362692714e-05, (7.377738e-05, 0.020396551, 0.0035048653, 0.013912594)\n",
      "   validation loss 0.00018916100088972598, (0.00018871395, 0.023664042, 0.0044704485, 0.013912594)\n",
      "decoder loss ratio: 0.000394, decoder SINDy loss  ratio: 0.285691\n",
      "Epoch 74\n",
      "   training loss 0.0001191092815133743, (0.00011875544, 0.019563092, 0.0035384756, 0.013914552)\n",
      "   validation loss 0.00020582362776622176, (0.00020537457, 0.023222085, 0.0044906475, 0.013914552)\n",
      "decoder loss ratio: 0.000428, decoder SINDy loss  ratio: 0.286982\n",
      "Epoch 75\n",
      "   training loss 7.47613376006484e-05, (7.4410375e-05, 0.020463375, 0.0035096584, 0.013911307)\n",
      "   validation loss 0.00019454014545772225, (0.00019409292, 0.02370355, 0.0044722892, 0.013911307)\n",
      "decoder loss ratio: 0.000405, decoder SINDy loss  ratio: 0.285808\n",
      "Epoch 76\n",
      "   training loss 0.00010390242823632434, (0.00010354856, 0.019677611, 0.0035386288, 0.013911539)\n",
      "   validation loss 0.0001944506075233221, (0.0001940016, 0.023287084, 0.004490135, 0.013911539)\n",
      "decoder loss ratio: 0.000405, decoder SINDy loss  ratio: 0.286949\n",
      "Epoch 77\n",
      "   training loss 6.942015897948295e-05, (6.906975e-05, 0.020423774, 0.003504118, 0.013905122)\n",
      "   validation loss 0.00018377161177340895, (0.0001833247, 0.023700668, 0.0044691665, 0.013905122)\n",
      "decoder loss ratio: 0.000382, decoder SINDy loss  ratio: 0.285609\n",
      "Epoch 78\n",
      "   training loss 0.00010879034380195662, (0.000108436376, 0.01954141, 0.003539672, 0.013906532)\n",
      "   validation loss 0.00019433347915764898, (0.00019388423, 0.023198344, 0.0044924277, 0.013906532)\n",
      "decoder loss ratio: 0.000404, decoder SINDy loss  ratio: 0.287095\n",
      "Epoch 79\n",
      "   training loss 7.797683792887256e-05, (7.762617e-05, 0.020571863, 0.0035066633, 0.013903804)\n",
      "   validation loss 0.00019265648734290153, (0.0001922092, 0.023770303, 0.0044728788, 0.013903804)\n",
      "decoder loss ratio: 0.000401, decoder SINDy loss  ratio: 0.285846\n",
      "Epoch 80\n",
      "   training loss 0.00010424080392112955, (0.00010388656, 0.019729666, 0.0035424526, 0.013906798)\n",
      "   validation loss 0.00019473458814900368, (0.00019428514, 0.023335403, 0.004494548, 0.013906798)\n",
      "decoder loss ratio: 0.000405, decoder SINDy loss  ratio: 0.287231\n",
      "Epoch 81\n",
      "   training loss 7.308106432901695e-05, (7.273027e-05, 0.02056605, 0.003507977, 0.01390194)\n",
      "   validation loss 0.00019129538850393146, (0.00019084824, 0.023778895, 0.0044715526, 0.01390194)\n",
      "decoder loss ratio: 0.000398, decoder SINDy loss  ratio: 0.285761\n",
      "Epoch 82\n",
      "   training loss 9.538732410874218e-05, (9.503334e-05, 0.01968355, 0.0035398193, 0.0139023)\n",
      "   validation loss 0.00018479450955055654, (0.00018434528, 0.023284128, 0.004492316, 0.0139023)\n",
      "decoder loss ratio: 0.000385, decoder SINDy loss  ratio: 0.287088\n",
      "Epoch 83\n",
      "   training loss 7.42461415939033e-05, (7.389586e-05, 0.020578822, 0.0035027578, 0.013897069)\n",
      "   validation loss 0.00018505379557609558, (0.00018460676, 0.023795033, 0.0044703907, 0.013897069)\n",
      "decoder loss ratio: 0.000385, decoder SINDy loss  ratio: 0.285687\n",
      "Epoch 84\n",
      "   training loss 0.00010311545338481665, (0.00010276129, 0.019627323, 0.0035416556, 0.013899703)\n",
      "   validation loss 0.00018976865976583213, (0.00018931914, 0.023257887, 0.0044952184, 0.013899703)\n",
      "decoder loss ratio: 0.000395, decoder SINDy loss  ratio: 0.287274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85\n",
      "   training loss 7.925214595161378e-05, (7.89013e-05, 0.020720981, 0.0035084495, 0.013897465)\n",
      "   validation loss 0.00019543463713489473, (0.00019498722, 0.023853041, 0.0044741947, 0.013897465)\n",
      "decoder loss ratio: 0.000407, decoder SINDy loss  ratio: 0.285930\n",
      "Epoch 86\n",
      "   training loss 9.302052058046684e-05, (9.266648e-05, 0.019780472, 0.0035403748, 0.013899374)\n",
      "   validation loss 0.00018439869745634496, (0.00018394933, 0.023351094, 0.004493578, 0.013899374)\n",
      "decoder loss ratio: 0.000384, decoder SINDy loss  ratio: 0.287169\n",
      "Epoch 87\n",
      "   training loss 7.509413262596354e-05, (7.474366e-05, 0.020679984, 0.003504763, 0.013894804)\n",
      "   validation loss 0.00018925701442640275, (0.00018880994, 0.023854509, 0.004470847, 0.013894804)\n",
      "decoder loss ratio: 0.000394, decoder SINDy loss  ratio: 0.285716\n",
      "Epoch 88\n",
      "   training loss 9.459102875553071e-05, (9.4237184e-05, 0.019665152, 0.003538448, 0.013895712)\n",
      "   validation loss 0.0001822453923523426, (0.00018179612, 0.023263134, 0.004492712, 0.013895712)\n",
      "decoder loss ratio: 0.000379, decoder SINDy loss  ratio: 0.287114\n",
      "Epoch 89\n",
      "   training loss 8.004774281289428e-05, (7.9697245e-05, 0.020764295, 0.003504938, 0.013892636)\n",
      "   validation loss 0.00019165223056916147, (0.0001912049, 0.023893014, 0.0044732476, 0.013892636)\n",
      "decoder loss ratio: 0.000399, decoder SINDy loss  ratio: 0.285870\n",
      "Epoch 90\n",
      "   training loss 9.621636854717508e-05, (9.586252e-05, 0.019710781, 0.0035384875, 0.0138949035)\n",
      "   validation loss 0.00018454222299624234, (0.00018409286, 0.023300538, 0.0044935592, 0.0138949035)\n",
      "decoder loss ratio: 0.000384, decoder SINDy loss  ratio: 0.287168\n",
      "Epoch 91\n",
      "   training loss 8.031193283386528e-05, (7.9961144e-05, 0.020833373, 0.0035078696, 0.013892753)\n",
      "   validation loss 0.0001957165077328682, (0.00019526905, 0.023929747, 0.0044745277, 0.013892753)\n",
      "decoder loss ratio: 0.000407, decoder SINDy loss  ratio: 0.285951\n",
      "Epoch 92\n",
      "   training loss 9.143350325757638e-05, (9.107994e-05, 0.019732237, 0.0035356372, 0.013893318)\n",
      "   validation loss 0.00018031640502158552, (0.00017986729, 0.023300948, 0.004491109, 0.013893318)\n",
      "decoder loss ratio: 0.000375, decoder SINDy loss  ratio: 0.287011\n",
      "Epoch 93\n",
      "   training loss 8.109093323582783e-05, (8.0740356e-05, 0.020842822, 0.0035057901, 0.013890793)\n",
      "   validation loss 0.00019380517187528312, (0.00019335776, 0.023950296, 0.0044741295, 0.013890793)\n",
      "decoder loss ratio: 0.000403, decoder SINDy loss  ratio: 0.285926\n",
      "Epoch 94\n",
      "   training loss 9.594841685611755e-05, (9.559499e-05, 0.019674303, 0.0035342989, 0.013891611)\n",
      "   validation loss 0.0001825109065975994, (0.00018206179, 0.023265284, 0.0044912295, 0.013891611)\n",
      "decoder loss ratio: 0.000380, decoder SINDy loss  ratio: 0.287019\n",
      "Epoch 95\n",
      "   training loss 8.325412636622787e-05, (8.290314e-05, 0.020937277, 0.0035098186, 0.01389071)\n",
      "   validation loss 0.00019864196656271815, (0.0001981942, 0.023995413, 0.0044776257, 0.01389071)\n",
      "decoder loss ratio: 0.000413, decoder SINDy loss  ratio: 0.286149\n",
      "Epoch 96\n",
      "   training loss 9.316077193943784e-05, (9.28076e-05, 0.019712778, 0.0035317163, 0.013890772)\n",
      "   validation loss 0.000180581962922588, (0.00018013302, 0.023289768, 0.0044894367, 0.013890772)\n",
      "decoder loss ratio: 0.000376, decoder SINDy loss  ratio: 0.286904\n",
      "Epoch 97\n",
      "   training loss 8.405598782701418e-05, (8.3704996e-05, 0.02096378, 0.0035099485, 0.013890238)\n",
      "   validation loss 0.00019947859982494265, (0.00019903076, 0.024028061, 0.0044783647, 0.013890238)\n",
      "decoder loss ratio: 0.000415, decoder SINDy loss  ratio: 0.286197\n",
      "Epoch 98\n",
      "   training loss 9.66624211287126e-05, (9.6309435e-05, 0.019672384, 0.0035298553, 0.0138897775)\n",
      "   validation loss 0.0001822946942411363, (0.00018184578, 0.023269825, 0.0044891285, 0.0138897775)\n",
      "decoder loss ratio: 0.000379, decoder SINDy loss  ratio: 0.286885\n",
      "Epoch 99\n",
      "   training loss 8.422130485996604e-05, (8.386988e-05, 0.021035276, 0.0035142072, 0.0138903875)\n",
      "   validation loss 0.00020203375606797636, (0.00020158554, 0.024070162, 0.0044820667, 0.0138903875)\n",
      "decoder loss ratio: 0.000421, decoder SINDy loss  ratio: 0.286433\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0d66913bb719389121bab79020f7a52c6e05d87274bae621f301af382c19c893"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
