{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRiWtT66EpgK","executionInfo":{"status":"ok","timestamp":1679132149419,"user_tz":-60,"elapsed":40928,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"7abdff3b-1fe0-4e30-a4c8-0db6b7b990e7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UtJhc1fEoHM","executionInfo":{"status":"ok","timestamp":1679132203785,"user_tz":-60,"elapsed":407,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"ad366fbc-59e4-48a7-b8a2-5fc3a422dee3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Github/SindyAutoencoders_project\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"pycharm":{"name":"#%%\n"},"id":"tBTeSgnZDfni","executionInfo":{"status":"ok","timestamp":1679132225232,"user_tz":-60,"elapsed":1949,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["import os\n","import datetime\n","import pandas as pd\n","import numpy as np\n","from robi.example_LV import get_lofka_volterra_data\n","from src.sindy_utils import library_size\n","from src.training import train_network\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"eieoW7yzDfnr"},"source":["# Generate data"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"nN2gnjRMDfnt","executionInfo":{"status":"ok","timestamp":1679132242029,"user_tz":-60,"elapsed":8704,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["# generate training, validation, testing data\n","noise_strength = 1e-6\n","training_data = get_lofka_volterra_data(128, noise_strength=noise_strength)\n","validation_data = get_lofka_volterra_data(20, noise_strength=noise_strength)"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["training_data"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"mdVSNA1iDfnw"}},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"LtUvTVjpDfnx"},"source":["# Set up model and training parameters"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"pycharm":{"name":"#%%\n"},"id":"3yuYFK6RDfny","executionInfo":{"status":"ok","timestamp":1679132250120,"user_tz":-60,"elapsed":803,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}}},"outputs":[],"source":["params = {}\n","\n","params['input_dim'] = 128\n","params['latent_dim'] = 2\n","params['model_order'] = 1\n","params['poly_order'] = 2\n","params['include_sine'] = False\n","params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n","\n","# sequential thresholding parameters\n","params['sequential_thresholding'] = True\n","params['coefficient_threshold'] = 0.1\n","params['threshold_frequency'] = 500\n","params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","params['coefficient_initialization'] = 'constant'\n","\n","# loss function weighting\n","params['loss_weight_decoder'] = 1.0\n","params['loss_weight_sindy_z'] = 1e-4\n","params['loss_weight_sindy_x'] = 1e-4\n","params['loss_weight_sindy_regularization'] = 1e-5\n","\n","params['activation'] = 'sigmoid'\n","params['widths'] = [64,32]\n","\n","# training parameters\n","params['epoch_size'] = training_data['x'].shape[0]\n","params['batch_size'] = 1024\n","params['learning_rate'] = 1e-3\n","\n","params['data_path'] = os.getcwd() + '/'\n","params['print_progress'] = True\n","params['print_frequency'] = 100\n","\n","# training time cutoffs\n","params['max_epochs'] = 5001\n","params['refinement_epochs'] = 1001"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"VSf6uw-aDfnz"},"source":["# Run training experiments"]},{"cell_type":"code","execution_count":9,"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"H9PEhyUeDfn0","executionInfo":{"status":"ok","timestamp":1679144723164,"user_tz":-60,"elapsed":12319081,"user":{"displayName":"Roberta Troilo","userId":"14529775410272755567"}},"outputId":"08be151f-b33d-4491-83cf-a7b1e8d3df53"},"outputs":[{"output_type":"stream","name":"stdout","text":["EXPERIMENT 0\n","TRAINING\n","Epoch 0\n","   training loss 0.044791292399168015, (0.03991676, 47.659744, 0.9918648, 0.93744165)\n","   validation loss 0.045885439962148666, (0.04135255, 44.21105, 1.0241078, 0.93744165)\n","decoder loss ratio: 0.200807, decoder SINDy loss  ratio: 1.033422\n","Epoch 100\n","   training loss 2.1557159925578162e-05, (3.5287035e-06, 0.02589908, 0.009074572, 1.4531093)\n","   validation loss 2.7550062441150658e-05, (7.1992226e-06, 0.041294564, 0.01690291, 1.4531093)\n","decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.017057\n","Epoch 200\n","   training loss 1.6197434888454154e-05, (1.6872351e-06, 0.015480702, 0.0033302717, 1.2629104)\n","   validation loss 2.037580998148769e-05, (5.0682224e-06, 0.020946154, 0.0058386857, 1.2629104)\n","decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.005892\n","Epoch 300\n","   training loss 1.3130711522535421e-05, (1.018874e-06, 0.011609984, 0.002625069, 1.0688332)\n","   validation loss 1.6901427443372086e-05, (3.9893866e-06, 0.017598309, 0.0046387804, 1.0688332)\n","decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.004681\n","Epoch 400\n","   training loss 1.106378113036044e-05, (8.610622e-07, 0.009911091, 0.0020715552, 0.9004454)\n","   validation loss 1.3981383744976483e-05, (2.9244884e-06, 0.016703416, 0.0038209984, 0.9004454)\n","decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.003856\n","Epoch 500\n","   training loss 9.491871423961129e-06, (8.703997e-07, 0.008448271, 0.0016615534, 0.761049)\n","   validation loss 1.196763423649827e-05, (2.4620238e-06, 0.015768286, 0.0031829257, 0.761049)\n","decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.003212\n","THRESHOLDING: 9 active coefficients\n","Epoch 600\n","   training loss 8.456039722659625e-06, (1.0105671e-06, 0.007285257, 0.0014058652, 0.65763605)\n","   validation loss 1.0536536137806252e-05, (2.1543071e-06, 0.015222531, 0.0028361557, 0.65763605)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.002862\n","Epoch 700\n","   training loss 7.92991977505153e-06, (7.498088e-07, 0.0073227566, 0.0013347624, 0.63143593)\n","   validation loss 9.66926381806843e-06, (1.4456791e-06, 0.016367117, 0.00272514, 0.63143593)\n","decoder loss ratio: 0.000007, decoder SINDy loss  ratio: 0.002750\n","Epoch 800\n","   training loss 7.515365723520517e-06, (5.043929e-07, 0.007402043, 0.0012856668, 0.6142202)\n","   validation loss 9.106670404435135e-06, (1.039008e-06, 0.016776776, 0.002477831, 0.6142202)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.002500\n","Epoch 900\n","   training loss 7.325866135943215e-06, (4.4657136e-07, 0.007428501, 0.0012084479, 0.60156)\n","   validation loss 8.852037353790365e-06, (9.607948e-07, 0.016572962, 0.00218346, 0.60156)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.002203\n","Epoch 1000\n","   training loss 7.190017640823498e-06, (4.7416495e-07, 0.0070667285, 0.0011135612, 0.5897824)\n","   validation loss 8.689019523444586e-06, (1.0160052e-06, 0.01582307, 0.0019288391, 0.5897824)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.001946\n","THRESHOLDING: 7 active coefficients\n","Epoch 1100\n","   training loss 7.017184543656185e-06, (5.192453e-07, 0.006502758, 0.0010018833, 0.57474756)\n","   validation loss 8.525488738087006e-06, (1.0970965e-06, 0.015067731, 0.0017414364, 0.57474756)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.001757\n","Epoch 1200\n","   training loss 6.852113074273802e-06, (5.7539336e-07, 0.005872356, 0.0008939179, 0.5600093)\n","   validation loss 8.359578714589588e-06, (1.1720047e-06, 0.014292949, 0.0015818636, 0.5600093)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001596\n","Epoch 1300\n","   training loss 6.69352630211506e-06, (6.2120387e-07, 0.0054131676, 0.000781836, 0.5452822)\n","   validation loss 8.20895547803957e-06, (1.222365e-06, 0.013888504, 0.0014491791, 0.5452822)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001462\n","Epoch 1400\n","   training loss 6.55829171591904e-06, (6.5866004e-07, 0.0051330933, 0.0006715056, 0.53191715)\n","   validation loss 8.069603609328624e-06, (1.2518896e-06, 0.013665742, 0.0013196795, 0.53191715)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001332\n","Epoch 1500\n","   training loss 6.452316483773757e-06, (6.939656e-07, 0.0049698325, 0.00057055894, 0.5204312)\n","   validation loss 7.94249808677705e-06, (1.2757798e-06, 0.013432732, 0.0011913335, 0.5204312)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001202\n","THRESHOLDING: 7 active coefficients\n","Epoch 1600\n","   training loss 6.326433322101366e-06, (6.8419433e-07, 0.0048646834, 0.00048685021, 0.5107086)\n","   validation loss 7.789913070155308e-06, (1.2575397e-06, 0.01318031, 0.0010725702, 0.5107086)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.001082\n","Epoch 1700\n","   training loss 6.3665997913631145e-06, (8.7004327e-07, 0.004489618, 0.00032472785, 0.5015122)\n","   validation loss 7.560789981653215e-06, (1.1890894e-06, 0.0126014855, 0.00096430036, 0.5015122)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000973\n","Epoch 1800\n","   training loss 6.761975328117842e-06, (1.3483188e-06, 0.0042922515, 0.00028850682, 0.49555805)\n","   validation loss 7.66204630053835e-06, (1.4216214e-06, 0.011989273, 0.0008591675, 0.49555805)\n","decoder loss ratio: 0.000007, decoder SINDy loss  ratio: 0.000867\n","Epoch 1900\n","   training loss 5.9122485254192725e-06, (5.840982e-07, 0.004093662, 0.0002545825, 0.48933265)\n","   validation loss 6.9899597292533144e-06, (8.696074e-07, 0.011488875, 0.0007813857, 0.48933265)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000788\n","Epoch 2000\n","   training loss 9.256475095753558e-06, (3.998785e-06, 0.0039217793, 0.00027549703, 0.48379633)\n","   validation loss 9.820762898016255e-06, (3.7426255e-06, 0.011608279, 0.0007934594, 0.48379633)\n","decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000801\n","THRESHOLDING: 6 active coefficients\n","Epoch 2100\n","   training loss 5.556849373533623e-06, (3.778633e-07, 0.0031992665, 0.00015416817, 0.48436427)\n","   validation loss 6.41138649370987e-06, (6.2217475e-07, 0.008878938, 0.00057675, 0.48436427)\n","decoder loss ratio: 0.000003, decoder SINDy loss  ratio: 0.000582\n","Epoch 2200\n","   training loss 5.6243784456455614e-06, (5.3440726e-07, 0.003262354, 0.00014156525, 0.47495794)\n","   validation loss 6.501350071630441e-06, (7.875886e-07, 0.009118602, 0.0005232229, 0.47495794)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000528\n","Epoch 2300\n","   training loss 5.533132480195491e-06, (5.083996e-07, 0.003439651, 0.0001551889, 0.46652493)\n","   validation loss 6.7130918068869505e-06, (1.0703727e-06, 0.0093037095, 0.00047099104, 0.46652493)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.000475\n","Epoch 2400\n","   training loss 5.144050192029681e-06, (1.8019807e-07, 0.003399369, 0.0001246706, 0.46114483)\n","   validation loss 5.971979135210859e-06, (4.1164648e-07, 0.009055682, 0.00043316153, 0.46114483)\n","decoder loss ratio: 0.000002, decoder SINDy loss  ratio: 0.000437\n","Epoch 2500\n","   training loss 5.308660547598265e-06, (3.71869e-07, 0.003714814, 0.00012856227, 0.4552454)\n","   validation loss 6.317317456705496e-06, (8.1479715e-07, 0.009086542, 0.0004141209, 0.4552454)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000418\n","THRESHOLDING: 5 active coefficients\n","Epoch 2600\n","   training loss 5.2542109187925234e-06, (4.340048e-07, 0.0040764846, 0.00016647053, 0.43959108)\n","   validation loss 6.408377885236405e-06, (8.572802e-07, 0.011061793, 0.0004900796, 0.43959108)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000495\n","Epoch 2700\n","   training loss 5.1989973144372925e-06, (4.306109e-07, 0.0040014973, 0.00016743816, 0.43514928)\n","   validation loss 6.348840543068945e-06, (8.5456765e-07, 0.010950605, 0.0004771945, 0.43514928)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000482\n","Epoch 2800\n","   training loss 5.1786746553261764e-06, (4.5354017e-07, 0.003961196, 0.00017757379, 0.43112573)\n","   validation loss 6.3295306063082535e-06, (8.790556e-07, 0.010922809, 0.00046936673, 0.43112573)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000474\n","Epoch 2900\n","   training loss 7.5596881288220175e-06, (2.8214633e-06, 0.004409609, 0.00023843274, 0.42734206)\n","   validation loss 9.076738024305087e-06, (3.5839773e-06, 0.011677176, 0.0005162262, 0.42734206)\n","decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000521\n","Epoch 3000\n","   training loss 5.142148893355625e-06, (4.8758994e-07, 0.004007929, 0.00019634687, 0.42341313)\n","   validation loss 6.270253834372852e-06, (8.7894017e-07, 0.011081605, 0.00049022294, 0.42341313)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000495\n","THRESHOLDING: 4 active coefficients\n","Epoch 3100\n","   training loss 4.668029760068748e-06, (8.9908646e-08, 0.004496648, 0.00015307285, 0.41131487)\n","   validation loss 5.8476189224165864e-06, (3.9738248e-07, 0.012830336, 0.0005405383, 0.41131487)\n","decoder loss ratio: 0.000002, decoder SINDy loss  ratio: 0.000545\n","Epoch 3200\n","   training loss 4.807380264537642e-06, (2.6489784e-07, 0.004279168, 0.00020106402, 0.4094459)\n","   validation loss 6.000268513162155e-06, (5.917083e-07, 0.012583564, 0.00055744837, 0.4094459)\n","decoder loss ratio: 0.000003, decoder SINDy loss  ratio: 0.000563\n","Epoch 3300\n","   training loss 4.68367670691805e-06, (1.5231092e-07, 0.0043817544, 0.00017932095, 0.40752587)\n","   validation loss 5.794494427391328e-06, (4.6757972e-07, 0.011989669, 0.0005268957, 0.40752587)\n","decoder loss ratio: 0.000002, decoder SINDy loss  ratio: 0.000532\n","Epoch 3400\n","   training loss 2.599084109533578e-05, (2.1406277e-05, 0.0049198903, 0.00027050258, 0.40655255)\n","   validation loss 2.4408551325905137e-05, (1.8904318e-05, 0.013566458, 0.0008206192, 0.40655255)\n","decoder loss ratio: 0.000092, decoder SINDy loss  ratio: 0.000828\n","Epoch 3500\n","   training loss 4.663696927309502e-06, (1.5851941e-07, 0.0043003466, 0.0002163418, 0.4053509)\n","   validation loss 5.697617780242581e-06, (3.9906735e-07, 0.011898497, 0.0005519201, 0.4053509)\n","decoder loss ratio: 0.000002, decoder SINDy loss  ratio: 0.000557\n","THRESHOLDING: 4 active coefficients\n","Epoch 3600\n","   training loss 5.335393325367477e-06, (8.2728207e-07, 0.004351813, 0.00025966478, 0.40469638)\n","   validation loss 6.201706128194928e-06, (9.1904354e-07, 0.011772424, 0.00058456685, 0.40469638)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000590\n","Epoch 3700\n","   training loss 5.503124612005195e-06, (1.0034481e-06, 0.004338935, 0.0002813085, 0.40376523)\n","   validation loss 6.299003871390596e-06, (1.0281858e-06, 0.011727343, 0.000604316, 0.40376523)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.000610\n","Epoch 3800\n","   training loss 5.624235654977383e-06, (1.1334954e-06, 0.004332672, 0.00029983395, 0.40274894)\n","   validation loss 6.3783591031096876e-06, (1.1188001e-06, 0.011699501, 0.0006211914, 0.40274894)\n","decoder loss ratio: 0.000005, decoder SINDy loss  ratio: 0.000627\n","Epoch 3900\n","   training loss 5.725557002733694e-06, (1.2434737e-06, 0.004330607, 0.0003164499, 0.40173778)\n","   validation loss 6.452224170061527e-06, (1.2032466e-06, 0.011680298, 0.00063569995, 0.40173778)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000641\n","Epoch 4000\n","   training loss 5.804543889098568e-06, (1.33089e-06, 0.004328738, 0.0003308885, 0.40076914)\n","   validation loss 6.516686426039087e-06, (1.2779398e-06, 0.011663201, 0.0006473556, 0.40076914)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000653\n","THRESHOLDING: 4 active coefficients\n","Epoch 4100\n","   training loss 5.849582521477714e-06, (1.3847172e-06, 0.0043239216, 0.0003426281, 0.39982107)\n","   validation loss 6.562165253853891e-06, (1.3339267e-06, 0.011644519, 0.0006557604, 0.39982107)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000662\n","Epoch 4200\n","   training loss 5.845685791427968e-06, (1.3900077e-06, 0.004313594, 0.00035132476, 0.3989186)\n","   validation loss 6.5769913817348424e-06, (1.3594623e-06, 0.011622739, 0.00066069106, 0.3989186)\n","decoder loss ratio: 0.000007, decoder SINDy loss  ratio: 0.000667\n","Epoch 4300\n","   training loss 5.773532848252216e-06, (1.3279613e-06, 0.004294974, 0.0003567838, 0.39803958)\n","   validation loss 6.546685654029716e-06, (1.3402387e-06, 0.0115985125, 0.0006619952, 0.39803958)\n","decoder loss ratio: 0.000007, decoder SINDy loss  ratio: 0.000668\n","Epoch 4400\n","   training loss 5.59478849027073e-06, (1.1608738e-06, 0.004258954, 0.00035834796, 0.39721847)\n","   validation loss 6.450786713685375e-06, (1.2548192e-06, 0.011579275, 0.00065855327, 0.39721847)\n","decoder loss ratio: 0.000006, decoder SINDy loss  ratio: 0.000665\n","Epoch 4500\n","   training loss 7.740120963717345e-06, (3.2497678e-06, 0.004886837, 0.00035680237, 0.39659894)\n","   validation loss 8.626304406789131e-06, (3.4339562e-06, 0.011507341, 0.00075625133, 0.39659894)\n","decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000763\n","THRESHOLDING: 4 active coefficients\n","Epoch 4600\n","   training loss 7.378287591564003e-06, (2.9086823e-06, 0.0047986275, 0.0003622427, 0.39535186)\n","   validation loss 8.40861139295157e-06, (3.2271423e-06, 0.011522917, 0.0007565882, 0.39535186)\n","decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.000763\n","Epoch 4700\n","   training loss 7.297355296032038e-06, (2.8388708e-06, 0.004789532, 0.00036398048, 0.39431334)\n","   validation loss 8.340868589584716e-06, (3.164029e-06, 0.011577501, 0.000759556, 0.39431334)\n","decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000766\n","Epoch 4800\n","   training loss 7.207594535429962e-06, (2.7589745e-06, 0.0047710584, 0.00036510592, 0.39350036)\n","   validation loss 8.258874004241079e-06, (3.0882786e-06, 0.011595037, 0.0007608811, 0.39350036)\n","decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000768\n","Epoch 4900\n","   training loss 7.11185930413194e-06, (2.6733867e-06, 0.0047458927, 0.0003654944, 0.39273342)\n","   validation loss 8.168082786141895e-06, (3.0058477e-06, 0.011588283, 0.0007607326, 0.39273342)\n","decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000768\n","Epoch 5000\n","   training loss 7.016259587544482e-06, (2.5873653e-06, 0.0047174767, 0.0003655327, 0.39205936)\n","   validation loss 8.075307050603442e-06, (2.9221858e-06, 0.01156569, 0.00075959717, 0.39205936)\n","decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000767\n","THRESHOLDING: 4 active coefficients\n","REFINEMENT\n","Epoch 0\n","   training loss 5.603433237411082e-07, (1.6406335e-07, 0.0037189536, 0.00024384652, 0.3929237)\n","   validation loss 1.7152659665953252e-06, (5.2478316e-07, 0.011310993, 0.0005938349, 0.3929237)\n","decoder loss ratio: 0.000003, decoder SINDy loss  ratio: 0.000599\n","Epoch 100\n","   training loss 6.519257453874161e-07, (3.1703593e-07, 0.0030863108, 0.00026258756, 0.40669954)\n","   validation loss 1.7883653526951093e-06, (8.0612114e-07, 0.0093074115, 0.00051503046, 0.40669954)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000520\n","Epoch 200\n","   training loss 6.623216677326127e-07, (3.345333e-07, 0.0030793678, 0.00019851587, 0.41183603)\n","   validation loss 1.6844616084199515e-06, (7.8603205e-07, 0.008474487, 0.00050980883, 0.41183603)\n","decoder loss ratio: 0.000004, decoder SINDy loss  ratio: 0.000514\n","Epoch 300\n","   training loss 2.0562683857860975e-06, (1.7037403e-06, 0.003268941, 0.00025634046, 0.4176593)\n","   validation loss 2.8796225706173573e-06, (2.0429143e-06, 0.0077627273, 0.00060435385, 0.4176593)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000610\n","Epoch 400\n","   training loss 1.9725812308024615e-06, (1.6357122e-06, 0.0031193383, 0.00024935076, 0.42143616)\n","   validation loss 2.772770585579565e-06, (1.974943e-06, 0.0073922304, 0.0005860475, 0.42143616)\n","decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000591\n","Epoch 500\n","   training loss 1.9069924519499182e-06, (1.5827771e-06, 0.002999153, 0.00024300003, 0.42474225)\n","   validation loss 2.6835434709937545e-06, (1.9183788e-06, 0.007081366, 0.00057028065, 0.42474225)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000575\n","Epoch 600\n","   training loss 1.8372910517427954e-06, (1.5240744e-06, 0.0028953454, 0.00023682113, 0.42767954)\n","   validation loss 2.5924553028744413e-06, (1.8555403e-06, 0.006813268, 0.0005558801, 0.42767954)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000561\n","Epoch 700\n","   training loss 1.77001732026838e-06, (1.4663043e-06, 0.0028060735, 0.00023105757, 0.43031824)\n","   validation loss 2.504959638827131e-06, (1.7927572e-06, 0.0065794084, 0.00054261624, 0.43031824)\n","decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000548\n","Epoch 800\n","   training loss 1.706807665868837e-06, (1.4113123e-06, 0.0027291584, 0.00022579537, 0.4327102)\n","   validation loss 2.4229423161159502e-06, (1.732542e-06, 0.0063736327, 0.00053037034, 0.4327102)\n","decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000535\n","Epoch 900\n","   training loss 1.6513828313691192e-06, (1.362974e-06, 0.002662991, 0.00022109754, 0.43489707)\n","   validation loss 2.3494258130085655e-06, (1.678353e-06, 0.0061916243, 0.0005191021, 0.43489707)\n","decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000524\n","Epoch 1000\n","   training loss 1.6064354895206634e-06, (1.3241299e-06, 0.0026060396, 0.00021701584, 0.43691376)\n","   validation loss 2.286610424562241e-06, (1.632759e-06, 0.0060297293, 0.00050878536, 0.43691376)\n","decoder loss ratio: 0.000008, decoder SINDy loss  ratio: 0.000513\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-49c4b7839fd5>:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = df.append({**results_dict, **params}, ignore_index=True)\n"]}],"source":["num_experiments = 1\n","df = pd.DataFrame()\n","for i in range(num_experiments):\n","    print('EXPERIMENT %d' % i)\n","\n","    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n","\n","    params['save_name'] = 'LV_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n","\n","    # tf.reset_default_graph() didn't work anymore\n","    tf.compat.v1.reset_default_graph()\n","\n","    results_dict = train_network(training_data, validation_data, params)\n","    df = df.append({**results_dict, **params}, ignore_index=True)\n","\n","df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}